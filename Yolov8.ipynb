{"cells":[{"cell_type":"markdown","metadata":{"id":"fl1LfKB_Pym3"},"source":["\n","##Dependency\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"YliHlp7kj6iV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692604559307,"user_tz":-420,"elapsed":19497,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"5c1232b1-5068-4d93-a907-fb369bc3433b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"l18XFjWu-wLl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692604559308,"user_tz":-420,"elapsed":15,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"f4e84cd4-1a72-421b-976b-1c729e068366"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BDC\n"]}],"source":["%cd /content/drive/MyDrive/BDC"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6106,"status":"ok","timestamp":1692604565406,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"c2QlHLQcjYVU","outputId":"f07357bd-09b3-4c25-cc1e-24e890772798"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.0.158-py3-none-any.whl (609 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m609.6/609.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.42.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (16.0.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: ultralytics\n","Successfully installed ultralytics-8.0.158\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17569,"status":"ok","timestamp":1692604582960,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"3iqph0IiJIqc","outputId":"e5e19253-70db-4a71-f532-2f47e878f89d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gfpgan\n","  Downloading gfpgan-1.3.8-py3-none-any.whl (52 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting basicsr>=1.4.2 (from gfpgan)\n","  Downloading basicsr-1.4.2.tar.gz (172 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting facexlib>=0.2.5 (from gfpgan)\n","  Downloading facexlib-0.3.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lmdb (from gfpgan)\n","  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gfpgan) (1.23.5)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from gfpgan) (4.8.0.76)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gfpgan) (6.0.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gfpgan) (1.10.1)\n","Collecting tb-nightly (from gfpgan)\n","  Downloading tb_nightly-2.15.0a20230820-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from gfpgan) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from gfpgan) (0.15.2+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gfpgan) (4.66.1)\n","Collecting yapf (from gfpgan)\n","  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting addict (from basicsr>=1.4.2->gfpgan)\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan) (0.18.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan) (9.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan) (2.31.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan) (0.19.3)\n","Collecting filterpy (from facexlib>=0.2.5->gfpgan)\n","  Downloading filterpy-1.4.5.zip (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->gfpgan) (0.56.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->gfpgan) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->gfpgan) (16.0.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (1.57.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (3.4.4)\n","Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (2.3.7)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (0.41.1)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan) (6.8.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan) (3.10.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan) (2.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly->gfpgan) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->gfpgan) (3.16.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->gfpgan) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->gfpgan) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->gfpgan) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->gfpgan) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->gfpgan) (2.1.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib>=0.2.5->gfpgan) (3.7.1)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.5->gfpgan) (0.39.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan) (2.31.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan) (2023.8.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan) (23.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->gfpgan) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->gfpgan) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly->gfpgan) (3.2.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (4.42.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (2.8.2)\n","Building wheels for collected packages: basicsr, filterpy\n","  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214817 sha256=f6b469318ee36073cdb730f5a9ff7b183a6422e832cbca445ca2e8ed7da5c1bd\n","  Stored in directory: /root/.cache/pip/wheels/38/83/99/2d8437cc652a01af27df5ff037a4075e95b52d67705c5f30ca\n","  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=cc8eb5f7c62dd51e58ad705d0437b44deda8a677aa3583c335339ed3ec738af8\n","  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n","Successfully built basicsr filterpy\n","Installing collected packages: lmdb, addict, yapf, filterpy, tb-nightly, facexlib, basicsr, gfpgan\n","Successfully installed addict-2.4.0 basicsr-1.4.2 facexlib-0.3.0 filterpy-1.4.5 gfpgan-1.3.8 lmdb-1.4.1 tb-nightly-2.15.0a20230820 yapf-0.40.1\n"]}],"source":["\n","!pip install gfpgan"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"in6LasIjjoGm","executionInfo":{"status":"ok","timestamp":1692604590886,"user_tz":-420,"elapsed":7932,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"outputs":[],"source":["import cv2\n","from ultralytics import YOLO\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","from google.colab import files"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14288,"status":"ok","timestamp":1692604605164,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"RjbWMVxbvcdu","outputId":"d17e6065-d512-4544-9ef4-3fbfc62966b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting aspose-words\n","  Downloading aspose_words-23.8.0-py3-none-manylinux1_x86_64.whl (82.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: aspose-words\n","Successfully installed aspose-words-23.8.0\n"]}],"source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","!pip install aspose-words"]},{"cell_type":"markdown","source":["#Final Test Program"],"metadata":{"id":"I7wrrFmZBESA"}},{"cell_type":"markdown","metadata":{"id":"zk-PqKCSPVA4"},"source":["##Function"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"5BIxs8u8aNd4","executionInfo":{"status":"ok","timestamp":1692606251476,"user_tz":-420,"elapsed":335,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"outputs":[],"source":["## Mengurutkan nama file berdasarkan urutan angka\n","import re\n","def natural_sort_key(s):\n","    parts = re.split(r'(\\d+)', s)\n","    parts[1::2] = map(int, parts[1::2])\n","    return parts"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"YhZxvjPGk64s","executionInfo":{"status":"ok","timestamp":1692606251804,"user_tz":-420,"elapsed":5,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"outputs":[],"source":["'''Untuk Menggabungkan karakter yang telah dideteksi oleh model\n","Untuk membatasi jumlah karakter harus kurang dari 9 '''\n","def BikinPlat(x):\n","  tmp=''\n","  c= 0\n","  for i in plat:\n","    if c < 8:\n","      tmp = tmp + convert(i)\n","    else:\n","      tmp = tmp\n","    c = c+1\n","\n","  return tmp"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"-T6K9jCk0Fbq","executionInfo":{"status":"ok","timestamp":1692606252482,"user_tz":-420,"elapsed":25,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"outputs":[],"source":["## untuk mengkonversi label berupa angka menjadi karakter-karakter pada plat kendaraan\n","def convert(i):\n","  if i == '0':\n","    return 'A'\n","  elif i == '1':\n","    return 'B'\n","  elif i == '2':\n","    return 'C'\n","  elif i == '3':\n","    return 'D'\n","  elif i == '4':\n","    return 'E'\n","  elif i == '5':\n","    return 'F'\n","  elif i == '6':\n","    return 'G'\n","  elif i == '7':\n","    return 'H'\n","  elif i == '8':\n","    return 'I'\n","  elif i == '9':\n","    return 'J'\n","  elif i == '10':\n","    return 'K'\n","  elif i == '11':\n","    return 'L'\n","  elif i == '12':\n","    return 'M'\n","  elif i == '13':\n","    return 'N'\n","  elif i == '14':\n","    return 'O'\n","  elif i == '15':\n","    return 'P'\n","  elif i == '16':\n","    return 'Q'\n","  elif i == '17':\n","    return 'R'\n","  elif i == '18':\n","    return 'S'\n","  elif i == '19':\n","    return 'T'\n","  elif i == '20':\n","    return 'U'\n","  elif i == '21':\n","    return 'V'\n","  elif i == '22':\n","    return 'W'\n","  elif i == '23':\n","    return 'X'\n","  elif i == '24':\n","    return 'Y'\n","  elif i == '25':\n","    return 'Z'\n","  elif i == '26':\n","    return '0'\n","  elif i == '27':\n","    return '1'\n","  elif i == '28':\n","    return '2'\n","  elif i == '29':\n","    return '3'\n","  elif i == '30':\n","    return '4'\n","  elif i == '31':\n","    return '5'\n","  elif i == '32':\n","    return '6'\n","  elif i == '33':\n","    return '7'\n","  elif i == '34':\n","    return '8'\n","  elif i == '35':\n","    return '9'\n","  else:\n","    return \" \""]},{"cell_type":"code","source":["## Untuk menghapus digit numerik yang lebih dari 4 buah\n","## Untuk mengibah hasil deteksi O menjadi 0 (nol) jika jumlah digit numerik sudah 4 buah\n","def RemoveDigit(i):\n","  teks = list(i)\n","  c= -1\n","  for i in range(len(teks)):\n","    if teks[i].isdigit():\n","      c=c+1\n","      if c >3 and  teks[i]== '0':\n","        teks[i] = 'O'\n","      elif c> 3 and teks[i]!= '0':\n","        teks[i] = \"\"\n","  teks = ''.join(teks)\n","  return teks"],"metadata":{"id":"c4CKqo8nrIyo","executionInfo":{"status":"ok","timestamp":1692606252485,"user_tz":-420,"elapsed":25,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["## Mengecek jumlah karakter huruf diawal, jika jumlahnya lebih dari 2, maka akan diambil 2 karakter huruf pertama\n","def CheckKarakter(i):\n","  tmp = i\n","  pattern = \"[A-Z]{1,2}\\d+(\\w+)\"\n","  digitAkhir = re.findall(pattern, i)\n","  pattern = \"[A-Z]{1,2}(\\d+)\\w+\"\n","  digitTengah = re.findall(pattern, i)\n","  pattern = \"([A-Z]{1,3})\\d+\\w+\"\n","  digitAwal = re.findall(pattern, tmp)\n","  if digitAwal:\n","    if len(digitAwal[0]) >= 3:\n","      tmp = digitAwal[0][:2]+digitTengah[0]+digitAkhir[0]\n","  if digitAkhir:\n","    if len(digitAkhir[0])>3:\n","      tmp = digitAwal[0][:2]+digitTengah[0]+digitAkhir[0][:3]\n","  return tmp"],"metadata":{"id":"f94cffKnyYAd","executionInfo":{"status":"ok","timestamp":1692606252488,"user_tz":-420,"elapsed":27,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["#Fungsi berikut berdasarkan aturan plat tiap daerah\n","\n","def AturanPlat(i):\n","  pattern = \"[A-Z]{1,2}\\d+(\\w+)\"\n","  digitAkhir = re.findall(pattern, i)\n","  pattern = \"[A-Z]{1,2}(\\d+)\\w+\"\n","  digitTengah = re.findall(pattern, i)\n","  pattern = \"([A-Z]{1,2})\\d+\\w+\"\n","  digitAwal = re.findall(pattern, i)\n","  tmp = list(i)\n","  if digitTengah:\n","    if digitTengah[0][0] == \"0\":\n","      digitTengah[0] = \"8\" + digitTengah[0][1:]\n","      tmp = digitAwal + digitTengah + digitAkhir ## Jika karakter awal numerik pada plat nomor dideteksi 0, maka diubah menjadi menjadi 8\n","  if tmp[0]+tmp[1] == 'AB':\n","    if tmp[-2] == 'O':\n","      tmp[-1] = tmp[-1].replace(tmp[-1], 'H') ## Jika karakter awal AB, dan karakter ke 2 dari akhir adalah O, maka karakter akhir diubah menjadi H\n","    elif tmp[-1] == 'O':\n","      tmp.append('H')\n","    elif i[-1]=='1':\n","      i= i[:-1] + \"I\" #Jika digit akhir merupakan angka 1, maka diganti dengan huruf I, karena paling menyerupai\n","      if len(digitAkhir[0]) == 1:\n","        tmp = list(i) + [\"Z\"] # Jika panjang digit akhir hanya 1 karakter, ditambahkan dengan huruf Z\n","\n","  elif tmp[0]+tmp[1] == 'AD':\n","    if tmp[-2]+ tmp[-1] == 'AB':\n","      tmp.append('E') ## Jika digit akhirnya AB (dua huruf), ditambahkan huruf E\n","    elif tmp[-2] == 'C':\n","      tmp[-1] = tmp[-1].replace(tmp[-1], 'B') ##Jika digit keduanya C, digit akhirnya direplcae B\n","  elif tmp[0] == 'B' and tmp[1].isdigit():\n","    if digitAkhir[0][0] == 'U' and len(digitAkhir[0]) == 1:\n","      tmp.append('L') # Jika karakter digit akhirnya hanya 1, dan karakternya U, ditambahkan karakter L\n","    elif digitAkhir[0][0] not in [\"B\",\"S\",\"U\",\"P\",\"T\", \"W\", \"E\", \"N\", \"W\", \"C\", \"V\", \"Q\", \"D\", \"G\", \"J\", \"K\", \"F\", \"Y\",\"R\"] and digitAkhir[0] not in [\"RFD\",\"RFS\",\"RFL\",\"RFU\",\"RFP\"]:\n","      tmp[-2] = tmp[-2].replace(tmp[-2], 'B') #Jika digit akhirnya tidak mengandung plat dari wilayah jabodetabek dan plat khusus, digit keduanya direplace 2 ~\n","    elif i[0]== 'B' and i[1] =='1' and i[-3:]!= \"JKT\":\n","      k=0\n","      for x in i:\n","        if x.isdigit():\n","          k=k+1\n","      if k ==1:\n","        i = \"\".join(digitAwal+digitTengah) + \"JKT\"\n","        tmp = list(i) ## Jika karakter awal B, diikuti numeriknya 1, digit akhirnya diubah menjadi JKT\n","  if digitAwal:\n","    if digitAwal[0] == \"AT\":\n","      tmp = [\"AB\"] + digitTengah + digitAkhir ## Karena AT tidak ada, maka diganti AB\n","      if tmp[-1]==\"I\" and (len(digitAkhir[0]) == 1):\n","        tmp += [\"N\"] ##Jika panjang digit akhirnya 1,dan digit akhirnya I, ditambah huruf N di digit akhir\n","  tmp = ''.join(tmp)\n","  return tmp"],"metadata":{"id":"qJ81DPit3rGH","executionInfo":{"status":"ok","timestamp":1692606252489,"user_tz":-420,"elapsed":27,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":["Referensi Aturan Plat Kendaraan : https://auto2000.co.id/berita-dan-tips/kode-plat-nomor-belakang#"],"metadata":{"id":"rOsqw7UFJfvf"}},{"cell_type":"code","execution_count":72,"metadata":{"id":"JRYYj7f2QPD8","executionInfo":{"status":"ok","timestamp":1692606252491,"user_tz":-420,"elapsed":28,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"outputs":[],"source":["## Untuk mengukur akurasi hasil prediksi\n","\n","def metric(y_pred, y_true):\n","  n = min(len(y_true), len(y_pred))\n","  banyak_spasi= 9-len(y_true)\n","  score= 0\n","  for i in range(n):\n","    if y_pred[i]==y_true[i]:\n","      score+=1\n","  score+= banyak_spasi\n","  score/= 9\n","  return score\n"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1692606252494,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"uTI64b8pQtoD","outputId":"6e01d085-9bcd-4296-b626-a4241b337454"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               File      Plate\n","0     DataTest1.png   AD7034OE\n","1     DataTest2.png    A9388EX\n","2     DataTest3.png      B16TB\n","3     DataTest4.png   B1661TKZ\n","4     DataTest5.png  AD3772ABE\n","..              ...        ...\n","95   DataTest96.png    B1285UL\n","96   DataTest97.png   AB8644PK\n","97   DataTest98.png   AG9718EG\n","98   DataTest99.png    B1509UN\n","99  DataTest100.png    B1408RX\n","\n","[100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-12295248-f899-4c33-bb3e-1d8b08904c92\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File</th>\n","      <th>Plate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest1.png</td>\n","      <td>AD7034OE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DataTest2.png</td>\n","      <td>A9388EX</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest3.png</td>\n","      <td>B16TB</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DataTest4.png</td>\n","      <td>B1661TKZ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DataTest5.png</td>\n","      <td>AD3772ABE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>DataTest96.png</td>\n","      <td>B1285UL</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>DataTest97.png</td>\n","      <td>AB8644PK</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>DataTest98.png</td>\n","      <td>AG9718EG</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>DataTest99.png</td>\n","      <td>B1509UN</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>DataTest100.png</td>\n","      <td>B1408RX</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12295248-f899-4c33-bb3e-1d8b08904c92')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-12295248-f899-4c33-bb3e-1d8b08904c92 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-12295248-f899-4c33-bb3e-1d8b08904c92');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-979049ab-06e3-403a-8e2d-5eafb7125ba3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-979049ab-06e3-403a-8e2d-5eafb7125ba3')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-979049ab-06e3-403a-8e2d-5eafb7125ba3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":73}],"source":["validation = pd.read_csv('/content/drive/MyDrive/BDC/val.csv', sep=',')\n","validation = validation.iloc[validation['File'].map(natural_sort_key).argsort()]\n","validation"]},{"cell_type":"markdown","source":["##YOLOV5L FOKUSKAN DISINI"],"metadata":{"id":"6KYXydw43MAM"}},{"cell_type":"code","execution_count":74,"metadata":{"id":"p9MzjAcj_gIJ","executionInfo":{"status":"ok","timestamp":1692606264569,"user_tz":-420,"elapsed":12102,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"12d5b76b-da11-4ff8-e8d5-c82f860deecc"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","image 1/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest1.png: 224x640 1 A, 1 D, 1 E, 1 O, 1 0, 1 3, 1 4, 1 7, 31.2ms\n","image 2/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest10.png: 256x640 2 Bs, 1 H, 1 Y, 1 1, 1 3, 1 6, 1 7, 58.4ms\n","image 3/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest100.png: 192x640 1 B, 1 R, 1 X, 1 0, 1 1, 1 4, 1 8, 27.5ms\n","image 4/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest11.png: 224x640 2 Bs, 1 E, 1 I, 1 1, 1 2, 1 6, 1 7, 30.6ms\n","image 5/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest12.png: 224x640 1 B, 1 N, 1 W, 1 Z, 1 1, 1 6, 1 7, 1 8, 30.2ms\n","image 6/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest13.png: 224x640 1 A, 1 D, 2 Ss, 1 1, 2 3s, 1 9, 29.9ms\n","image 7/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest14.png: 224x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 30.0ms\n","image 8/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest15.png: 352x640 1 B, 1 S, 1 Z, 1 0, 2 1s, 1 8, 37.4ms\n","image 9/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest16.png: 288x640 1 B, 1 J, 1 S, 1 T, 1 1, 2 4s, 1 7, 36.0ms\n","image 10/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest17.png: 224x640 1 B, 1 P, 1 U, 1 1, 1 3, 2 9s, 30.6ms\n","image 11/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest18.png: 224x640 1 B, 2 Ts, 1 Z, 1 0, 1 1, 1 2, 1 6, 29.8ms\n","image 12/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest19.png: 224x640 1 B, 1 J, 1 O, 1 T, 1 1, 1 3, 1 6, 1 7, 29.9ms\n","image 13/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest2.png: 224x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 29.9ms\n","image 14/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest20.png: 192x640 1 B, 1 O, 1 Q, 1 1, 1 7, 27.5ms\n","image 15/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest21.png: 352x640 1 A, 1 2, 1 6, 1 8, 37.7ms\n","image 16/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest22.png: 224x640 1 B, 1 P, 1 Z, 1 1, 1 2, 1 3, 1 6, 30.9ms\n","image 17/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest23.png: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 23.6ms\n","image 18/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest24.png: 256x640 1 B, 1 J, 1 K, 1 T, 1 1, 26.3ms\n","image 19/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest25.png: 160x640 2 As, 1 D, 1 O, 1 0, 1 4, 1 7, 1 8, 22.9ms\n","image 20/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest26.png: 352x640 1 B, 1 E, 1 G, 1 K, 3 1s, 1 3, 32.3ms\n","image 21/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest27.png: 192x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 3, 1 7, 25.8ms\n","image 22/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest28.png: 192x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 22.6ms\n","image 23/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest29.png: 192x640 1 A, 1 B, 1 C, 1 D, 1 Q, 1 0, 1 2, 1 8, 1 9, 22.6ms\n","image 24/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest3.png: 256x640 2 Bs, 1 T, 2 1s, 1 6, 25.8ms\n","image 25/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest30.png: 320x640 1 A, 1 M, 1 Z, 1 1, 1 2, 2 9s, 31.5ms\n","image 26/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest31.png: 224x640 1 B, 1 I, 1 K, 1 T, 1 X, 2 0s, 1 1, 1 2, 26.5ms\n","image 27/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest32.png: 224x640 1 B, 1 O, 1 R, 1 T, 1 1, 1 3, 1 4, 1 6, 25.5ms\n","image 28/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest33.png: 192x640 1 B, 1 J, 1 T, 1 U, 1 0, 1 1, 1 3, 1 9, 23.3ms\n","image 29/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest34.png: 352x640 1 A, 1 B, 1 D, 1 V, 1 1, 1 2, 1 6, 1 8, 31.9ms\n","image 30/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest35.png: 256x640 1 B, 1 E, 1 F, 1 T, 1 0, 1 1, 1 6, 1 8, 27.7ms\n","image 31/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest36.png: 416x640 1 A, 1 F, 1 S, 1 4, 1 6, 1 7, 1 8, 1 9, 39.1ms\n","image 32/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest37.png: 224x640 1 B, 1 F, 1 N, 1 O, 1 1, 1 5, 2 6s, 26.2ms\n","image 33/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest38.png: 288x640 1 B, 1 J, 1 Q, 1 S, 1 0, 1 1, 1 3, 1 6, 27.8ms\n","image 34/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest39.png: 192x640 1 B, 1 F, 1 T, 1 X, 1 1, 1 2, 1 4, 1 5, 21.1ms\n","image 35/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest4.png: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 20.2ms\n","image 36/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest40.png: 224x640 1 B, 1 C, 1 J, 1 Y, 1 0, 1 1, 1 3, 1 6, 1 8, 23.6ms\n","image 37/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest41.png: 352x640 1 A, 1 B, 1 H, 1 U, 1 2, 1 3, 1 4, 1 9, 28.7ms\n","image 38/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest42.png: 160x640 1 B, 1 N, 1 U, 1 0, 2 1s, 1 5, 1 9, 24.0ms\n","image 39/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest43.png: 160x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 3, 1 7, 1 9, 19.8ms\n","image 40/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest44.png: 256x640 1 B, 1 L, 1 U, 1 0, 1 1, 2 2s, 23.3ms\n","image 41/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest45.png: 224x640 1 B, 1 M, 1 T, 1 Z, 1 0, 1 1, 1 2, 1 6, 23.6ms\n","image 42/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest46.png: 288x640 1 B, 1 P, 1 W, 1 Y, 1 1, 1 2, 1 4, 1 7, 27.7ms\n","image 43/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest47.png: 192x640 1 B, 1 I, 1 S, 1 V, 1 0, 2 1s, 1 2, 21.0ms\n","image 44/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest48.png: 224x640 1 A, 1 D, 1 E, 1 O, 1 0, 1 3, 1 4, 1 7, 24.0ms\n","image 45/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest49.png: 352x640 1 A, 1 B, 1 C, 1 X, 1 2, 1 3, 1 4, 1 5, 28.7ms\n","image 46/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest5.png: 384x640 2 As, 1 B, 1 D, 1 2, 1 3, 2 7s, 29.3ms\n","image 47/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest50.png: 224x640 2 Bs, 1 E, 1 J, 1 1, 1 5, 1 8, 1 9, 23.6ms\n","image 48/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest51.png: 256x640 1 B, 1 J, 1 T, 1 U, 1 1, 1 6, 1 7, 1 8, 23.7ms\n","image 49/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest52.png: 256x640 1 B, 1 F, 1 R, 1 S, 1 1, 1 4, 1 5, 1 9, 29.3ms\n","image 50/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest53.png: 256x640 1 B, 1 E, 1 F, 1 O, 1 1, 1 6, 1 8, 1 9, 29.4ms\n","image 51/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest54.png: 192x640 1 B, 1 V, 1 X, 2 1s, 1 3, 1 7, 27.1ms\n","image 52/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest55.png: 352x640 1 B, 1 P, 1 S, 1 W, 1 0, 1 1, 1 2, 1 3, 1 6, 37.2ms\n","image 53/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest56.png: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 27.4ms\n","image 54/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest57.png: 192x640 2 As, 1 V, 1 0, 1 1, 1 4, 1 8, 26.4ms\n","image 55/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest58.png: 192x640 1 B, 1 U, 1 Y, 1 1, 1 3, 1 7, 1 8, 26.4ms\n","image 56/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest59.png: 160x640 1 B, 1 U, 1 0, 1 1, 1 2, 1 8, 26.6ms\n","image 57/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest6.png: 192x640 1 B, 1 O, 1 V, 1 1, 1 2, 1 5, 1 7, 27.7ms\n","image 58/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest60.png: 224x640 2 Bs, 1 K, 1 1, 2 2s, 1 4, 30.7ms\n","image 59/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest61.png: 320x640 2 As, 1 B, 1 X, 1 1, 1 2, 1 7, 1 8, 36.3ms\n","image 60/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest62.png: 288x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 35.8ms\n","image 61/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest63.png: 288x640 1 B, 1 Y, 2 1s, 1 5, 1 7, 31.2ms\n","image 62/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest64.png: 224x640 1 B, 1 D, 1 F, 1 R, 1 1, 1 2, 2 3s, 25.0ms\n","image 63/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest65.png: 192x640 1 B, 1 I, 1 N, 1 0, 2 1s, 1 3, 22.3ms\n","image 64/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest66.png: 256x640 1 A, 1 D, 1 J, 1 R, 2 9s, 24.3ms\n","image 65/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest67.png: 288x640 1 B, 1 E, 1 S, 1 Y, 1 1, 1 3, 1 6, 1 8, 28.7ms\n","image 66/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest68.png: 256x640 2 As, 1 F, 1 Q, 2 0s, 1 4, 1 7, 24.3ms\n","image 67/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest69.png: 160x640 1 B, 2 Ss, 1 W, 2 1s, 1 2, 1 4, 21.6ms\n","image 68/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest7.png: 288x640 1 B, 1 F, 1 R, 1 T, 1 0, 1 1, 1 4, 1 6, 29.0ms\n","image 69/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest70.png: 256x640 1 B, 2 Js, 1 T, 1 1, 1 2, 1 3, 1 6, 24.2ms\n","image 70/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest71.png: 256x640 1 B, 1 E, 1 L, 1 R, 1 0, 1 1, 1 7, 1 9, 23.5ms\n","image 71/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest72.png: 192x640 1 B, 1 J, 1 Q, 1 T, 2 1s, 1 5, 1 8, 22.3ms\n","image 72/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest73.png: 288x640 1 B, 1 J, 1 N, 1 U, 1 1, 1 3, 1 4, 1 7, 28.7ms\n","image 73/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest74.png: 192x640 1 B, 1 E, 1 F, 1 Y, 1 1, 1 3, 1 4, 1 7, 21.9ms\n","image 74/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest75.png: 160x640 1 B, 1 O, 1 Q, 1 0, 1 1, 1 5, 1 7, 21.5ms\n","image 75/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest76.png: 352x640 1 A, 1 H, 1 I, 1 N, 1 2, 2 3s, 29.9ms\n","image 76/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest77.png: 192x640 1 B, 1 J, 2 Ts, 1 1, 1 2, 1 3, 1 5, 21.8ms\n","image 77/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest78.png: 256x640 1 B, 1 L, 2 Ss, 2 1s, 1 5, 1 7, 24.5ms\n","image 78/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest79.png: 192x640 1 B, 1 V, 1 X, 2 1s, 1 3, 1 7, 22.2ms\n","image 79/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest8.png: 160x640 1 B, 1 J, 1 T, 1 W, 1 1, 1 3, 1 5, 1 9, 22.0ms\n","image 80/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest80.png: 224x640 1 B, 1 J, 1 S, 1 T, 2 1s, 1 3, 1 6, 28.9ms\n","image 81/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest81.png: 192x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 25.0ms\n","image 82/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest82.png: 384x640 1 B, 1 K, 1 N, 1 Y, 1 1, 1 2, 1 3, 1 5, 36.9ms\n","image 83/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest83.png: 192x640 1 B, 2 Us, 1 Y, 2 0s, 1 1, 1 8, 25.3ms\n","image 84/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest84.png: 192x640 1 B, 1 E, 1 T, 1 V, 3 1s, 1 4, 25.3ms\n","image 85/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest85.png: 352x640 1 B, 1 E, 1 K, 1 3, 2 7s, 1 8, 37.7ms\n","image 86/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest86.png: 256x640 1 B, 1 D, 1 F, 1 R, 1 1, 2 3s, 1 9, 28.3ms\n","image 87/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest87.png: 192x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 3, 1 9, 25.8ms\n","image 88/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest88.png: 320x640 1 A, 1 B, 1 H, 1 0, 1 2, 1 5, 1 8, 1 9, 26.7ms\n","image 89/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest89.png: 256x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 22.4ms\n","image 90/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest9.png: 256x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 2, 1 7, 20.8ms\n","image 91/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest90.png: 224x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 5, 2 8s, 22.1ms\n","image 92/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest91.png: 256x640 1 B, 1 N, 2 Ss, 1 1, 1 3, 1 4, 1 6, 21.6ms\n","image 93/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest92.png: 288x640 1 A, 2 Bs, 1 H, 2 1s, 1 3, 1 5, 27.6ms\n","image 94/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest93.png: 288x640 1 A, 1 B, 2 Us, 1 1, 1 2, 1 6, 1 7, 24.7ms\n","image 95/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest94.png: 224x640 1 B, 1 J, 1 T, 1 V, 1 0, 1 1, 1 2, 1 8, 25.0ms\n","image 96/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest95.png: 160x640 2 Bs, 1 R, 1 U, 2 1s, 1 6, 1 9, 19.0ms\n","image 97/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest96.png: 256x640 1 B, 1 O, 1 Q, 1 U, 1 5, 2 8s, 21.7ms\n","image 98/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest97.png: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 19.9ms\n","image 99/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest98.png: 192x640 1 A, 1 E, 2 Gs, 1 1, 1 7, 1 8, 1 9, 18.6ms\n","image 100/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest99.png: 160x640 1 B, 1 N, 1 U, 1 0, 2 1s, 1 5, 1 9, 22.6ms\n","Speed: 1.6ms preprocess, 27.1ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n"]}],"source":["model = YOLO('/content/drive/MyDrive/BDC/best_v5l.pt')\n","tab = model.predict('/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs', conf = 0.4, iou= 0.1)"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"a8m40WHplQmw","executionInfo":{"status":"ok","timestamp":1692606265283,"user_tz":-420,"elapsed":736,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"outputs":[],"source":["NomorKendaraan=[]\n","NamaFile= []\n","for i in tab :\n","  kelas = pd.DataFrame(i.boxes.cls.cpu().numpy()).astype(int)\n","  kelas = kelas.rename(columns={0:'kelas'})\n","  titik = pd.DataFrame(i.boxes.xywhn.cpu().numpy())\n","  titik = titik.rename(columns={0:'x', 1:'y', 2:'w', 3:'h'})\n","  titik= titik.join(kelas).sort_values('x', ascending=True)\n","  plat = titik['kelas'].astype(str).tolist()\n","  name = i.path.split('/')\n","  name= name[8]\n","  NomorKendaraan.append(BikinPlat(plat))\n","  NamaFile.append(name)\n","\n","import re\n","def natural_sort_key(s):\n","    parts = re.split(r'(\\d+)', s)\n","    parts[1::2] = map(int, parts[1::2])\n","    return parts\n","\n","submission4 = {\n","    'File': NamaFile,\n","    'Plate':NomorKendaraan\n","}\n","submission4 = pd.DataFrame(submission4)\n","submission4 = submission4.iloc[submission4['File'].map(natural_sort_key).argsort()]\n","\n","# lu 1 sampe 50, gua 51 sampe 100 ngelabelinnya"]},{"cell_type":"code","source":["y_true = validation['Plate']\n","y_pred4 = submission4['Plate']\n","scores=[]\n","for y_pred, y_true in zip(y_pred4, y_true):\n","  score = metric(y_pred,y_true)\n","  scores.append(score)"],"metadata":{"id":"JBK1635QzWb7","executionInfo":{"status":"ok","timestamp":1692606265284,"user_tz":-420,"elapsed":21,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["np.mean(scores), len(scores)"],"metadata":{"id":"j4E0aBRO2Nt1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606265285,"user_tz":-420,"elapsed":20,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"fbc297a7-64a8-4ae4-f23f-e46464798475"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.9288888888888889, 100)"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["submission4['score'] = scores"],"metadata":{"id":"c01eppFi5LSx","executionInfo":{"status":"ok","timestamp":1692606265285,"user_tz":-420,"elapsed":17,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["submission4"],"metadata":{"id":"odIaTXK-5To8","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1692606265287,"user_tz":-420,"elapsed":18,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"e1f60da4-00c4-48e2-ad8b-bbbca072188f"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               File     Plate     score\n","0     DataTest1.png  AD7034OE  1.000000\n","12    DataTest2.png   A9388EX  1.000000\n","23    DataTest3.png    B161TB  0.777778\n","34    DataTest4.png  B1661TKZ  1.000000\n","45    DataTest5.png  AD3772AB  0.888889\n","..              ...       ...       ...\n","96   DataTest96.png   BO885UQ  0.666667\n","97   DataTest97.png  AB8644PK  1.000000\n","98   DataTest98.png  AG9718EG  1.000000\n","99   DataTest99.png  B15091UN  0.777778\n","2   DataTest100.png   B1408RX  1.000000\n","\n","[100 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-523922cb-afc5-4977-8191-0e5ed6d0b366\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File</th>\n","      <th>Plate</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest1.png</td>\n","      <td>AD7034OE</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>DataTest2.png</td>\n","      <td>A9388EX</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>DataTest3.png</td>\n","      <td>B161TB</td>\n","      <td>0.777778</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>DataTest4.png</td>\n","      <td>B1661TKZ</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>DataTest5.png</td>\n","      <td>AD3772AB</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>DataTest96.png</td>\n","      <td>BO885UQ</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>DataTest97.png</td>\n","      <td>AB8644PK</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>DataTest98.png</td>\n","      <td>AG9718EG</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>DataTest99.png</td>\n","      <td>B15091UN</td>\n","      <td>0.777778</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest100.png</td>\n","      <td>B1408RX</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-523922cb-afc5-4977-8191-0e5ed6d0b366')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-523922cb-afc5-4977-8191-0e5ed6d0b366 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-523922cb-afc5-4977-8191-0e5ed6d0b366');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b0a9a7a6-eb81-438c-a0a6-3fe93d63e044\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0a9a7a6-eb81-438c-a0a6-3fe93d63e044')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b0a9a7a6-eb81-438c-a0a6-3fe93d63e044 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":79}]},{"cell_type":"markdown","source":["##TESTING ALL ROTATE"],"metadata":{"id":"fLsmnf0S_Gf3"}},{"cell_type":"code","source":["#Evaluasi 1, Rotate 15\n","import imutils\n","NewPlate1 = []\n","NewScore1 = []\n","Files = []\n","for File, plate , score in zip(submission4['File'], submission4['Plate'], submission4['score']):\n","  img = cv2.imread('/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/'+ File)\n","  img = imutils.rotate(img, angle=15)\n","  img = img_scale_up = cv2.resize(img, (0, 0), fx=1.5, fy=1.5)\n","  # Create the sharpening kernel\n","  kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n","  # Apply the sharpening kernel to the image using filter2D\n","  img = cv2.filter2D(img, -1, kernel)\n","\n","  tab = model.predict(img)\n","  kelas = pd.DataFrame(tab[0].boxes.cls.cpu().numpy()).astype(int)\n","  kelas = kelas.rename(columns={0:'kelas'})\n","  titik = pd.DataFrame(tab[0].boxes.xywhn.cpu().numpy())\n","  titik = titik.rename(columns={0:'x', 1:'y', 2:'w', 3:'h'})\n","  titik= titik.join(kelas).sort_values('x', ascending=True)\n","  plat = titik['kelas'].astype(str).tolist()\n","  plat =  BikinPlat(plat)\n","  val = (validation[validation['File'] == File].Plate).tolist()\n","  val = val[0]\n","  scoreEval = metric(plat,val)\n","  print(scoreEval)\n","  if scoreEval > score:\n","    NewPlate1.append(plat)\n","    NewScore1.append(scoreEval)\n","    Files.append(File)\n","  else :\n","    NewPlate1.append(plate)\n","    NewScore1.append(score)\n","    Files.append(File)\n","Files = pd.DataFrame(Files)\n","Files = Files.rename(columns={0:'Files'})\n","\n","NewPlate1 = pd.DataFrame(NewPlate1)\n","NewPlate1 = NewPlate1.rename(columns={0:'NewPlate1'})\n","\n","NewScore1 = pd.DataFrame(NewScore1)\n","NewScore1 = NewScore1.rename(columns={0:'NewScore1'})\n","\n","Evaluasi1 = pd.concat([Files, NewPlate1, NewScore1], axis= 1)"],"metadata":{"id":"EShFg-eF_GIR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606286069,"user_tz":-420,"elapsed":20798,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"3a159098-8ebf-4ad3-998e-0fe1a60ea75a"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 1 E, 1 O, 1 0, 1 3, 1 4, 1 7, 31.0ms\n","Speed: 2.2ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 224x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 30.2ms\n","Speed: 2.1ms preprocess, 30.2ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 256x640 2 Bs, 1 K, 1 1, 1 6, 31.4ms\n","Speed: 2.1ms preprocess, 31.4ms inference, 2.1ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 K, 1 T, 1 Z, 1 1, 1 4, 2 6s, 28.8ms\n","Speed: 2.1ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 384x640 2 As, 1 B, 1 D, 1 E, 1 U, 1 2, 1 3, 2 7s, 38.6ms\n","Speed: 2.7ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 O, 1 V, 1 0, 1 1, 1 5, 1 7, 27.9ms\n","Speed: 5.3ms preprocess, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 F, 1 R, 1 T, 1 0, 1 1, 1 4, 1 6, 36.0ms\n","Speed: 2.3ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 160x640 1 B, 1 D, 1 J, 1 T, 1 W, 1 1, 1 3, 1 5, 1 9, 26.7ms\n","Speed: 2.8ms preprocess, 26.7ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 2, 1 7, 31.6ms\n","Speed: 4.2ms preprocess, 31.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 256x640 2 Bs, 1 H, 1 Y, 2 1s, 1 3, 1 6, 1 7, 29.4ms\n","Speed: 2.1ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 224x640 2 Bs, 1 E, 1 1, 1 2, 1 5, 30.8ms\n","Speed: 1.6ms preprocess, 30.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.3333333333333333\n","0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 N, 1 W, 1 Z, 1 1, 1 6, 1 7, 1 8, 30.1ms\n","Speed: 2.3ms preprocess, 30.1ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 2 Ss, 1 1, 2 3s, 1 9, 29.9ms\n","Speed: 3.8ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 29.9ms\n","Speed: 3.4ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 3 Bs, 1 S, 1 0, 2 1s, 2 7s, 1 8, 37.6ms\n","Speed: 3.0ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 288x640 1 B, 1 J, 1 S, 3 1s, 2 4s, 1 7, 35.9ms\n","Speed: 2.2ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.4444444444444444\n","0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 D, 1 P, 1 0, 1 1, 1 3, 2 9s, 30.6ms\n","Speed: 3.0ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 2 Bs, 1 L, 1 0, 2 1s, 1 2, 1 6, 1 7, 29.8ms\n","Speed: 1.3ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.4444444444444444\n","0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["0: 224x640 2 Bs, 1 J, 1 O, 1 T, 2 1s, 1 3, 1 6, 1 7, 30.7ms\n","Speed: 3.0ms preprocess, 30.7ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 O, 1 Q, 1 0, 29.1ms\n","Speed: 1.9ms preprocess, 29.1ms inference, 2.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 A, 37.3ms\n","Speed: 3.3ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 224x640 1 B, 1 H, 1 L, 1 1, 1 2, 1 3, 1 6, 30.7ms\n","Speed: 1.4ms preprocess, 30.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.5555555555555556\n","0.2222222222222222\n","0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 24.2ms\n","Speed: 1.9ms preprocess, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 B, 1 I, 1 J, 1 K, 1 1, 26.6ms\n","Speed: 2.0ms preprocess, 26.6ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 2 As, 1 B, 1 L, 1 O, 1 0, 1 7, 1 8, 23.0ms\n","Speed: 2.9ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 352x640 2 Bs, 1 G, 1 K, 2 1s, 1 3, 1 7, 1 9, 32.1ms\n","Speed: 2.9ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","0.5555555555555556\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 N, 1 0, 1 1, 1 3, 1 7, 24.2ms\n","Speed: 2.1ms preprocess, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 192x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 24.3ms\n","Speed: 2.1ms preprocess, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 O, 2 0s, 1 3, 1 4, 25.0ms\n","Speed: 4.0ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["0: 320x640 1 A, 1 L, 2 9s, 32.7ms\n","Speed: 3.4ms preprocess, 32.7ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 224x640 1 B, 1 K, 1 Q, 2 0s, 1 1, 1 2, 1 7, 30.6ms\n","Speed: 2.0ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.4444444444444444\n","0.5555555555555556\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 O, 1 R, 1 T, 1 1, 1 3, 1 4, 1 6, 30.0ms\n","Speed: 2.8ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 C, 1 J, 1 0, 1 1, 1 3, 1 9, 28.5ms\n","Speed: 2.9ms preprocess, 28.5ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 A, 1 B, 1 D, 1 V, 1 1, 1 2, 1 6, 1 8, 37.3ms\n","Speed: 3.0ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 E, 1 F, 1 T, 1 0, 1 1, 1 6, 1 8, 30.0ms\n","Speed: 2.9ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 416x640 1 A, 1 F, 1 S, 1 4, 1 6, 1 7, 1 9, 45.5ms\n","Speed: 3.0ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 224x640 1 B, 1 F, 2 Ns, 1 O, 2 1s, 1 5, 2 6s, 30.5ms\n","Speed: 2.1ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n","0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 D, 1 J, 1 S, 1 0, 1 1, 1 3, 1 6, 35.8ms\n","Speed: 3.1ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 2 Bs, 1 F, 1 K, 1 T, 1 X, 1 1, 1 2, 1 4, 1 5, 27.2ms\n","Speed: 2.2ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 224x640 1 B, 2 Js, 1 0, 1 1, 1 3, 1 4, 1 6, 1 8, 30.5ms\n","Speed: 1.9ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 352x640 1 A, 1 B, 1 H, 1 U, 1 2, 1 3, 1 4, 1 9, 37.2ms\n","Speed: 3.7ms preprocess, 37.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n","0.6666666666666666\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 5, 1 9, 27.2ms\n","Speed: 1.8ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 160x640 1 L, 1 P, 1 T, 1 Y, 1 1, 1 3, 1 7, 1 9, 26.1ms\n","Speed: 1.7ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 L, 2 Us, 1 0, 2 2s, 1 4, 30.1ms\n","Speed: 4.5ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 M, 1 N, 1 T, 1 Z, 1 0, 1 1, 1 2, 1 6, 31.0ms\n","Speed: 2.9ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 P, 1 W, 1 Y, 1 1, 1 2, 1 4, 1 7, 36.0ms\n","Speed: 3.7ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 192x640 1 B, 1 I, 1 S, 1 V, 1 0, 2 1s, 1 2, 27.6ms\n","Speed: 2.7ms preprocess, 27.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 B, 1 D, 1 E, 1 O, 1 0, 1 3, 1 4, 1 7, 31.1ms\n","Speed: 3.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 352x640 1 A, 1 B, 1 K, 1 2, 2 3s, 1 4, 1 5, 37.2ms\n","Speed: 2.5ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 2 Bs, 1 E, 1 J, 1 1, 1 5, 1 8, 1 9, 30.9ms\n","Speed: 2.6ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 256x640 2 Bs, 1 J, 1 T, 1 U, 1 1, 1 6, 1 7, 1 8, 30.6ms\n","Speed: 3.6ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 2 Bs, 1 F, 1 R, 1 S, 1 1, 1 4, 1 5, 1 9, 29.3ms\n","Speed: 3.5ms preprocess, 29.3ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 E, 1 F, 1 O, 1 1, 1 6, 1 8, 1 9, 29.3ms\n","Speed: 2.5ms preprocess, 29.3ms inference, 1.7ms postprocess per image at shape (1, 3, 256, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 V, 1 X, 2 1s, 1 3, 1 7, 29.6ms\n","Speed: 1.9ms preprocess, 29.6ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 2 Bs, 1 P, 1 S, 1 W, 1 0, 1 1, 1 2, 1 3, 1 6, 37.8ms\n","Speed: 3.4ms preprocess, 37.8ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 1 4, 2 6s, 28.0ms\n","Speed: 2.1ms preprocess, 28.0ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 2 As, 1 H, 1 V, 1 0, 1 1, 1 4, 1 8, 26.4ms\n","Speed: 1.8ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 U, 1 Y, 1 1, 1 3, 1 7, 1 8, 26.4ms\n","Speed: 1.9ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 160x640 1 B, 1 U, 1 0, 1 1, 1 2, 1 6, 29.2ms\n","Speed: 2.2ms preprocess, 29.2ms inference, 1.7ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 224x640 2 Bs, 1 K, 1 1, 1 2, 1 4, 31.1ms\n","Speed: 2.0ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n","0.5555555555555556\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 320x640 1 A, 2 Bs, 1 Q, 1 1, 1 2, 1 5, 36.6ms\n","Speed: 2.4ms preprocess, 36.6ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 288x640 1 A, 1 D, 1 E, 1 U, 1 1, 1 4, 1 8, 38.2ms\n","Speed: 2.1ms preprocess, 38.2ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.5555555555555556\n","0.5555555555555556\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 2 Bs, 1 T, 1 Y, 1 1, 1 5, 1 7, 33.6ms\n","Speed: 2.4ms preprocess, 33.6ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 224x640 2 Bs, 1 D, 1 F, 1 R, 1 U, 1 1, 1 2, 2 3s, 30.1ms\n","Speed: 2.1ms preprocess, 30.1ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 I, 1 N, 1 0, 2 1s, 1 3, 26.6ms\n","Speed: 1.9ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 A, 1 D, 1 J, 1 R, 2 9s, 29.1ms\n","Speed: 1.9ms preprocess, 29.1ms inference, 1.8ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 288x640 1 B, 1 E, 1 S, 1 Y, 1 1, 1 3, 1 6, 1 8, 34.3ms\n","Speed: 2.0ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 2 As, 1 Q, 2 0s, 1 1, 1 4, 1 7, 27.3ms\n","Speed: 2.9ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 160x640 1 B, 1 H, 2 Ss, 2 1s, 1 2, 1 4, 25.4ms\n","Speed: 1.9ms preprocess, 25.4ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.5555555555555556\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 2 Js, 1 T, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 27.3ms\n","Speed: 3.1ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 256x640 1 B, 1 E, 1 L, 1 R, 1 0, 1 1, 1 7, 1 9, 26.6ms\n","Speed: 2.3ms preprocess, 26.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.5555555555555556\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 D, 1 J, 1 T, 2 1s, 1 5, 1 8, 24.9ms\n","Speed: 2.2ms preprocess, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 288x640 1 B, 1 J, 1 N, 1 U, 1 1, 1 3, 1 4, 1 7, 32.4ms\n","Speed: 3.6ms preprocess, 32.4ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 2 Bs, 1 E, 1 Y, 1 1, 1 3, 1 4, 1 7, 24.7ms\n","Speed: 3.2ms preprocess, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 160x640 1 B, 1 O, 1 Q, 1 0, 1 1, 1 5, 1 7, 24.5ms\n","Speed: 1.8ms preprocess, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 2 As, 1 I, 1 N, 1 T, 1 2, 2 3s, 1 9, 33.8ms\n","Speed: 2.4ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 192x640 2 Bs, 1 J, 1 S, 2 1s, 1 2, 1 3, 1 5, 24.7ms\n","Speed: 2.3ms preprocess, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 B, 1 L, 1 S, 2 1s, 1 5, 1 7, 27.0ms\n","Speed: 1.7ms preprocess, 27.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n","0.7777777777777778\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 V, 1 X, 2 1s, 1 3, 1 7, 24.8ms\n","Speed: 1.9ms preprocess, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 J, 2 Ss, 1 T, 2 1s, 1 3, 1 5, 1 6, 27.3ms\n","Speed: 2.2ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 192x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 24.6ms\n","Speed: 1.8ms preprocess, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.4444444444444444\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 384x640 2 Bs, 1 K, 1 M, 1 N, 1 X, 2 1s, 1 3, 1 5, 33.5ms\n","Speed: 3.3ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 192x640 1 B, 1 D, 1 U, 2 0s, 1 1, 1 8, 23.7ms\n","Speed: 2.0ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 E, 1 T, 1 V, 3 1s, 1 4, 23.2ms\n","Speed: 2.7ms preprocess, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 B, 1 E, 1 K, 1 3, 2 7s, 1 8, 32.5ms\n","Speed: 4.5ms preprocess, 32.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 256x640 1 B, 1 D, 1 F, 1 R, 1 U, 1 1, 2 3s, 1 8, 1 9, 26.1ms\n","Speed: 1.7ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 192x640 1 B, 1 D, 1 F, 1 R, 1 V, 1 0, 1 1, 1 3, 1 9, 23.7ms\n","Speed: 1.6ms preprocess, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.1111111111111111\n","0.4444444444444444\n","0.1111111111111111\n"]},{"output_type":"stream","name":"stderr","text":["0: 320x640 1 A, 1 B, 1 0, 1 5, 1 8, 30.8ms\n","Speed: 2.1ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 256x640 1 A, 1 D, 1 E, 1 U, 1 1, 1 4, 1 8, 24.8ms\n","Speed: 2.6ms preprocess, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n","0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 3 Bs, 1 L, 1 P, 1 T, 2 1s, 1 5, 2 8s, 25.5ms\n","Speed: 2.1ms preprocess, 25.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 256x640 1 B, 1 N, 2 Ss, 2 1s, 1 3, 1 4, 1 6, 24.7ms\n","Speed: 1.8ms preprocess, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 288x640 1 A, 2 Bs, 1 H, 1 1, 1 3, 1 5, 28.9ms\n","Speed: 2.7ms preprocess, 28.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n","0.7777777777777778\n","0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 A, 1 B, 2 Us, 1 1, 1 2, 1 6, 1 7, 28.2ms\n","Speed: 4.3ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 J, 1 T, 1 V, 1 0, 1 1, 1 2, 1 8, 24.9ms\n","Speed: 2.4ms preprocess, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 160x640 2 Bs, 1 R, 1 0, 2 1s, 1 6, 1 9, 22.0ms\n","Speed: 1.4ms preprocess, 22.0ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 256x640 1 B, 1 D, 1 L, 1 Q, 1 U, 1 3, 1 5, 1 6, 2 8s, 24.6ms\n","Speed: 2.4ms preprocess, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n","0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 K, 1 N, 1 P, 2 4s, 1 6, 1 8, 22.1ms\n","Speed: 3.0ms preprocess, 22.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 192x640 1 A, 1 B, 1 G, 1 1, 1 7, 1 8, 1 9, 26.9ms\n","Speed: 2.4ms preprocess, 26.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 5, 1 9, 27.1ms\n","Speed: 1.8ms preprocess, 27.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 192x640 1 B, 1 K, 1 R, 1 X, 1 0, 1 1, 1 4, 1 8, 30.4ms\n","Speed: 1.8ms preprocess, 30.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]}]},{"cell_type":"code","source":["#Evaluasi 2, Rotate -15\n","import imutils\n","NewPlate2 = []\n","NewScore2 = []\n","Files2 = []\n","for File, plate , score in zip(Evaluasi1['Files'], Evaluasi1['NewPlate1'], Evaluasi1['NewScore1']):\n","  img = cv2.imread('/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/'+ File)\n","  img = imutils.rotate(img, angle=-15)\n","  img = img_scale_up = cv2.resize(img, (0, 0), fx=1.5, fy=1.5)\n","  # Create the sharpening kernel\n","  kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n","  # Apply the sharpening kernel to the image using filter2D\n","  img = cv2.filter2D(img, -1, kernel)\n","\n","  tab = model.predict(img)\n","  kelas = pd.DataFrame(tab[0].boxes.cls.cpu().numpy()).astype(int)\n","  kelas = kelas.rename(columns={0:'kelas'})\n","  titik = pd.DataFrame(tab[0].boxes.xywhn.cpu().numpy())\n","  titik = titik.rename(columns={0:'x', 1:'y', 2:'w', 3:'h'})\n","  titik= titik.join(kelas).sort_values('x', ascending=True)\n","  plat = titik['kelas'].astype(str).tolist()\n","  plat =  BikinPlat(plat)\n","  val = (validation[validation['File'] == File].Plate).tolist()\n","  val = val[0]\n","  scoreEval = metric(plat,val)\n","  print(scoreEval)\n","  if scoreEval > score:\n","    NewPlate2.append(plat)\n","    NewScore2.append(scoreEval)\n","    Files2.append(File)\n","  else :\n","    NewPlate2.append(plate)\n","    NewScore2.append(score)\n","    Files2.append(File)\n","Files2 = pd.DataFrame(Files2)\n","Files2 = Files2.rename(columns={0:'Files'})\n","\n","NewPlate2 = pd.DataFrame(NewPlate2)\n","NewPlate2 = NewPlate2.rename(columns={0:'NewPlate1'})\n","\n","NewScore2 = pd.DataFrame(NewScore2)\n","NewScore2 = NewScore2.rename(columns={0:'NewScore1'})\n","\n","Evaluasi2 = pd.concat([Files2, NewPlate2, NewScore2], axis= 1)\n"],"metadata":{"id":"Qa8eYhp1__lt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606307140,"user_tz":-420,"elapsed":21101,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"0bc29c42-1a9c-42c8-dbb6-b2b8df0629dc"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 1 E, 1 O, 1 0, 1 3, 1 4, 1 7, 31.4ms\n","Speed: 2.4ms preprocess, 31.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 29.9ms\n","Speed: 2.4ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 3 Bs, 1 T, 1 1, 1 6, 1 7, 30.0ms\n","Speed: 2.7ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 K, 1 T, 1 Z, 1 1, 1 2, 2 6s, 28.6ms\n","Speed: 3.5ms preprocess, 28.6ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 384x640 1 A, 1 B, 1 3, 37.9ms\n","Speed: 3.2ms preprocess, 37.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","0.1111111111111111\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 O, 1 V, 1 1, 1 3, 1 7, 27.4ms\n","Speed: 2.6ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["0: 288x640 1 B, 1 F, 1 R, 1 T, 1 0, 1 1, 1 4, 1 6, 37.7ms\n","Speed: 3.2ms preprocess, 37.7ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 160x640 1 B, 1 J, 1 T, 1 W, 1 1, 1 3, 1 5, 1 9, 27.6ms\n","Speed: 1.9ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 D, 1 F, 1 G, 1 R, 1 0, 1 2, 1 7, 30.0ms\n","Speed: 3.2ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 256x640 2 Bs, 1 H, 1 Y, 1 1, 1 3, 1 6, 1 7, 29.5ms\n","Speed: 1.8ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 224x640 2 Bs, 1 E, 1 1, 1 2, 1 6, 1 7, 30.7ms\n","Speed: 1.9ms preprocess, 30.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.1111111111111111\n","1.0\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 M, 2 Ns, 1 W, 1 Z, 2 1s, 1 6, 1 7, 1 8, 30.0ms\n","Speed: 2.9ms preprocess, 30.0ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 1 S, 1 1, 2 3s, 1 9, 30.2ms\n","Speed: 2.5ms preprocess, 30.2ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 1 7, 30.2ms\n","Speed: 3.1ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 1 B, 1 S, 1 Z, 1 0, 3 1s, 1 8, 37.9ms\n","Speed: 4.7ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 288x640 1 B, 1 J, 1 S, 1 T, 1 1, 2 4s, 1 7, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 P, 1 1, 1 3, 2 9s, 30.7ms\n","Speed: 2.3ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 B, 1 T, 1 Z, 1 0, 2 1s, 1 2, 1 6, 30.2ms\n","Speed: 2.2ms preprocess, 30.2ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["0: 224x640 1 B, 1 J, 1 O, 1 T, 1 1, 1 3, 1 6, 1 7, 30.7ms\n","Speed: 3.6ms preprocess, 30.7ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 192x640 1 B, 1 O, 1 Q, 28.1ms\n","Speed: 2.4ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 1 A, 1 B, 1 1, 1 2, 1 3, 1 6, 2 8s, 37.4ms\n","Speed: 3.6ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 224x640 1 B, 1 P, 1 W, 1 Z, 1 1, 1 2, 1 3, 1 6, 31.2ms\n","Speed: 1.9ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.5555555555555556\n","0.2222222222222222\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 29.3ms\n","Speed: 2.3ms preprocess, 29.3ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 B, 1 J, 1 R, 1 T, 1 Y, 1 1, 29.9ms\n","Speed: 1.4ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 2 As, 1 O, 1 Q, 1 0, 1 4, 1 7, 1 8, 27.3ms\n","Speed: 2.7ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 352x640 1 B, 1 E, 1 G, 1 X, 3 1s, 1 3, 37.2ms\n","Speed: 3.4ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 N, 1 0, 1 1, 1 3, 1 7, 27.6ms\n","Speed: 1.8ms preprocess, 27.6ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 192x640 1 B, 1 U, 1 Z, 1 0, 1 1, 1 3, 1 6, 26.4ms\n","Speed: 1.9ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 C, 1 D, 1 0, 1 2, 1 3, 2 9s, 27.5ms\n","Speed: 2.4ms preprocess, 27.5ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 320x640 1 A, 1 M, 1 Z, 1 1, 1 2, 2 9s, 36.9ms\n","Speed: 4.8ms preprocess, 36.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 2 Ks, 1 T, 1 X, 2 0s, 1 1, 1 2, 30.9ms\n","Speed: 2.3ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 I, 1 O, 1 R, 1 T, 1 1, 1 3, 1 4, 1 6, 30.1ms\n","Speed: 2.3ms preprocess, 30.1ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 J, 1 T, 1 U, 1 0, 1 1, 1 3, 1 9, 27.4ms\n","Speed: 2.1ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 B, 1 1, 1 6, 1 8, 42.3ms\n","Speed: 2.6ms preprocess, 42.3ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.1111111111111111\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 E, 1 Z, 1 0, 1 6, 1 7, 1 8, 30.3ms\n","Speed: 2.5ms preprocess, 30.3ms inference, 1.6ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 416x640 1 A, 1 B, 1 G, 1 4, 1 6, 1 7, 1 9, 45.6ms\n","Speed: 2.9ms preprocess, 45.6ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 224x640 1 B, 1 F, 1 N, 1 O, 1 1, 1 5, 2 6s, 31.1ms\n","Speed: 1.8ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.1111111111111111\n","0.3333333333333333\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 D, 1 J, 1 Q, 1 S, 1 0, 1 1, 1 3, 1 6, 36.2ms\n","Speed: 4.8ms preprocess, 36.2ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 F, 1 T, 1 X, 1 1, 1 2, 1 4, 1 5, 27.7ms\n","Speed: 2.7ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 224x640 1 B, 1 C, 1 J, 1 Y, 1 0, 1 1, 1 3, 1 8, 31.9ms\n","Speed: 1.4ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 352x640 1 A, 1 B, 2 Hs, 1 M, 1 U, 1 2, 1 3, 1 4, 1 9, 37.6ms\n","Speed: 3.0ms preprocess, 37.6ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n","0.1111111111111111\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 5, 1 9, 27.0ms\n","Speed: 1.8ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 L, 1 T, 1 1, 1 3, 1 7, 1 8, 1 9, 28.2ms\n","Speed: 1.7ms preprocess, 28.2ms inference, 1.7ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 L, 1 U, 1 0, 2 2s, 30.0ms\n","Speed: 4.0ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 M, 1 Z, 1 0, 1 2, 1 6, 30.9ms\n","Speed: 2.7ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.1111111111111111\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 P, 1 W, 1 Y, 1 1, 1 2, 1 4, 1 7, 35.8ms\n","Speed: 3.4ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 192x640 1 B, 1 I, 1 N, 1 S, 1 0, 2 1s, 1 2, 28.4ms\n","Speed: 2.4ms preprocess, 28.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 1 E, 1 F, 1 O, 1 0, 1 3, 1 4, 1 7, 30.9ms\n","Speed: 3.4ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 352x640 1 A, 1 B, 1 C, 1 X, 1 2, 1 3, 1 4, 1 5, 37.6ms\n","Speed: 3.2ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 2 Bs, 1 E, 1 J, 1 1, 1 5, 1 8, 1 9, 30.7ms\n","Speed: 3.8ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 256x640 1 B, 1 J, 1 T, 1 U, 1 1, 1 6, 1 7, 1 8, 30.3ms\n","Speed: 4.4ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 F, 1 R, 1 S, 1 1, 1 4, 1 5, 1 9, 29.3ms\n","Speed: 4.0ms preprocess, 29.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 256x640 1 B, 1 E, 1 F, 1 O, 1 1, 1 5, 1 6, 1 8, 1 9, 30.7ms\n","Speed: 2.9ms preprocess, 30.7ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 192x640 1 B, 2 1s, 1 3, 1 7, 30.3ms\n","Speed: 2.8ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 1 B, 1 P, 1 S, 1 W, 1 0, 1 1, 1 2, 1 3, 1 6, 1 9, 37.4ms\n","Speed: 4.1ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 1 2, 2 6s, 27.2ms\n","Speed: 2.6ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 V, 1 0, 1 1, 1 4, 1 8, 27.8ms\n","Speed: 1.8ms preprocess, 27.8ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.5555555555555556\n","0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 U, 1 Y, 1 1, 1 3, 1 7, 1 8, 26.6ms\n","Speed: 2.6ms preprocess, 26.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 160x640 1 0, 1 1, 1 2, 1 6, 27.6ms\n","Speed: 1.7ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 2 Bs, 1 K, 1 1, 2 2s, 1 4, 31.1ms\n","Speed: 3.0ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 320x640 2 As, 1 B, 1 X, 1 2, 1 5, 1 7, 1 8, 36.5ms\n","Speed: 3.2ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 288x640 2 As, 1 D, 1 U, 1 1, 1 4, 1 8, 35.8ms\n","Speed: 2.3ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 Y, 2 1s, 1 5, 2 7s, 35.7ms\n","Speed: 2.6ms preprocess, 35.7ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 224x640 1 B, 1 D, 1 F, 1 R, 1 1, 1 2, 2 3s, 30.7ms\n","Speed: 3.3ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.5555555555555556\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 I, 1 N, 1 0, 2 1s, 1 3, 28.9ms\n","Speed: 2.5ms preprocess, 28.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 D, 1 J, 1 R, 2 9s, 30.1ms\n","Speed: 2.1ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 288x640 1 B, 1 E, 1 I, 1 S, 1 Y, 1 1, 1 3, 1 6, 1 8, 35.7ms\n","Speed: 2.1ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.4444444444444444\n","0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 2 As, 3 0s, 1 4, 1 7, 30.1ms\n","Speed: 4.3ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 160x640 1 B, 2 Ss, 1 W, 2 1s, 1 2, 1 4, 27.7ms\n","Speed: 2.3ms preprocess, 27.7ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 J, 1 T, 1 1, 1 2, 1 3, 1 6, 30.6ms\n","Speed: 2.5ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 256x640 1 B, 1 E, 1 L, 1 R, 1 0, 1 1, 1 7, 1 9, 29.3ms\n","Speed: 2.1ms preprocess, 29.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 D, 1 J, 1 T, 2 1s, 1 5, 1 8, 27.3ms\n","Speed: 2.1ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 288x640 1 B, 1 J, 1 N, 1 U, 1 1, 1 3, 1 4, 1 7, 36.8ms\n","Speed: 3.4ms preprocess, 36.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 E, 1 F, 1 Y, 1 1, 1 3, 1 4, 1 7, 27.2ms\n","Speed: 2.0ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 160x640 1 B, 1 D, 1 O, 1 0, 1 5, 2 7s, 26.9ms\n","Speed: 3.0ms preprocess, 26.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 2 3s, 37.1ms\n","Speed: 3.4ms preprocess, 37.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 192x640 1 B, 1 J, 2 Ts, 1 1, 1 2, 1 3, 1 5, 26.9ms\n","Speed: 1.8ms preprocess, 26.9ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 B, 1 L, 1 S, 2 1s, 1 5, 1 7, 30.3ms\n","Speed: 1.7ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","0.1111111111111111\n","1.0\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 2 1s, 1 3, 1 7, 23.8ms\n","Speed: 2.7ms preprocess, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 J, 1 S, 1 T, 2 1s, 1 3, 1 6, 26.4ms\n","Speed: 2.3ms preprocess, 26.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 192x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 23.6ms\n","Speed: 3.6ms preprocess, 23.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 384x640 1 B, 1 K, 1 N, 2 Ys, 1 1, 1 2, 1 3, 1 5, 32.8ms\n","Speed: 3.1ms preprocess, 32.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 192x640 1 B, 2 Us, 1 Y, 2 0s, 1 1, 1 8, 23.5ms\n","Speed: 2.0ms preprocess, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 E, 1 T, 1 V, 3 1s, 1 4, 22.6ms\n","Speed: 3.5ms preprocess, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 2 Bs, 1 K, 1 1, 1 3, 2 7s, 1 8, 32.3ms\n","Speed: 2.7ms preprocess, 32.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 256x640 1 B, 1 D, 1 F, 1 R, 1 1, 1 3, 1 8, 1 9, 25.7ms\n","Speed: 1.6ms preprocess, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 192x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 3, 1 9, 23.3ms\n","Speed: 2.1ms preprocess, 23.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.4444444444444444\n","0.7777777777777778\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 320x640 1 A, 1 B, 1 D, 1 H, 1 0, 1 2, 1 5, 1 8, 1 9, 31.2ms\n","Speed: 5.7ms preprocess, 31.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 256x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 26.2ms\n","Speed: 3.9ms preprocess, 26.2ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 5, 2 8s, 25.6ms\n","Speed: 2.3ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 256x640 1 B, 1 E, 1 N, 1 S, 1 V, 1 1, 1 3, 1 4, 1 6, 24.6ms\n","Speed: 3.1ms preprocess, 24.6ms inference, 1.7ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 288x640 1 A, 2 Bs, 1 H, 2 1s, 1 3, 1 5, 29.1ms\n","Speed: 2.4ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.2222222222222222\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 A, 1 B, 1 D, 2 Us, 1 1, 1 2, 1 6, 1 7, 28.5ms\n","Speed: 3.9ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 J, 1 T, 1 V, 1 0, 1 1, 1 2, 1 8, 25.4ms\n","Speed: 5.7ms preprocess, 25.4ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 160x640 2 Bs, 1 R, 1 U, 2 1s, 1 6, 1 9, 22.3ms\n","Speed: 1.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 O, 1 5, 2 8s, 25.0ms\n","Speed: 2.2ms preprocess, 25.0ms inference, 1.6ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 2 As, 1 B, 1 N, 1 P, 1 R, 1 X, 2 4s, 1 6, 1 8, 27.5ms\n","Speed: 2.2ms preprocess, 27.5ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 192x640 1 A, 1 E, 2 Gs, 1 1, 1 7, 1 8, 1 9, 26.4ms\n","Speed: 1.5ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 5, 1 9, 29.1ms\n","Speed: 1.7ms preprocess, 29.1ms inference, 1.8ms postprocess per image at shape (1, 3, 160, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 R, 1 X, 1 0, 1 1, 1 4, 1 8, 28.3ms\n","Speed: 1.9ms preprocess, 28.3ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]}]},{"cell_type":"code","source":["#Evaluasi 3, Rotate -7\n","import imutils\n","NewPlate2 = []\n","NewScore2 = []\n","Files2 = []\n","for File, plate , score in zip(Evaluasi2['Files'], Evaluasi2['NewPlate1'], Evaluasi2['NewScore1']):\n","  img = cv2.imread('/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/'+ File)\n","  img = imutils.rotate(img, angle=-7)\n","  img = img_scale_up = cv2.resize(img, (0, 0), fx=1.5, fy=1.5)\n","  # Create the sharpening kernel\n","  kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n","  # Apply the sharpening kernel to the image using filter2D\n","  img = cv2.filter2D(img, -1, kernel)\n","\n","  tab = model.predict(img)\n","  kelas = pd.DataFrame(tab[0].boxes.cls.cpu().numpy()).astype(int)\n","  kelas = kelas.rename(columns={0:'kelas'})\n","  titik = pd.DataFrame(tab[0].boxes.xywhn.cpu().numpy())\n","  titik = titik.rename(columns={0:'x', 1:'y', 2:'w', 3:'h'})\n","  titik= titik.join(kelas).sort_values('x', ascending=True)\n","  plat = titik['kelas'].astype(str).tolist()\n","  plat =  BikinPlat(plat)\n","  val = (validation[validation['File'] == File].Plate).tolist()\n","  val = val[0]\n","  scoreEval = metric(plat,val)\n","  print(scoreEval)\n","  if scoreEval > score:\n","    NewPlate2.append(plat)\n","    NewScore2.append(scoreEval)\n","    Files2.append(File)\n","  else :\n","    NewPlate2.append(plate)\n","    NewScore2.append(score)\n","    Files2.append(File)\n","Files2 = pd.DataFrame(Files2)\n","Files2 = Files2.rename(columns={0:'Files'})\n","\n","NewPlate2 = pd.DataFrame(NewPlate2)\n","NewPlate2 = NewPlate2.rename(columns={0:'NewPlate1'})\n","\n","NewScore2 = pd.DataFrame(NewScore2)\n","NewScore2 = NewScore2.rename(columns={0:'NewScore1'})\n","\n","Evaluasi3 = pd.concat([Files2, NewPlate2, NewScore2], axis= 1)\n"],"metadata":{"id":"Gy_La7MOA6h4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606332931,"user_tz":-420,"elapsed":25797,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"308c8add-3b3d-4986-8ebf-f626906d88c2"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 1 E, 1 N, 1 O, 1 0, 1 3, 1 4, 1 7, 31.3ms\n","Speed: 2.3ms preprocess, 31.3ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["0: 224x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 31.6ms\n","Speed: 2.0ms preprocess, 31.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 256x640 2 Bs, 1 T, 1 1, 1 6, 30.5ms\n","Speed: 2.3ms preprocess, 30.5ms inference, 1.7ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 27.5ms\n","Speed: 1.9ms preprocess, 27.5ms inference, 3.7ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 384x640 2 As, 1 B, 1 D, 1 3, 1 6, 1 7, 38.2ms\n","Speed: 2.6ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 2 Bs, 1 O, 1 V, 1 1, 1 2, 1 6, 1 7, 29.6ms\n","Speed: 2.1ms preprocess, 29.6ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 F, 1 R, 1 T, 1 0, 1 1, 1 4, 1 6, 38.0ms\n","Speed: 2.8ms preprocess, 38.0ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 160x640 1 B, 1 J, 1 T, 1 W, 1 1, 1 3, 1 5, 1 9, 28.2ms\n","Speed: 1.6ms preprocess, 28.2ms inference, 2.2ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 D, 1 F, 1 G, 1 R, 1 0, 1 1, 1 2, 1 7, 30.6ms\n","Speed: 2.4ms preprocess, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 256x640 2 Bs, 1 H, 1 Y, 1 1, 1 3, 1 6, 1 7, 29.2ms\n","Speed: 2.0ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 224x640 2 Bs, 1 E, 1 I, 1 1, 1 2, 1 6, 1 7, 30.9ms\n","Speed: 1.4ms preprocess, 30.9ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 2 Ns, 1 W, 1 Z, 1 1, 1 6, 1 7, 1 8, 30.1ms\n","Speed: 3.0ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 2 Ss, 1 1, 2 3s, 1 9, 30.0ms\n","Speed: 2.5ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 30.6ms\n","Speed: 2.2ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 1 B, 1 S, 1 T, 1 Z, 1 0, 3 1s, 1 8, 37.3ms\n","Speed: 3.6ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 288x640 1 B, 1 J, 1 S, 1 T, 1 1, 2 4s, 1 7, 36.1ms\n","Speed: 3.0ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 P, 1 U, 1 1, 1 3, 2 9s, 30.8ms\n","Speed: 2.5ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 B, 1 T, 1 Z, 1 0, 2 1s, 1 2, 1 6, 29.8ms\n","Speed: 1.8ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["0: 224x640 1 B, 1 J, 1 O, 1 T, 1 1, 1 3, 1 6, 1 7, 36.3ms\n","Speed: 2.4ms preprocess, 36.3ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 192x640 1 B, 1 O, 1 Q, 1 1, 1 7, 27.9ms\n","Speed: 2.7ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 1 A, 1 B, 1 1, 1 2, 1 3, 1 5, 1 6, 1 8, 37.3ms\n","Speed: 2.6ms preprocess, 37.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 224x640 1 B, 1 P, 1 W, 1 Z, 1 1, 1 2, 1 3, 1 6, 30.6ms\n","Speed: 2.6ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.3333333333333333\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 25.1ms\n","Speed: 2.3ms preprocess, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 B, 1 J, 1 K, 1 T, 1 1, 28.2ms\n","Speed: 1.8ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 2 As, 1 D, 1 O, 2 0s, 1 4, 1 7, 1 8, 25.3ms\n","Speed: 2.2ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 352x640 1 B, 1 E, 1 G, 1 K, 3 1s, 1 3, 34.5ms\n","Speed: 2.9ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 3, 1 7, 27.5ms\n","Speed: 2.1ms preprocess, 27.5ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 192x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 24.5ms\n","Speed: 2.6ms preprocess, 24.5ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 C, 1 D, 1 0, 1 2, 1 9, 24.4ms\n","Speed: 2.2ms preprocess, 24.4ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["0: 320x640 1 A, 1 M, 1 Z, 1 1, 1 2, 2 9s, 35.2ms\n","Speed: 3.9ms preprocess, 35.2ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 224x640 1 B, 1 K, 1 T, 1 X, 2 0s, 1 1, 1 2, 30.9ms\n","Speed: 3.5ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 O, 1 R, 1 T, 1 1, 1 3, 1 4, 1 6, 30.0ms\n","Speed: 2.8ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 J, 1 T, 1 U, 1 0, 1 1, 1 3, 1 9, 29.9ms\n","Speed: 2.0ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 A, 1 B, 1 D, 1 1, 1 2, 1 6, 1 8, 37.3ms\n","Speed: 3.9ms preprocess, 37.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 E, 1 F, 1 T, 1 0, 1 1, 1 6, 1 8, 29.9ms\n","Speed: 4.1ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 416x640 1 A, 1 B, 1 F, 1 S, 1 4, 1 6, 1 7, 1 8, 1 9, 45.3ms\n","Speed: 4.0ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 224x640 1 B, 1 F, 1 N, 1 O, 1 1, 1 5, 2 6s, 31.0ms\n","Speed: 1.8ms preprocess, 31.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.4444444444444444\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 J, 1 Q, 1 S, 1 0, 1 1, 1 3, 1 6, 28.2ms\n","Speed: 2.5ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 F, 1 T, 1 X, 1 1, 1 2, 1 4, 1 5, 21.3ms\n","Speed: 3.5ms preprocess, 21.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 224x640 1 B, 1 C, 1 J, 1 Y, 1 0, 1 1, 1 3, 1 8, 23.8ms\n","Speed: 3.4ms preprocess, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 352x640 1 A, 1 B, 1 H, 1 U, 1 2, 1 3, 1 4, 1 9, 29.2ms\n","Speed: 2.7ms preprocess, 29.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 N, 1 U, 1 0, 2 1s, 1 5, 1 9, 22.1ms\n","Speed: 1.8ms preprocess, 22.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 160x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 3, 1 7, 1 8, 20.5ms\n","Speed: 2.4ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 L, 1 U, 1 0, 1 1, 2 2s, 23.7ms\n","Speed: 3.2ms preprocess, 23.7ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 M, 1 T, 1 W, 1 Z, 1 0, 1 1, 1 2, 1 6, 23.9ms\n","Speed: 3.0ms preprocess, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 P, 1 W, 1 Y, 1 1, 1 2, 1 4, 1 7, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 192x640 1 B, 1 I, 1 N, 1 S, 1 V, 1 0, 2 1s, 1 2, 28.5ms\n","Speed: 1.9ms preprocess, 28.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 1 E, 1 O, 1 0, 1 3, 1 4, 1 7, 33.3ms\n","Speed: 2.1ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 352x640 1 A, 1 B, 1 C, 1 X, 1 2, 1 3, 1 4, 1 5, 37.3ms\n","Speed: 3.4ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 2 Bs, 1 E, 1 J, 1 1, 1 5, 1 8, 1 9, 31.2ms\n","Speed: 2.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 256x640 1 B, 1 J, 1 T, 1 U, 1 1, 1 6, 1 7, 1 8, 32.0ms\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["Speed: 2.7ms preprocess, 32.0ms inference, 1.7ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 F, 1 R, 1 S, 1 1, 1 4, 1 5, 1 9, 29.3ms\n","Speed: 4.9ms preprocess, 29.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 E, 1 F, 1 O, 1 1, 1 6, 1 8, 1 9, 39.0ms\n","Speed: 2.5ms preprocess, 39.0ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 X, 2 1s, 1 3, 1 7, 27.5ms\n","Speed: 2.0ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 1 B, 1 P, 1 S, 1 W, 1 0, 1 1, 1 2, 1 3, 1 6, 66.9ms\n","Speed: 9.9ms preprocess, 66.9ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 58.0ms\n","Speed: 1.9ms preprocess, 58.0ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 2 As, 1 V, 1 0, 1 1, 1 4, 1 8, 39.1ms\n","Speed: 1.9ms preprocess, 39.1ms inference, 6.8ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 U, 1 Y, 1 1, 1 3, 1 7, 1 8, 54.0ms\n","Speed: 1.9ms preprocess, 54.0ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 U, 1 0, 1 1, 1 2, 1 6, 1 8, 36.2ms\n","Speed: 2.2ms preprocess, 36.2ms inference, 1.7ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 2 Bs, 1 H, 1 K, 1 M, 1 1, 2 2s, 1 4, 59.8ms\n","Speed: 2.1ms preprocess, 59.8ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 320x640 2 As, 1 B, 1 X, 1 1, 1 2, 1 5, 1 7, 1 8, 44.9ms\n","Speed: 9.9ms preprocess, 44.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 94.4ms\n","Speed: 4.5ms preprocess, 94.4ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 Y, 2 1s, 1 5, 1 7, 35.1ms\n","Speed: 2.9ms preprocess, 35.1ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 D, 1 F, 1 R, 1 1, 1 2, 2 3s, 51.8ms\n","Speed: 2.1ms preprocess, 51.8ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 I, 1 N, 1 0, 2 1s, 1 3, 45.2ms\n","Speed: 2.6ms preprocess, 45.2ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 A, 1 D, 1 J, 1 R, 2 9s, 63.5ms\n","Speed: 14.1ms preprocess, 63.5ms inference, 1.8ms postprocess per image at shape (1, 3, 256, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 288x640 1 B, 1 E, 1 S, 1 Y, 1 1, 1 3, 1 6, 1 8, 43.8ms\n","Speed: 5.7ms preprocess, 43.8ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 2 As, 1 F, 1 Q, 3 0s, 1 4, 1 7, 30.3ms\n","Speed: 2.4ms preprocess, 30.3ms inference, 1.6ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 2 Ss, 1 W, 2 1s, 1 2, 1 4, 27.1ms\n","Speed: 1.8ms preprocess, 27.1ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 2 Js, 1 T, 1 1, 1 2, 1 3, 1 6, 30.5ms\n","Speed: 2.4ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 256x640 1 B, 1 E, 1 L, 1 R, 1 0, 1 1, 1 7, 1 9, 57.3ms\n","Speed: 2.3ms preprocess, 57.3ms inference, 1.9ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 J, 1 Q, 1 T, 2 1s, 1 5, 1 8, 38.9ms\n","Speed: 2.0ms preprocess, 38.9ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 288x640 1 B, 1 J, 1 N, 1 U, 1 V, 1 1, 1 3, 1 4, 1 7, 47.0ms\n","Speed: 2.1ms preprocess, 47.0ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 E, 1 F, 1 Y, 1 1, 1 3, 1 4, 1 7, 27.9ms\n","Speed: 2.3ms preprocess, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 160x640 1 B, 1 O, 1 Q, 1 0, 1 5, 2 7s, 27.5ms\n","Speed: 1.7ms preprocess, 27.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 2 3s, 37.2ms\n","Speed: 2.8ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 192x640 1 B, 1 F, 1 J, 2 Ts, 1 1, 1 2, 1 3, 1 5, 27.1ms\n","Speed: 1.6ms preprocess, 27.1ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 B, 1 L, 2 Ss, 2 1s, 1 5, 1 7, 30.2ms\n","Speed: 1.6ms preprocess, 30.2ms inference, 1.6ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","0.1111111111111111\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 X, 2 1s, 1 3, 1 7, 25.7ms\n","Speed: 2.5ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["0: 224x640 1 B, 1 J, 1 S, 1 T, 2 1s, 1 3, 1 6, 28.8ms\n","Speed: 2.3ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 192x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 26.3ms\n","Speed: 2.1ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 384x640 1 B, 1 K, 1 N, 1 Y, 1 1, 1 2, 1 3, 1 5, 38.3ms\n","Speed: 4.3ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 192x640 1 B, 2 Us, 1 Y, 2 0s, 1 1, 1 8, 25.4ms\n","Speed: 1.5ms preprocess, 25.4ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 E, 1 T, 1 V, 3 1s, 1 4, 25.8ms\n","Speed: 2.1ms preprocess, 25.8ms inference, 2.6ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 B, 1 E, 1 K, 1 X, 1 3, 2 7s, 1 8, 37.0ms\n","Speed: 3.7ms preprocess, 37.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 256x640 1 B, 1 D, 1 F, 1 R, 1 1, 2 3s, 1 9, 28.2ms\n","Speed: 1.6ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 192x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 3, 1 9, 25.6ms\n","Speed: 1.7ms preprocess, 25.6ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.2222222222222222\n","0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 320x640 1 A, 1 B, 1 H, 1 0, 1 2, 1 5, 1 8, 1 9, 31.5ms\n","Speed: 2.6ms preprocess, 31.5ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 256x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 26.0ms\n","Speed: 1.9ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 5, 2 8s, 26.9ms\n","Speed: 2.2ms preprocess, 26.9ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 256x640 1 B, 1 N, 2 Ss, 1 V, 1 1, 1 3, 1 4, 1 6, 25.4ms\n","Speed: 1.6ms preprocess, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 288x640 1 A, 2 Bs, 1 H, 2 1s, 1 3, 1 5, 32.4ms\n","Speed: 3.8ms preprocess, 32.4ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 A, 1 B, 2 Us, 1 1, 1 2, 1 6, 1 7, 29.5ms\n","Speed: 3.7ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 J, 1 T, 1 V, 1 0, 1 1, 1 2, 1 8, 26.1ms\n","Speed: 3.8ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 160x640 2 Bs, 1 R, 1 U, 2 1s, 1 6, 1 9, 22.4ms\n","Speed: 1.3ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 256x640 1 A, 1 B, 1 O, 1 Q, 1 U, 1 2, 1 5, 2 8s, 25.7ms\n","Speed: 2.3ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n","0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 23.5ms\n","Speed: 2.9ms preprocess, 23.5ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 192x640 1 A, 1 E, 2 Gs, 1 1, 1 7, 1 8, 1 9, 27.5ms\n","Speed: 1.4ms preprocess, 27.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 160x640 1 B, 1 N, 1 U, 1 0, 2 1s, 1 5, 1 9, 28.7ms\n","Speed: 2.3ms preprocess, 28.7ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 192x640 1 B, 1 R, 1 X, 1 0, 1 1, 1 4, 1 8, 27.4ms\n","Speed: 2.5ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n","1.0\n"]}]},{"cell_type":"code","source":["#Evaluasi 4, Rotate 7\n","import imutils\n","NewPlate2 = []\n","NewScore2 = []\n","Files2 = []\n","for File, plate , score in zip(Evaluasi3['Files'], Evaluasi3['NewPlate1'], Evaluasi3['NewScore1']):\n","  img = cv2.imread('/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/'+ File)\n","  img = imutils.rotate(img, angle=-7)\n","  img = img_scale_up = cv2.resize(img, (0, 0), fx=1.5, fy=1.5)\n","  # Create the sharpening kernel\n","  kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n","  # Apply the sharpening kernel to the image using filter2D\n","  img = cv2.filter2D(img, -1, kernel)\n","\n","  tab = model.predict(img)\n","  kelas = pd.DataFrame(tab[0].boxes.cls.cpu().numpy()).astype(int)\n","  kelas = kelas.rename(columns={0:'kelas'})\n","  titik = pd.DataFrame(tab[0].boxes.xywhn.cpu().numpy())\n","  titik = titik.rename(columns={0:'x', 1:'y', 2:'w', 3:'h'})\n","  titik= titik.join(kelas).sort_values('x', ascending=True)\n","  plat = titik['kelas'].astype(str).tolist()\n","  plat =  BikinPlat(plat)\n","  val = (validation[validation['File'] == File].Plate).tolist()\n","  val = val[0]\n","  scoreEval = metric(plat,val)\n","  print(scoreEval)\n","  if scoreEval > score:\n","    NewPlate2.append(plat)\n","    NewScore2.append(scoreEval)\n","    Files2.append(File)\n","  else :\n","    NewPlate2.append(plate)\n","    NewScore2.append(score)\n","    Files2.append(File)\n","Files2 = pd.DataFrame(Files2)\n","Files2 = Files2.rename(columns={0:'Files'})\n","\n","NewPlate2 = pd.DataFrame(NewPlate2)\n","NewPlate2 = NewPlate2.rename(columns={0:'NewPlate1'})\n","\n","NewScore2 = pd.DataFrame(NewScore2)\n","NewScore2 = NewScore2.rename(columns={0:'NewScore1'})\n","\n","Evaluasi4 = pd.concat([Files2, NewPlate2, NewScore2], axis= 1)\n"],"metadata":{"id":"iwV8g1-tCB5U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606354544,"user_tz":-420,"elapsed":21642,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"19391b81-6702-4ac5-8b84-497426e9be4d"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 1 E, 1 N, 1 O, 1 0, 1 3, 1 4, 1 7, 30.8ms\n","Speed: 2.0ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 29.9ms\n","Speed: 2.5ms preprocess, 29.9ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.2222222222222222\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 2 Bs, 1 T, 1 1, 1 6, 30.7ms\n","Speed: 2.2ms preprocess, 30.7ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 27.2ms\n","Speed: 2.8ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 384x640 2 As, 1 B, 1 D, 1 3, 1 6, 1 7, 38.1ms\n","Speed: 3.3ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 2 Bs, 1 O, 1 V, 1 1, 1 2, 1 6, 1 7, 29.5ms\n","Speed: 3.1ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["0: 288x640 1 B, 1 F, 1 R, 1 T, 1 0, 1 1, 1 4, 1 6, 37.6ms\n","Speed: 3.0ms preprocess, 37.6ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 160x640 1 B, 1 J, 1 T, 1 W, 1 1, 1 3, 1 5, 1 9, 26.7ms\n","Speed: 3.0ms preprocess, 26.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 D, 1 F, 1 G, 1 R, 1 0, 1 1, 1 2, 1 7, 30.1ms\n","Speed: 4.2ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 256x640 2 Bs, 1 H, 1 Y, 1 1, 1 3, 1 6, 1 7, 29.2ms\n","Speed: 1.7ms preprocess, 29.2ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 224x640 2 Bs, 1 E, 1 I, 1 1, 1 2, 1 6, 1 7, 30.6ms\n","Speed: 1.6ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 2 Ns, 1 W, 1 Z, 1 1, 1 6, 1 7, 1 8, 30.2ms\n","Speed: 3.5ms preprocess, 30.2ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 2 Ss, 1 1, 2 3s, 1 9, 30.5ms\n","Speed: 2.1ms preprocess, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 29.9ms\n","Speed: 3.8ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 1 B, 1 S, 1 T, 1 Z, 1 0, 3 1s, 1 8, 41.2ms\n","Speed: 3.2ms preprocess, 41.2ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["0: 288x640 1 B, 1 J, 1 S, 1 T, 1 1, 2 4s, 1 7, 36.2ms\n","Speed: 2.3ms preprocess, 36.2ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 P, 1 U, 1 1, 1 3, 2 9s, 31.1ms\n","Speed: 2.3ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 224x640 1 B, 1 T, 1 Z, 1 0, 2 1s, 1 2, 1 6, 29.9ms\n","Speed: 1.5ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 J, 1 O, 1 T, 1 1, 1 3, 1 6, 1 7, 30.0ms\n","Speed: 2.2ms preprocess, 30.0ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 O, 1 Q, 1 1, 1 7, 27.6ms\n","Speed: 1.9ms preprocess, 27.6ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 A, 1 B, 1 1, 1 2, 1 3, 1 5, 1 6, 1 8, 37.6ms\n","Speed: 2.3ms preprocess, 37.6ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 224x640 1 B, 1 P, 1 W, 1 Z, 1 1, 1 2, 1 3, 1 6, 31.8ms\n","Speed: 2.3ms preprocess, 31.8ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.3333333333333333\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 24.9ms\n","Speed: 1.9ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 B, 1 J, 1 K, 1 T, 1 1, 27.7ms\n","Speed: 2.7ms preprocess, 27.7ms inference, 2.2ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 2 As, 1 D, 1 O, 2 0s, 1 4, 1 7, 1 8, 24.5ms\n","Speed: 2.1ms preprocess, 24.5ms inference, 1.8ms postprocess per image at shape (1, 3, 160, 640)\n","\n","0: 352x640 1 B, 1 E, 1 G, 1 K, 3 1s, 1 3, 34.9ms\n","Speed: 2.9ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 3, 1 7, 24.9ms\n","Speed: 1.8ms preprocess, 24.9ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 192x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 25.1ms\n","Speed: 4.1ms preprocess, 25.1ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 C, 1 D, 1 0, 1 2, 1 9, 28.2ms\n","Speed: 2.3ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 320x640 1 A, 1 M, 1 Z, 1 1, 1 2, 2 9s, 38.5ms\n","Speed: 2.9ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 224x640 1 B, 1 K, 1 T, 1 X, 2 0s, 1 1, 1 2, 33.0ms\n","Speed: 2.2ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 O, 1 R, 1 T, 1 1, 1 3, 1 4, 1 6, 30.0ms\n","Speed: 2.4ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 J, 1 T, 1 U, 1 0, 1 1, 1 3, 1 9, 27.9ms\n","Speed: 3.2ms preprocess, 27.9ms inference, 2.5ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 A, 1 B, 1 D, 1 1, 1 2, 1 6, 1 8, 37.3ms\n","Speed: 3.6ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 E, 1 F, 1 T, 1 0, 1 1, 1 6, 1 8, 30.2ms\n","Speed: 2.5ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 416x640 1 A, 1 B, 1 F, 1 S, 1 4, 1 6, 1 7, 1 8, 1 9, 45.7ms\n","Speed: 3.0ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 224x640 1 B, 1 F, 1 N, 1 O, 1 1, 1 5, 2 6s, 30.7ms\n","Speed: 1.6ms preprocess, 30.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.4444444444444444\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 J, 1 Q, 1 S, 1 0, 1 1, 1 3, 1 6, 32.5ms\n","Speed: 3.7ms preprocess, 32.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 F, 1 T, 1 X, 1 1, 1 2, 1 4, 1 5, 25.3ms\n","Speed: 2.2ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 224x640 1 B, 1 C, 1 J, 1 Y, 1 0, 1 1, 1 3, 1 8, 27.8ms\n","Speed: 1.1ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 352x640 1 A, 1 B, 1 H, 1 U, 1 2, 1 3, 1 4, 1 9, 33.8ms\n","Speed: 2.7ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 N, 1 U, 1 0, 2 1s, 1 5, 1 9, 24.8ms\n","Speed: 1.9ms preprocess, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["0: 160x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 3, 1 7, 1 8, 23.5ms\n","Speed: 3.4ms preprocess, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 L, 1 U, 1 0, 1 1, 2 2s, 27.9ms\n","Speed: 2.9ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 M, 1 T, 1 W, 1 Z, 1 0, 1 1, 1 2, 1 6, 28.2ms\n","Speed: 2.8ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 P, 1 W, 1 Y, 1 1, 1 2, 1 4, 1 7, 36.3ms\n","Speed: 3.0ms preprocess, 36.3ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 192x640 1 B, 1 I, 1 N, 1 S, 1 V, 1 0, 2 1s, 1 2, 27.3ms\n","Speed: 4.4ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 A, 1 D, 1 E, 1 O, 1 0, 1 3, 1 4, 1 7, 30.9ms\n","Speed: 3.4ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 352x640 1 A, 1 B, 1 C, 1 X, 1 2, 1 3, 1 4, 1 5, 37.2ms\n","Speed: 2.8ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 2 Bs, 1 E, 1 J, 1 1, 1 5, 1 8, 1 9, 30.7ms\n","Speed: 1.9ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 256x640 1 B, 1 J, 1 T, 1 U, 1 1, 1 6, 1 7, 1 8, 30.3ms\n","Speed: 3.2ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 1 F, 1 R, 1 S, 1 1, 1 4, 1 5, 1 9, 29.3ms\n","Speed: 4.4ms preprocess, 29.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 256x640 1 B, 1 E, 1 F, 1 O, 1 1, 1 6, 1 8, 1 9, 31.0ms\n","Speed: 4.2ms preprocess, 31.0ms inference, 4.7ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 192x640 1 B, 1 X, 2 1s, 1 3, 1 7, 27.3ms\n","Speed: 4.7ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 1 B, 1 P, 1 S, 1 W, 1 0, 1 1, 1 2, 1 3, 1 6, 37.3ms\n","Speed: 4.0ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 27.3ms\n","Speed: 1.9ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 2 As, 1 V, 1 0, 1 1, 1 4, 1 8, 26.6ms\n","Speed: 1.6ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 U, 1 Y, 1 1, 1 3, 1 7, 1 8, 26.5ms\n","Speed: 2.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 160x640 1 B, 1 U, 1 0, 1 1, 1 2, 1 6, 1 8, 26.7ms\n","Speed: 1.5ms preprocess, 26.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 2 Bs, 1 H, 1 K, 1 M, 1 1, 2 2s, 1 4, 30.6ms\n","Speed: 2.4ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 320x640 2 As, 1 B, 1 X, 1 1, 1 2, 1 5, 1 7, 1 8, 36.3ms\n","Speed: 3.6ms preprocess, 36.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 288x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 35.8ms\n","Speed: 2.4ms preprocess, 35.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 B, 1 Y, 2 1s, 1 5, 1 7, 35.3ms\n","Speed: 5.5ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n","\n","0: 224x640 1 B, 1 D, 1 F, 1 R, 1 1, 1 2, 2 3s, 30.7ms\n","Speed: 2.9ms preprocess, 30.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 I, 1 N, 1 0, 2 1s, 1 3, 28.1ms\n","Speed: 1.9ms preprocess, 28.1ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 A, 1 D, 1 J, 1 R, 2 9s, 30.1ms\n","Speed: 2.9ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 288x640 1 B, 1 E, 1 S, 1 Y, 1 1, 1 3, 1 6, 1 8, 36.0ms\n","Speed: 2.0ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 2 As, 1 F, 1 Q, 3 0s, 1 4, 1 7, 30.3ms\n","Speed: 3.1ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 160x640 1 B, 2 Ss, 1 W, 2 1s, 1 2, 1 4, 27.2ms\n","Speed: 1.7ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 B, 2 Js, 1 T, 1 1, 1 2, 1 3, 1 6, 30.1ms\n","Speed: 2.7ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 256x640 1 B, 1 E, 1 L, 1 R, 1 0, 1 1, 1 7, 1 9, 29.6ms\n","Speed: 2.5ms preprocess, 29.6ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 J, 1 Q, 1 T, 2 1s, 1 5, 1 8, 27.6ms\n","Speed: 2.6ms preprocess, 27.6ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 288x640 1 B, 1 J, 1 N, 1 U, 1 V, 1 1, 1 3, 1 4, 1 7, 35.8ms\n","Speed: 3.0ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 E, 1 F, 1 Y, 1 1, 1 3, 1 4, 1 7, 27.2ms\n","Speed: 2.3ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 160x640 1 B, 1 O, 1 Q, 1 0, 1 5, 2 7s, 26.6ms\n","Speed: 2.4ms preprocess, 26.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 352x640 2 3s, 37.6ms\n","Speed: 3.1ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 192x640 1 B, 1 F, 1 J, 2 Ts, 1 1, 1 2, 1 3, 1 5, 27.3ms\n","Speed: 2.3ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 256x640 1 B, 1 L, 2 Ss, 2 1s, 1 5, 1 7, 30.0ms\n","Speed: 1.7ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.1111111111111111\n","1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 X, 2 1s, 1 3, 1 7, 28.2ms\n","Speed: 1.8ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 J, 1 S, 1 T, 2 1s, 1 3, 1 6, 31.2ms\n","Speed: 2.6ms preprocess, 31.2ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 192x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 28.4ms\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["Speed: 2.1ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 384x640 1 B, 1 K, 1 N, 1 Y, 1 1, 1 2, 1 3, 1 5, 43.0ms\n","Speed: 3.2ms preprocess, 43.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 2 Us, 1 Y, 2 0s, 1 1, 1 8, 27.2ms\n","Speed: 1.4ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 E, 1 T, 1 V, 3 1s, 1 4, 31.1ms\n","Speed: 1.9ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 352x640 1 B, 1 E, 1 K, 1 X, 1 3, 2 7s, 1 8, 37.6ms\n","Speed: 2.8ms preprocess, 37.6ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 256x640 1 B, 1 D, 1 F, 1 R, 1 1, 2 3s, 1 9, 32.0ms\n","Speed: 1.5ms preprocess, 32.0ms inference, 1.7ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.2222222222222222\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 3, 1 9, 27.3ms\n","Speed: 1.6ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 320x640 1 A, 1 B, 1 H, 1 0, 1 2, 1 5, 1 8, 1 9, 36.6ms\n","Speed: 2.1ms preprocess, 36.6ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 256x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 27.5ms\n","Speed: 2.2ms preprocess, 27.5ms inference, 1.7ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 5, 2 8s, 32.8ms\n","Speed: 2.1ms preprocess, 32.8ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 256x640 1 B, 1 N, 2 Ss, 1 V, 1 1, 1 3, 1 4, 1 6, 31.2ms\n","Speed: 2.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 640)\n","\n","0: 288x640 1 A, 2 Bs, 1 H, 2 1s, 1 3, 1 5, 32.1ms\n","Speed: 4.5ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","0.8888888888888888\n","0.8888888888888888\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 288x640 1 A, 1 B, 2 Us, 1 1, 1 2, 1 6, 1 7, 31.4ms\n","Speed: 3.1ms preprocess, 31.4ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 224x640 1 B, 1 J, 1 T, 1 V, 1 0, 1 1, 1 2, 1 8, 27.6ms\n","Speed: 2.5ms preprocess, 27.6ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n","\n","0: 160x640 2 Bs, 1 R, 1 U, 2 1s, 1 6, 1 9, 24.3ms\n","Speed: 1.2ms preprocess, 24.3ms inference, 1.9ms postprocess per image at shape (1, 3, 160, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 256x640 1 A, 1 B, 1 O, 1 Q, 1 U, 1 2, 1 5, 2 8s, 30.5ms\n","Speed: 2.3ms preprocess, 30.5ms inference, 3.7ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 27.4ms\n","Speed: 2.1ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n","\n","0: 192x640 1 A, 1 E, 2 Gs, 1 1, 1 7, 1 8, 1 9, 26.4ms\n","Speed: 1.6ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 160x640 1 B, 1 N, 1 U, 1 0, 2 1s, 1 5, 1 9, 27.0ms\n","Speed: 2.9ms preprocess, 27.0ms inference, 1.7ms postprocess per image at shape (1, 3, 160, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["0: 192x640 1 B, 1 R, 1 X, 1 0, 1 1, 1 4, 1 8, 27.6ms\n","Speed: 2.9ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1.0\n"]}]},{"cell_type":"code","source":["Evaluasi4"],"metadata":{"id":"HO-vhhhDCBqr","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1692606354545,"user_tz":-420,"elapsed":49,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"e69d3069-4d09-441f-d52d-aebc80bf64fd"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              Files NewPlate1  NewScore1\n","0     DataTest1.png  AD7034OE   1.000000\n","1     DataTest2.png   A9388EX   1.000000\n","2     DataTest3.png     B16TB   1.000000\n","3     DataTest4.png  B1661TKZ   1.000000\n","4     DataTest5.png  AD3772AB   0.888889\n","..              ...       ...        ...\n","95   DataTest96.png   BO885UQ   0.666667\n","96   DataTest97.png  AB8644PK   1.000000\n","97   DataTest98.png  AG9718EG   1.000000\n","98   DataTest99.png   B1509UN   1.000000\n","99  DataTest100.png   B1408RX   1.000000\n","\n","[100 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-9538d6f0-8308-4baa-bb0f-763f1c0fdf9d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Files</th>\n","      <th>NewPlate1</th>\n","      <th>NewScore1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest1.png</td>\n","      <td>AD7034OE</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DataTest2.png</td>\n","      <td>A9388EX</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest3.png</td>\n","      <td>B16TB</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DataTest4.png</td>\n","      <td>B1661TKZ</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DataTest5.png</td>\n","      <td>AD3772AB</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>DataTest96.png</td>\n","      <td>BO885UQ</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>DataTest97.png</td>\n","      <td>AB8644PK</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>DataTest98.png</td>\n","      <td>AG9718EG</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>DataTest99.png</td>\n","      <td>B1509UN</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>DataTest100.png</td>\n","      <td>B1408RX</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9538d6f0-8308-4baa-bb0f-763f1c0fdf9d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9538d6f0-8308-4baa-bb0f-763f1c0fdf9d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9538d6f0-8308-4baa-bb0f-763f1c0fdf9d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a3c3aa73-0c01-4016-8f4d-7a0cf6a81dac\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3c3aa73-0c01-4016-8f4d-7a0cf6a81dac')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a3c3aa73-0c01-4016-8f4d-7a0cf6a81dac button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["##Terdapat Plat Nomor yang tidak sesuai aturan, yaitu memiliki jumlah digit numerik lebih dari 4 digit, oleh karena itu dilkaukan penghapusan\n","Evaluasi5 = []\n","for i in range(len(Evaluasi4['NewPlate1'])):\n","  after=RemoveDigit(Evaluasi4['NewPlate1'].values[i])\n","  Evaluasi5.append(after)"],"metadata":{"id":"6ZNpc1yUDPyL","executionInfo":{"status":"ok","timestamp":1692606354545,"user_tz":-420,"elapsed":45,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["Evaluasi5 = pd.DataFrame(Evaluasi5)\n","Evaluasi5= Evaluasi5.rename(columns={0:'Plate'})\n","\n","y_true = validation['Plate']\n","y_predd = Evaluasi5['Plate']\n","scores=[]\n","for y_pred, y_true in zip(y_predd, y_true):\n","  score = metric(y_pred,y_true)\n","  scores.append(score)"],"metadata":{"id":"js5kVKhQD4u3","executionInfo":{"status":"ok","timestamp":1692606354546,"user_tz":-420,"elapsed":45,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["np.mean(scores)*100"],"metadata":{"id":"hv2Jx_4oEBP5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606354547,"user_tz":-420,"elapsed":45,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"deaddc18-6860-4cc3-a640-6001eb9befc9"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["95.88888888888889"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["submission_fiks= pd.concat([Evaluasi4['Files'], Evaluasi5['Plate']], axis = 1)\n","submission_fiks.reset_index(drop=True, inplace=True)\n","submission_fiks"],"metadata":{"id":"zkApheohEVkk","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1692606354547,"user_tz":-420,"elapsed":35,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"455c4e5d-5b13-453a-c741-c3e6aa8ff459"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              Files     Plate\n","0     DataTest1.png  AD7034OE\n","1     DataTest2.png   A9388EX\n","2     DataTest3.png     B16TB\n","3     DataTest4.png  B1661TKZ\n","4     DataTest5.png  AD3772AB\n","..              ...       ...\n","95   DataTest96.png   BO885UQ\n","96   DataTest97.png  AB8644PK\n","97   DataTest98.png  AG9718EG\n","98   DataTest99.png   B1509UN\n","99  DataTest100.png   B1408RX\n","\n","[100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-473da10f-e34f-483a-9c73-720e48e7cca3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Files</th>\n","      <th>Plate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest1.png</td>\n","      <td>AD7034OE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DataTest2.png</td>\n","      <td>A9388EX</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest3.png</td>\n","      <td>B16TB</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DataTest4.png</td>\n","      <td>B1661TKZ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DataTest5.png</td>\n","      <td>AD3772AB</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>DataTest96.png</td>\n","      <td>BO885UQ</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>DataTest97.png</td>\n","      <td>AB8644PK</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>DataTest98.png</td>\n","      <td>AG9718EG</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>DataTest99.png</td>\n","      <td>B1509UN</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>DataTest100.png</td>\n","      <td>B1408RX</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-473da10f-e34f-483a-9c73-720e48e7cca3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-473da10f-e34f-483a-9c73-720e48e7cca3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-473da10f-e34f-483a-9c73-720e48e7cca3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b85bb30e-cea4-480e-a37e-f85e081273ca\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b85bb30e-cea4-480e-a37e-f85e081273ca')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b85bb30e-cea4-480e-a37e-f85e081273ca button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["submission_fiks['score']= scores"],"metadata":{"id":"OAVyI4fcotYZ","executionInfo":{"status":"ok","timestamp":1692606354548,"user_tz":-420,"elapsed":33,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["data_test = submission_fiks[submission_fiks.score < 1.0]\n","Folder_test = '/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/'\n","path_test = Folder_test+data_test['Files']"],"metadata":{"id":"s60KFCBdoyaK","executionInfo":{"status":"ok","timestamp":1692606354549,"user_tz":-420,"elapsed":33,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["data_test.shape"],"metadata":{"id":"06UXFFaccqzC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606354550,"user_tz":-420,"elapsed":34,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"4fba1315-ec67-469f-a465-84363caf82be"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(16, 3)"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["''' #FINE TUNNING MODEL YOLOV5l\n","\n","    model = YOLO('/content/drive/MyDrive/BDC/best_v5l.pt')\n","    result= model.train(\n","    data='data.yaml',\n","    task= 'detect',\n","    mode='train',\n","    epochs=100,\n","    imgsz=640,\n","    batch=8,\n","    optimizer='Adam',\n","    fliplr = 0.0\n","    )\n","\n","    '''"],"metadata":{"id":"tJlWbbKu09ol","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1692606354552,"user_tz":-420,"elapsed":25,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"3a5d395a-0125-4493-dfb5-438a53636de2"},"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" #FINE TUNNING MODEL YOLOV5l\\n\\n    model = YOLO('/content/drive/MyDrive/BDC/best_v5l.pt')\\n    result= model.train(\\n    data='data.yaml',\\n    task= 'detect',\\n    mode='train',\\n    epochs=100,\\n    imgsz=640,\\n    batch=8,\\n    optimizer='Adam',\\n    fliplr = 0.0\\n    )\\n\\n    \""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["model = YOLO('/content/drive/MyDrive/BDC/runs/detect/train14/weights/best.pt')\n"],"metadata":{"id":"hO_tPjhPEk9o","executionInfo":{"status":"ok","timestamp":1692606355030,"user_tz":-420,"elapsed":502,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["path_test.reset_index(drop=True, inplace=True)\n","path_test= pd.DataFrame(path_test)\n","path_test"],"metadata":{"id":"waAxYoSAF6At","colab":{"base_uri":"https://localhost:8080/","height":551},"executionInfo":{"status":"ok","timestamp":1692606355030,"user_tz":-420,"elapsed":8,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"1f534d74-60a1-4dc9-eff7-34c6c14c9a8c"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Files\n","0   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","1   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","2   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","3   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","4   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","5   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","6   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","7   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","8   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","9   /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","10  /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","11  /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","12  /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","13  /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","14  /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...\n","15  /content/drive/MyDrive/BDC/GFPGAN/hasil1/resto..."],"text/html":["\n","  <div id=\"df-ddc6b1b4-d5c3-4fb6-adb2-04a97eb9dbdb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Files</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>/content/drive/MyDrive/BDC/GFPGAN/hasil1/resto...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddc6b1b4-d5c3-4fb6-adb2-04a97eb9dbdb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ddc6b1b4-d5c3-4fb6-adb2-04a97eb9dbdb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ddc6b1b4-d5c3-4fb6-adb2-04a97eb9dbdb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6c0fa2c8-9476-46f9-b34d-939941d3b3e1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c0fa2c8-9476-46f9-b34d-939941d3b3e1')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6c0fa2c8-9476-46f9-b34d-939941d3b3e1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["platt= []\n","scores=[]\n","File = []\n","for i, j in zip(path_test['Files'], data_test['Files']):\n","  tab = model.predict(i, conf = 0.4, iou= 0.1)\n","  kelas = pd.DataFrame(tab[0].boxes.cls.cpu().numpy()).astype(int)\n","  kelas = kelas.rename(columns={0:'kelas'})\n","  titik = pd.DataFrame(tab[0].boxes.xywhn.cpu().numpy())\n","  titik = titik.rename(columns={0:'x', 1:'y', 2:'w', 3:'h'})\n","  titik= titik.join(kelas).sort_values('x', ascending=True)\n","  plat = titik['kelas'].astype(str).tolist()\n","  plat =  BikinPlat(plat)\n","  platt.append(plat)\n","  val = (validation[validation['File'] == j].Plate).tolist()\n","  val = val[0]\n","  scoreEval = metric(plat,val)\n","  scores.append(scoreEval)\n","  File.append(j)\n","  print(i, j)"],"metadata":{"id":"3Da2__T6FIMS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606357121,"user_tz":-420,"elapsed":2097,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"c18de0a9-1439-4480-b5b8-c93d53dfa7e2"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest5.png: 384x640 1 A, 1 B, 1 D, 1 2, 1 3, 3 7s, 37.4ms\n","Speed: 1.6ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest6.png: 192x640 1 B, 1 O, 1 Y, 3 7s, 25.6ms\n","Speed: 1.3ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest5.png DataTest5.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest6.png DataTest6.png\n"]},{"output_type":"stream","name":"stderr","text":["image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest12.png: 224x640 1 B, 1 M, 1 W, 1 Z, 1 1, 1 6, 1 7, 1 8, 28.7ms\n","Speed: 1.5ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest15.png: 352x640 1 B, 1 S, 1 T, 1 Z, 1 0, 2 1s, 1 8, 34.8ms\n","Speed: 1.8ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest21.png: 352x640 1 A, 1 B, 33.9ms\n","Speed: 1.4ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest22.png: 224x640 1 B, 1 K, 1 P, 1 Z, 1 1, 1 2, 1 3, 1 6, 28.4ms\n","Speed: 1.3ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest12.png DataTest12.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest15.png DataTest15.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest21.png DataTest21.png\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest22.png DataTest22.png\n"]},{"output_type":"stream","name":"stderr","text":["image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest29.png: 192x640 1 A, 1 B, 1 C, 1 D, 1 0, 1 2, 25.0ms\n","Speed: 1.6ms preprocess, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest36.png: 416x640 1 A, 1 B, 1 F, 1 S, 1 4, 1 7, 1 8, 1 9, 41.7ms\n","Speed: 1.9ms preprocess, 41.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest29.png DataTest29.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest36.png DataTest36.png\n"]},{"output_type":"stream","name":"stderr","text":["image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest55.png: 352x640 1 B, 1 P, 1 S, 1 W, 1 0, 1 1, 1 3, 1 6, 34.7ms\n","Speed: 2.5ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest59.png: 160x640 1 B, 1 U, 1 0, 1 1, 1 2, 1 8, 24.4ms\n","Speed: 1.1ms preprocess, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest60.png: 224x640 2 Bs, 1 F, 1 K, 1 M, 1 1, 2 2s, 1 4, 28.3ms\n","Speed: 1.3ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest55.png DataTest55.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest59.png DataTest59.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest60.png DataTest60.png\n"]},{"output_type":"stream","name":"stderr","text":["image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest76.png: 352x640 1 N, 3 3s, 1 7, 34.3ms\n","Speed: 1.5ms preprocess, 34.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest85.png: 352x640 1 A, 1 B, 1 E, 1 K, 1 3, 2 7s, 1 8, 33.8ms\n","Speed: 1.7ms preprocess, 33.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest86.png: 256x640 1 F, 1 R, 1 0, 1 1, 3 3s, 1 5, 1 9, 27.9ms\n","Speed: 1.1ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 256, 640)\n","\n","image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest92.png: 288x640 1 A, 1 B, 1 N, 1 O, 2 1s, 1 3, 1 5, 24.1ms\n","Speed: 1.2ms preprocess, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n","\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest76.png DataTest76.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest85.png DataTest85.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest86.png DataTest86.png\n","/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest92.png DataTest92.png\n"]},{"output_type":"stream","name":"stderr","text":["image 1/1 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest96.png: 256x640 1 B, 1 L, 1 2, 1 5, 1 8, 20.1ms\n","Speed: 1.6ms preprocess, 20.1ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 640)\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest96.png DataTest96.png\n"]}]},{"cell_type":"code","source":["File = pd.DataFrame(File)\n","File = File.rename(columns={0:'File'})\n","platt = pd.DataFrame(platt)\n","platt = platt.rename(columns={0:'Plate'})\n","scores = pd.DataFrame(scores)\n","scores = scores.rename(columns={0:'score'})\n","evaluasi6= pd.concat([File,platt,scores], axis= 1)"],"metadata":{"id":"OaWkSYgOGbAD","executionInfo":{"status":"ok","timestamp":1692606357475,"user_tz":-420,"elapsed":359,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["evaluasi6.shape"],"metadata":{"id":"oiRJN1wJZt5L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606357477,"user_tz":-420,"elapsed":46,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"49a87f50-d942-4375-a4be-0ae84f4fbc8c"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(16, 3)"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["evaluasi6"],"metadata":{"id":"JgWScbYJHTIA","colab":{"base_uri":"https://localhost:8080/","height":551},"executionInfo":{"status":"ok","timestamp":1692606357479,"user_tz":-420,"elapsed":47,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"2278dc1d-43bd-4093-afd9-75a2baf41931"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              File     Plate     score\n","0    DataTest5.png  7D3772AB  0.777778\n","1    DataTest6.png    B777OY  0.444444\n","2   DataTest12.png  B1678WZM  1.000000\n","3   DataTest15.png  B1801TZS  1.000000\n","4   DataTest21.png        AB  0.333333\n","5   DataTest22.png  B1236PZK  0.888889\n","6   DataTest29.png    AD20CB  0.333333\n","7   DataTest36.png  A8B749FS  0.444444\n","8   DataTest55.png  B1063SPW  1.000000\n","9   DataTest59.png    B1820U  0.777778\n","10  DataTest60.png  B1422BKM  0.888889\n","11  DataTest76.png     3337N  0.111111\n","12  DataTest85.png  AB3787KE  1.000000\n","13  DataTest86.png  313395RF  0.444444\n","14  DataTest92.png  AB3511ON  0.888889\n","15  DataTest96.png     B285L  0.333333"],"text/html":["\n","  <div id=\"df-1ed76d69-6838-4d92-befb-e2552b463148\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File</th>\n","      <th>Plate</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest5.png</td>\n","      <td>7D3772AB</td>\n","      <td>0.777778</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DataTest6.png</td>\n","      <td>B777OY</td>\n","      <td>0.444444</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest12.png</td>\n","      <td>B1678WZM</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DataTest15.png</td>\n","      <td>B1801TZS</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DataTest21.png</td>\n","      <td>AB</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>DataTest22.png</td>\n","      <td>B1236PZK</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>DataTest29.png</td>\n","      <td>AD20CB</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>DataTest36.png</td>\n","      <td>A8B749FS</td>\n","      <td>0.444444</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>DataTest55.png</td>\n","      <td>B1063SPW</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>DataTest59.png</td>\n","      <td>B1820U</td>\n","      <td>0.777778</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>DataTest60.png</td>\n","      <td>B1422BKM</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>DataTest76.png</td>\n","      <td>3337N</td>\n","      <td>0.111111</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>DataTest85.png</td>\n","      <td>AB3787KE</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>DataTest86.png</td>\n","      <td>313395RF</td>\n","      <td>0.444444</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>DataTest92.png</td>\n","      <td>AB3511ON</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>DataTest96.png</td>\n","      <td>B285L</td>\n","      <td>0.333333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ed76d69-6838-4d92-befb-e2552b463148')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1ed76d69-6838-4d92-befb-e2552b463148 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1ed76d69-6838-4d92-befb-e2552b463148');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1f1946d3-6de6-435b-bc51-150d6d26cf63\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f1946d3-6de6-435b-bc51-150d6d26cf63')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1f1946d3-6de6-435b-bc51-150d6d26cf63 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["Files = []\n","PlatBaru = []\n","scoreAkhir = []\n","\n","for File, platN, scoreN, platO, scoreO in zip(data_test['Files'],evaluasi6['Plate'], evaluasi6['score'], data_test['Plate'], data_test['score'] ):\n","  if scoreN >= scoreO:\n","    Files.append(File)\n","    PlatBaru.append(platN)\n","    scoreAkhir.append(scoreN)\n","  else:\n","    Files.append(File)\n","    PlatBaru.append(platO)\n","    scoreAkhir.append(scoreO)\n","Files = pd.DataFrame(Files)\n","Files = Files.rename(columns={0:'File'})\n","\n","PlatBaru = pd.DataFrame(PlatBaru)\n","PlatBaru = PlatBaru.rename(columns={0:'Plate'})\n","\n","scoreAkhir = pd.DataFrame(scoreAkhir)\n","scoreAkhir = scoreAkhir.rename(columns={0:'score'})\n","dataFinal = pd.concat([Files, PlatBaru, scoreAkhir], axis = 1)"],"metadata":{"id":"Sz5GQ_z8L_Zg","executionInfo":{"status":"ok","timestamp":1692606357480,"user_tz":-420,"elapsed":47,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["dataFinal = dataFinal.rename(columns={'File':'Files'})"],"metadata":{"id":"j1iqBJR-ejZC","executionInfo":{"status":"ok","timestamp":1692606357484,"user_tz":-420,"elapsed":51,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["check = submission_fiks.copy()\n","check = check.drop(check[check['score']<1.0].index)"],"metadata":{"id":"Xh0zdX0NXe--","executionInfo":{"status":"ok","timestamp":1692606357485,"user_tz":-420,"elapsed":52,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["check.shape"],"metadata":{"id":"3rO-W8z4YEUl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606357485,"user_tz":-420,"elapsed":52,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"b95e01a3-3d99-430c-b29f-350bc99521e8"},"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(84, 3)"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["\n","check = pd.concat([check,dataFinal], axis=0)\n","check.shape"],"metadata":{"id":"wVjjEpYkXq--","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606357486,"user_tz":-420,"elapsed":50,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"3afda0bd-d2a8-4b87-febc-408dc7802bda"},"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 3)"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["check"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"k1UuxGdcl0Pk","executionInfo":{"status":"ok","timestamp":1692606357487,"user_tz":-420,"elapsed":50,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"c472fe45-ba54-41c2-dde7-cf897b945a61"},"execution_count":104,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             Files     Plate     score\n","0    DataTest1.png  AD7034OE  1.000000\n","1    DataTest2.png   A9388EX  1.000000\n","2    DataTest3.png     B16TB  1.000000\n","3    DataTest4.png  B1661TKZ  1.000000\n","6    DataTest7.png  B1064TFR  1.000000\n","..             ...       ...       ...\n","11  DataTest76.png  ATA2933I  0.333333\n","12  DataTest85.png  AB3787KE  1.000000\n","13  DataTest86.png  B1339RFD  0.888889\n","14  DataTest92.png  AB3511ON  0.888889\n","15  DataTest96.png   BO885UQ  0.666667\n","\n","[100 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-264120a4-1932-439e-a667-fbc770eed48b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Files</th>\n","      <th>Plate</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest1.png</td>\n","      <td>AD7034OE</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DataTest2.png</td>\n","      <td>A9388EX</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest3.png</td>\n","      <td>B16TB</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DataTest4.png</td>\n","      <td>B1661TKZ</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>DataTest7.png</td>\n","      <td>B1064TFR</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>DataTest76.png</td>\n","      <td>ATA2933I</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>DataTest85.png</td>\n","      <td>AB3787KE</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>DataTest86.png</td>\n","      <td>B1339RFD</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>DataTest92.png</td>\n","      <td>AB3511ON</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>DataTest96.png</td>\n","      <td>BO885UQ</td>\n","      <td>0.666667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-264120a4-1932-439e-a667-fbc770eed48b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-264120a4-1932-439e-a667-fbc770eed48b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-264120a4-1932-439e-a667-fbc770eed48b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9e97949a-366c-415e-93a0-e45ad7443067\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e97949a-366c-415e-93a0-e45ad7443067')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9e97949a-366c-415e-93a0-e45ad7443067 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["check = check.iloc[check['Files'].map(natural_sort_key).argsort()]\n","check = check.reset_index(drop=True)"],"metadata":{"id":"QuR7Jh59YhEh","executionInfo":{"status":"ok","timestamp":1692606357488,"user_tz":-420,"elapsed":47,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["y_true = validation['Plate']\n","y_prediksi = check['Plate']\n","scores=[]\n","for y_pred, y_true in zip(y_prediksi, y_true):\n","  score = metric(y_pred,y_true)\n","  scores.append(score)"],"metadata":{"id":"KhSA6NyfYsrD","executionInfo":{"status":"ok","timestamp":1692606357488,"user_tz":-420,"elapsed":46,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["np.mean(scores)*100 , len(scores)"],"metadata":{"id":"djNYTkLjfBm2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606357489,"user_tz":-420,"elapsed":46,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"218751f1-9c5e-47d6-d995-f51155a98e42"},"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(96.88888888888889, 100)"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["fiks = []\n","Files = []\n","for i, j in zip(check['Files'], check['Plate']):\n","  fiks.append(RemoveDigit(j))\n","  Files.append(i)"],"metadata":{"id":"sCkFDULjkd80","executionInfo":{"status":"ok","timestamp":1692606357490,"user_tz":-420,"elapsed":45,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["scores=[]\n","y_true = validation['Plate']\n","for y_pred, y_true in zip(fiks, y_true):\n","  score = metric(y_pred,y_true)\n","  scores.append(score)"],"metadata":{"id":"InZFIQ2clR0Z","executionInfo":{"status":"ok","timestamp":1692606357491,"user_tz":-420,"elapsed":45,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["len(scores), np.mean(scores)*100"],"metadata":{"id":"t5E3xR3tlbxL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606357492,"user_tz":-420,"elapsed":46,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"f91f0182-85e2-45bc-940d-c82be58b411e"},"execution_count":110,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 96.88888888888889)"]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["check['afterRemove']= fiks"],"metadata":{"id":"EZCN6a7-Z4ZI","executionInfo":{"status":"ok","timestamp":1692606357493,"user_tz":-420,"elapsed":45,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["data = pd.DataFrame()\n","data['Files'] = check['Files']\n","data['Plate'] = pd.DataFrame(fiks)\n","data['score'] = pd.DataFrame(scores)"],"metadata":{"id":"nIiZGUOtlrQ7","executionInfo":{"status":"ok","timestamp":1692606357494,"user_tz":-420,"elapsed":46,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["hasil_filter = []\n","File = []\n","\n","for i, j in zip(data['Files'], data['Plate']):\n","  hasil_filter.append(AturanPlat(CheckKarakter(j)))\n","  File.append(i)\n","\n","df1 = pd.DataFrame()\n","df1['Plate']= pd.DataFrame(hasil_filter)\n","df1['Files'] = pd.DataFrame(File)"],"metadata":{"id":"4s0pRFjebLvz","executionInfo":{"status":"ok","timestamp":1692606357495,"user_tz":-420,"elapsed":47,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["hasil_filter = []\n","File = []\n","\n","for i, j in zip(data['Files'], data['Plate']):\n","  hasil_filter.append(AturanPlat(CheckKarakter(j)))\n","  File.append(i)\n","\n","df = pd.DataFrame()\n","df['Plate']= pd.DataFrame(hasil_filter)\n","df['Files'] = pd.DataFrame(File)"],"metadata":{"id":"1Rh39PRjsZH7","executionInfo":{"status":"ok","timestamp":1692606357496,"user_tz":-420,"elapsed":47,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["df['Banding']= validation['Plate']"],"metadata":{"id":"gw1B9VBzxxcZ","executionInfo":{"status":"ok","timestamp":1692606357496,"user_tz":-420,"elapsed":47,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["submit = pd.DataFrame()\n","submit['Name of File'] = df['Files']\n","submit['Vehicleregistrationplatebymodel'] = df['Plate']\n","submit"],"metadata":{"id":"vfUSY9tlAdmV","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1692606357497,"user_tz":-420,"elapsed":48,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"a7425b9c-d3c2-45c0-c852-5328819d1bd6"},"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Name of File Vehicleregistrationplatebymodel\n","0     DataTest1.png                        AD7034OE\n","1     DataTest2.png                         A9388EX\n","2     DataTest3.png                           B16TB\n","3     DataTest4.png                        B1661TKZ\n","4     DataTest5.png                       AD3772ABE\n","..              ...                             ...\n","95   DataTest96.png                         BO885UQ\n","96   DataTest97.png                        AB8644PK\n","97   DataTest98.png                        AG9718EG\n","98   DataTest99.png                         B1509UN\n","99  DataTest100.png                         B1408RX\n","\n","[100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-0b63a757-2524-466f-a4d1-2a9fd9642e80\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name of File</th>\n","      <th>Vehicleregistrationplatebymodel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest1.png</td>\n","      <td>AD7034OE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DataTest2.png</td>\n","      <td>A9388EX</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest3.png</td>\n","      <td>B16TB</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DataTest4.png</td>\n","      <td>B1661TKZ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DataTest5.png</td>\n","      <td>AD3772ABE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>DataTest96.png</td>\n","      <td>BO885UQ</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>DataTest97.png</td>\n","      <td>AB8644PK</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>DataTest98.png</td>\n","      <td>AG9718EG</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>DataTest99.png</td>\n","      <td>B1509UN</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>DataTest100.png</td>\n","      <td>B1408RX</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b63a757-2524-466f-a4d1-2a9fd9642e80')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0b63a757-2524-466f-a4d1-2a9fd9642e80 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0b63a757-2524-466f-a4d1-2a9fd9642e80');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-63cc528f-0498-47fe-b10b-7a8b45d6b943\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63cc528f-0498-47fe-b10b-7a8b45d6b943')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-63cc528f-0498-47fe-b10b-7a8b45d6b943 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","source":["scores=[]\n","y_true = validation['Plate']\n","for y_pred, y_true in zip(submit['Vehicleregistrationplatebymodel'], df['Banding']):\n","  score = metric(y_pred,y_true)\n","  scores.append(score)\n","len(scores), np.mean(scores)"],"metadata":{"id":"Vw8mNvZWxxRq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606357497,"user_tz":-420,"elapsed":47,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"dcff4cfa-daa8-47fa-f9e5-5fa189c1c578"},"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 0.9788888888888888)"]},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["model = YOLO('/content/drive/MyDrive/BDC/best_v5l.pt')\n","folder = '/content/drive/MyDrive/BDC/Datatest/'\n","for i, j in zip(submit['Name of File'], submit.Vehicleregistrationplatebymodel):\n","  if len(j) < 3:\n","    path = folder+i\n","    tab = model.predict(source = folder, conf= 0.337, iou= 0.05)"],"metadata":{"id":"8qJT6aXfqpK0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692606358511,"user_tz":-420,"elapsed":1059,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"792bdf80-d82b-4b89-e6b3-e80352abd44a"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/drive/MyDrive/BDC/Datatest/DataTest21.png: 352x640 1 A, 1 B, 1 1, 1 2, 1 3, 1 6, 1 8, 24.5ms\n","Speed: 1.6ms preprocess, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"]}]},{"cell_type":"code","source":["names = model.names\n","result = tab[0].cpu().numpy()\n","class_names = []\n","result_boxes = []\n","\n","for box in result.boxes:\n","  class_names.append(names[int(box.cls)])\n","  result_boxes.append(box.xyxy[0])\n","\n","pd_box = pd.DataFrame(result_boxes)\n","pd_box.columns = ['xmin', 'ymin', 'xmax', 'ymax']\n","pd_box['class'] = class_names\n","pd_box['conf'] = result.boxes.conf\n","pd_box = pd_box.sort_values('xmin')\n","plat = \"\"\n","for i, row in pd_box.iterrows():\n","  plat += row[\"class\"]"],"metadata":{"id":"LXVj_9d6nvW-","executionInfo":{"status":"ok","timestamp":1692606358512,"user_tz":-420,"elapsed":18,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["submit.loc[submit.Vehicleregistrationplatebymodel == \"AB\", \"Vehicleregistrationplatebymodel\"] = plat"],"metadata":{"id":"hsqpIz39EYF_","executionInfo":{"status":"ok","timestamp":1692606358513,"user_tz":-420,"elapsed":19,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["hasil_Akhir = []\n","File = []\n","\n","for i, j in zip(submit['Name of File'], submit['Vehicleregistrationplatebymodel']):\n","  hasil_Akhir.append(CheckKarakter(AturanPlat(j)))\n","  File.append(i)\n","submission_file = {\"Name of File\": File ,\n","                   \"Vehicleregistrationplatebymodel\": hasil_Akhir }\n","submission = pd.DataFrame(submission_file)"],"metadata":{"id":"Okry55yNFp3E","executionInfo":{"status":"ok","timestamp":1692606358514,"user_tz":-420,"elapsed":20,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["scores=[]\n","for y_pred, y_true in zip(submission.Vehicleregistrationplatebymodel, validation['Plate']):\n","  score = metric(y_pred,y_true)\n","  scores.append(score)\n","len(scores), np.mean(scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSoIWAmGGKvu","executionInfo":{"status":"ok","timestamp":1692606358515,"user_tz":-420,"elapsed":20,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"3bbb52dc-a079-46a7-9418-8493f2353377"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 0.9844444444444446)"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["submission"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"JIJQiHICnrWa","executionInfo":{"status":"ok","timestamp":1692606358516,"user_tz":-420,"elapsed":19,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"25aa8904-f28b-4abd-9c1e-16681b52a661"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Name of File Vehicleregistrationplatebymodel\n","0     DataTest1.png                        AD7034OE\n","1     DataTest2.png                         A9388EX\n","2     DataTest3.png                           B16TB\n","3     DataTest4.png                        B1661TKZ\n","4     DataTest5.png                       AD3772ABE\n","..              ...                             ...\n","95   DataTest96.png                         BO885UQ\n","96   DataTest97.png                        AB8644PK\n","97   DataTest98.png                        AG9718EG\n","98   DataTest99.png                         B1509UN\n","99  DataTest100.png                         B1408RX\n","\n","[100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-de23c10e-98e0-4eac-9d09-54492aaba25a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name of File</th>\n","      <th>Vehicleregistrationplatebymodel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest1.png</td>\n","      <td>AD7034OE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DataTest2.png</td>\n","      <td>A9388EX</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest3.png</td>\n","      <td>B16TB</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DataTest4.png</td>\n","      <td>B1661TKZ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DataTest5.png</td>\n","      <td>AD3772ABE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>DataTest96.png</td>\n","      <td>BO885UQ</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>DataTest97.png</td>\n","      <td>AB8644PK</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>DataTest98.png</td>\n","      <td>AG9718EG</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>DataTest99.png</td>\n","      <td>B1509UN</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>DataTest100.png</td>\n","      <td>B1408RX</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de23c10e-98e0-4eac-9d09-54492aaba25a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-de23c10e-98e0-4eac-9d09-54492aaba25a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-de23c10e-98e0-4eac-9d09-54492aaba25a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cb91cb20-34b2-4065-8334-9569c2fabb59\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb91cb20-34b2-4065-8334-9569c2fabb59')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cb91cb20-34b2-4065-8334-9569c2fabb59 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":123}]},{"cell_type":"markdown","metadata":{"id":"ePmGrMwpx91R"},"source":["##Eksport CSV"]},{"cell_type":"code","execution_count":124,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1692606358518,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"92k_S8yWyA8-","outputId":"49004138-3679-46cd-e5e4-ecd005f8a789"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_435f5f02-702d-4f25-9cc3-33a845f8e477\", \"submission.csv\", 2400)"]},"metadata":{}}],"source":["submission.to_csv('submission.csv', index=False)\n","files.download('submission.csv')"]},{"cell_type":"markdown","source":["#Tidak digunakan"],"metadata":{"id":"Rsem-U1mA_qw"}},{"cell_type":"markdown","metadata":{"id":"aE7Zof5rPu8k"},"source":["##Image Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25851,"status":"ok","timestamp":1688804799838,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"MrZX8xonzgCE","outputId":"2b8157b0-2133-4533-972f-179a0ca30906"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'GFPGAN'...\n","remote: Enumerating objects: 523, done.\u001b[K\n","remote: Total 523 (delta 0), reused 0 (delta 0), pack-reused 523\u001b[K\n","Receiving objects: 100% (523/523), 5.39 MiB | 29.22 MiB/s, done.\n","Resolving deltas: 100% (264/264), done.\n","/content/GFPGAN\n","Requirement already satisfied: basicsr in /usr/local/lib/python3.10/dist-packages (1.4.2)\n","Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.18.3)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.4.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.22.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from basicsr) (4.7.0.72)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr) (8.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.27.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.19.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.10.1)\n","Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.14.0a20230707)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.15.2+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from basicsr) (4.65.0)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.40.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->basicsr) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->basicsr) (16.0.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (3.4)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (23.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.56.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (2.3.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (0.40.0)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (6.8.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (3.7.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (2.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly->basicsr) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->basicsr) (3.15.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->basicsr) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly->basicsr) (3.2.2)\n","Requirement already satisfied: facexlib in /usr/local/lib/python3.10/dist-packages (0.3.0)\n","Requirement already satisfied: filterpy in /usr/local/lib/python3.10/dist-packages (from facexlib) (1.4.5)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib) (0.56.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facexlib) (1.22.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from facexlib) (4.7.0.72)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from facexlib) (8.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from facexlib) (1.10.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from facexlib) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facexlib) (0.15.2+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from facexlib) (4.65.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib) (3.7.1)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->facexlib) (67.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->facexlib) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->facexlib) (16.0.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->facexlib) (2.27.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->facexlib) (2.1.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->facexlib) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->facexlib) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->facexlib) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->facexlib) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->facexlib) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy->facexlib) (1.16.0)\n","Requirement already satisfied: basicsr>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.4.2)\n","Requirement already satisfied: facexlib>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.3.0)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.22.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.7.0.72)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (6.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.10.1)\n","Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.14.0a20230707)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.15.2+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.65.0)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.40.1)\n","Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->-r requirements.txt (line 1)) (2.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->-r requirements.txt (line 1)) (0.18.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->-r requirements.txt (line 1)) (8.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->-r requirements.txt (line 1)) (2.27.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->-r requirements.txt (line 1)) (0.19.3)\n","Requirement already satisfied: filterpy in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->-r requirements.txt (line 2)) (1.4.5)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->-r requirements.txt (line 2)) (0.56.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (1.56.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (2.3.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->-r requirements.txt (line 8)) (0.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 9)) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 9)) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 9)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 9)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 9)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 9)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->-r requirements.txt (line 9)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->-r requirements.txt (line 9)) (16.0.6)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->-r requirements.txt (line 12)) (6.8.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->-r requirements.txt (line 12)) (3.7.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->-r requirements.txt (line 12)) (2.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 8)) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 8)) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 8)) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 8)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly->-r requirements.txt (line 8)) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->-r requirements.txt (line 12)) (3.15.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->-r requirements.txt (line 1)) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->-r requirements.txt (line 1)) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->-r requirements.txt (line 1)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->-r requirements.txt (line 1)) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->-r requirements.txt (line 8)) (2.1.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib>=0.2.5->-r requirements.txt (line 2)) (3.7.1)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.5->-r requirements.txt (line 2)) (0.39.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->-r requirements.txt (line 1)) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->-r requirements.txt (line 1)) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->-r requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->-r requirements.txt (line 1)) (23.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->-r requirements.txt (line 9)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 8)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly->-r requirements.txt (line 8)) (3.2.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 2)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 2)) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 2)) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 2)) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 2)) (2.8.2)\n","/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Requirements should be satisfied by a PEP 517 installer.\n","        If you are using pip, you can try `pip install --use-pep517`.\n","        ********************************************************************************\n","\n","!!\n","  dist.fetch_build_eggs(dist.setup_requires)\n","running develop\n","/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` and ``easy_install``.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://github.com/pypa/setuptools/issues/917 for details.\n","        ********************************************************************************\n","\n","!!\n","  easy_install.initialize_options(self)\n","/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` directly.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n","        ********************************************************************************\n","\n","!!\n","  self.initialize_options()\n","running egg_info\n","creating gfpgan.egg-info\n","writing gfpgan.egg-info/PKG-INFO\n","writing dependency_links to gfpgan.egg-info/dependency_links.txt\n","writing requirements to gfpgan.egg-info/requires.txt\n","writing top-level names to gfpgan.egg-info/top_level.txt\n","writing manifest file 'gfpgan.egg-info/SOURCES.txt'\n","reading manifest file 'gfpgan.egg-info/SOURCES.txt'\n","reading manifest template 'MANIFEST.in'\n","warning: no files found matching 'inputs/*'\n","adding license file 'LICENSE'\n","writing manifest file 'gfpgan.egg-info/SOURCES.txt'\n","running build_ext\n","Creating /usr/local/lib/python3.10/dist-packages/gfpgan.egg-link (link to .)\n","Adding gfpgan 1.3.8 to easy-install.pth file\n","\n","Installed /content/GFPGAN\n","Processing dependencies for gfpgan==1.3.8\n","Searching for yapf==0.40.1\n","Best match: yapf 0.40.1\n","Adding yapf 0.40.1 to easy-install.pth file\n","Installing yapf script to /usr/local/bin\n","Installing yapf-diff script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tqdm==4.65.0\n","Best match: tqdm 4.65.0\n","Adding tqdm 4.65.0 to easy-install.pth file\n","Installing tqdm script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for torchvision==0.15.2+cu118\n","Best match: torchvision 0.15.2+cu118\n","Adding torchvision 0.15.2+cu118 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for torch==2.0.1+cu118\n","Best match: torch 2.0.1+cu118\n","Adding torch 2.0.1+cu118 to easy-install.pth file\n","Installing convert-caffe2-to-onnx script to /usr/local/bin\n","Installing convert-onnx-to-caffe2 script to /usr/local/bin\n","Installing torchrun script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tb-nightly==2.14.0a20230707\n","Best match: tb-nightly 2.14.0a20230707\n","Adding tb-nightly 2.14.0a20230707 to easy-install.pth file\n","Installing tensorboard script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for scipy==1.10.1\n","Best match: scipy 1.10.1\n","Adding scipy 1.10.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for PyYAML==6.0\n","Best match: PyYAML 6.0\n","Adding PyYAML 6.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for opencv-python==4.7.0.72\n","Best match: opencv-python 4.7.0.72\n","Adding opencv-python 4.7.0.72 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for numpy==1.22.4\n","Best match: numpy 1.22.4\n","Adding numpy 1.22.4 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.10 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for lmdb==1.4.1\n","Best match: lmdb 1.4.1\n","Adding lmdb 1.4.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for facexlib==0.3.0\n","Best match: facexlib 0.3.0\n","Adding facexlib 0.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for basicsr==1.4.2\n","Best match: basicsr 1.4.2\n","Adding basicsr 1.4.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tomli==2.0.1\n","Best match: tomli 2.0.1\n","Adding tomli 2.0.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for platformdirs==3.7.0\n","Best match: platformdirs 3.7.0\n","Adding platformdirs 3.7.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for importlib-metadata==6.8.0\n","Best match: importlib-metadata 6.8.0\n","Adding importlib-metadata 6.8.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for Pillow==8.4.0\n","Best match: Pillow 8.4.0\n","Adding Pillow 8.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for requests==2.27.1\n","Best match: requests 2.27.1\n","Adding requests 2.27.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for triton==2.0.0\n","Best match: triton 2.0.0\n","Adding triton 2.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for Jinja2==3.1.2\n","Best match: Jinja2 3.1.2\n","Adding Jinja2 3.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for networkx==3.1\n","Best match: networkx 3.1\n","Adding networkx 3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for sympy==1.11.1\n","Best match: sympy 1.11.1\n","Adding sympy 1.11.1 to easy-install.pth file\n","Installing isympy script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for typing-extensions==4.6.3\n","Best match: typing-extensions 4.6.3\n","Adding typing-extensions 4.6.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for filelock==3.12.2\n","Best match: filelock 3.12.2\n","Adding filelock 3.12.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for wheel==0.40.0\n","Best match: wheel 0.40.0\n","Adding wheel 0.40.0 to easy-install.pth file\n","Installing wheel script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for Werkzeug==2.3.6\n","Best match: Werkzeug 2.3.6\n","Adding Werkzeug 2.3.6 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tensorboard-data-server==0.7.1\n","Best match: tensorboard-data-server 0.7.1\n","Adding tensorboard-data-server 0.7.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for setuptools==67.7.2\n","Best match: setuptools 67.7.2\n","Adding setuptools 67.7.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for protobuf==3.20.3\n","Best match: protobuf 3.20.3\n","Adding protobuf 3.20.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for Markdown==3.4.3\n","Best match: Markdown 3.4.3\n","Adding Markdown 3.4.3 to easy-install.pth file\n","Installing markdown_py script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for google-auth-oauthlib==1.0.0\n","Best match: google-auth-oauthlib 1.0.0\n","Adding google-auth-oauthlib 1.0.0 to easy-install.pth file\n","Installing google-oauthlib-tool script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for google-auth==2.17.3\n","Best match: google-auth 2.17.3\n","Adding google-auth 2.17.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for grpcio==1.56.0\n","Best match: grpcio 1.56.0\n","Adding grpcio 1.56.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for absl-py==1.4.0\n","Best match: absl-py 1.4.0\n","Adding absl-py 1.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for numba==0.56.4\n","Best match: numba 0.56.4\n","Adding numba 0.56.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for filterpy==1.4.5\n","Best match: filterpy 1.4.5\n","Adding filterpy 1.4.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for scikit-image==0.19.3\n","Best match: scikit-image 0.19.3\n","Adding scikit-image 0.19.3 to easy-install.pth file\n","Installing skivi script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for future==0.18.3\n","Best match: future 0.18.3\n","Adding future 0.18.3 to easy-install.pth file\n","Installing futurize script to /usr/local/bin\n","Installing pasteurize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for addict==2.4.0\n","Best match: addict 2.4.0\n","Adding addict 2.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for zipp==3.15.0\n","Best match: zipp 3.15.0\n","Adding zipp 3.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for idna==3.4\n","Best match: idna 3.4\n","Adding idna 3.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for charset-normalizer==2.0.12\n","Best match: charset-normalizer 2.0.12\n","Adding charset-normalizer 2.0.12 to easy-install.pth file\n","Installing normalizer script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for certifi==2023.5.7\n","Best match: certifi 2023.5.7\n","Adding certifi 2023.5.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for urllib3==1.26.16\n","Best match: urllib3 1.26.16\n","Adding urllib3 1.26.16 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for lit==16.0.6\n","Best match: lit 16.0.6\n","Adding lit 16.0.6 to easy-install.pth file\n","Installing lit script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for cmake==3.25.2\n","Best match: cmake 3.25.2\n","Adding cmake 3.25.2 to easy-install.pth file\n","Installing cmake script to /usr/local/bin\n","Installing cpack script to /usr/local/bin\n","Installing ctest script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for MarkupSafe==2.1.3\n","Best match: MarkupSafe 2.1.3\n","Adding MarkupSafe 2.1.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for mpmath==1.3.0\n","Best match: mpmath 1.3.0\n","Adding mpmath 1.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for requests-oauthlib==1.3.1\n","Best match: requests-oauthlib 1.3.1\n","Adding requests-oauthlib 1.3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for rsa==4.9\n","Best match: rsa 4.9\n","Adding rsa 4.9 to easy-install.pth file\n","Installing pyrsa-decrypt script to /usr/local/bin\n","Installing pyrsa-encrypt script to /usr/local/bin\n","Installing pyrsa-keygen script to /usr/local/bin\n","Installing pyrsa-priv2pub script to /usr/local/bin\n","Installing pyrsa-sign script to /usr/local/bin\n","Installing pyrsa-verify script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for six==1.16.0\n","Best match: six 1.16.0\n","Adding six 1.16.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for pyasn1-modules==0.3.0\n","Best match: pyasn1-modules 0.3.0\n","Adding pyasn1-modules 0.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for cachetools==5.3.1\n","Best match: cachetools 5.3.1\n","Adding cachetools 5.3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for llvmlite==0.39.1\n","Best match: llvmlite 0.39.1\n","Adding llvmlite 0.39.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for matplotlib==3.7.1\n","Best match: matplotlib 3.7.1\n","Adding matplotlib 3.7.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for packaging==23.1\n","Best match: packaging 23.1\n","Adding packaging 23.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for PyWavelets==1.4.1\n","Best match: PyWavelets 1.4.1\n","Adding PyWavelets 1.4.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tifffile==2023.4.12\n","Best match: tifffile 2023.4.12\n","Adding tifffile 2023.4.12 to easy-install.pth file\n","Installing lsm2bin script to /usr/local/bin\n","Installing tiff2fsspec script to /usr/local/bin\n","Installing tiffcomment script to /usr/local/bin\n","Installing tifffile script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for imageio==2.25.1\n","Best match: imageio 2.25.1\n","Adding imageio 2.25.1 to easy-install.pth file\n","Installing imageio_download_bin script to /usr/local/bin\n","Installing imageio_remove_bin script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for oauthlib==3.2.2\n","Best match: oauthlib 3.2.2\n","Adding oauthlib 3.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for pyasn1==0.5.0\n","Best match: pyasn1 0.5.0\n","Adding pyasn1 0.5.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for python-dateutil==2.8.2\n","Best match: python-dateutil 2.8.2\n","Adding python-dateutil 2.8.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for pyparsing==3.1.0\n","Best match: pyparsing 3.1.0\n","Adding pyparsing 3.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for kiwisolver==1.4.4\n","Best match: kiwisolver 1.4.4\n","Adding kiwisolver 1.4.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for fonttools==4.40.0\n","Best match: fonttools 4.40.0\n","Adding fonttools 4.40.0 to easy-install.pth file\n","Installing fonttools script to /usr/local/bin\n","Installing pyftmerge script to /usr/local/bin\n","Installing pyftsubset script to /usr/local/bin\n","Installing ttx script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for cycler==0.11.0\n","Best match: cycler 0.11.0\n","Adding cycler 0.11.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for contourpy==1.1.0\n","Best match: contourpy 1.1.0\n","Adding contourpy 1.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Finished processing dependencies for gfpgan==1.3.8\n","Collecting realesrgan\n","  Downloading realesrgan-0.3.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: basicsr>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.4.2)\n","Requirement already satisfied: facexlib>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (0.3.0)\n","Requirement already satisfied: gfpgan>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.3.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.22.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from realesrgan) (4.7.0.72)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from realesrgan) (8.4.0)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from realesrgan) (0.15.2+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from realesrgan) (4.65.0)\n","Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (0.18.3)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.27.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (0.19.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (1.10.1)\n","Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.14.0a20230707)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (0.40.1)\n","Requirement already satisfied: filterpy in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->realesrgan) (1.4.5)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->realesrgan) (0.56.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->realesrgan) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->realesrgan) (16.0.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib>=0.2.5->realesrgan) (3.7.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->realesrgan) (2.1.3)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.5->realesrgan) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.5->realesrgan) (67.7.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (3.4)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (23.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->realesrgan) (1.3.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.56.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (3.20.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (2.3.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (0.40.0)\n","Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (6.8.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (3.7.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (2.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr>=1.4.2->realesrgan) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr>=1.4.2->realesrgan) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr>=1.4.2->realesrgan) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr>=1.4.2->realesrgan) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly->basicsr>=1.4.2->realesrgan) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->basicsr>=1.4.2->realesrgan) (3.15.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (2.8.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->basicsr>=1.4.2->realesrgan) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly->basicsr>=1.4.2->realesrgan) (3.2.2)\n","Installing collected packages: realesrgan\n","Successfully installed realesrgan-0.3.0\n","--2023-07-08 08:26:36--  https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/349321229/e9847322-b8b1-4ec2-9620-5146eb8a9e4b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230708%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230708T082636Z&X-Amz-Expires=300&X-Amz-Signature=ae185030ad9c83a16d379cb8e78f41b766e85f74e746bc0a7086d1cbbba15a84&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=349321229&response-content-disposition=attachment%3B%20filename%3DGFPGANv1.3.pth&response-content-type=application%2Foctet-stream [following]\n","--2023-07-08 08:26:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/349321229/e9847322-b8b1-4ec2-9620-5146eb8a9e4b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230708%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230708T082636Z&X-Amz-Expires=300&X-Amz-Signature=ae185030ad9c83a16d379cb8e78f41b766e85f74e746bc0a7086d1cbbba15a84&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=349321229&response-content-disposition=attachment%3B%20filename%3DGFPGANv1.3.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 348632874 (332M) [application/octet-stream]\n","Saving to: ‘experiments/pretrained_models/GFPGANv1.3.pth’\n","\n","GFPGANv1.3.pth      100%[===================>] 332.48M   183MB/s    in 1.8s    \n","\n","2023-07-08 08:26:38 (183 MB/s) - ‘experiments/pretrained_models/GFPGANv1.3.pth’ saved [348632874/348632874]\n","\n"]}],"source":["# Clone GFPGAN and enter the GFPGAN folder\n","%cd /content\n","!rm -rf GFPGAN\n","!git clone https://github.com/TencentARC/GFPGAN.git\n","%cd GFPGAN\n","\n","# Set up the environment\n","# Install basicsr - https://github.com/xinntao/BasicSR\n","# We use BasicSR for both training and inference\n","!pip install basicsr\n","# Install facexlib - https://github.com/xinntao/facexlib\n","# We use face detection and face restoration helper in the facexlib package\n","!pip install facexlib\n","# Install other depencencies\n","!pip install -r requirements.txt\n","!python setup.py develop\n","!pip install realesrgan  # used for enhancing the background (non-face) regions\n","# Download the pre-trained model\n","# !wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n","# Now we use the V1.3 model for the demo\n","!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n"]},{"cell_type":"code","source":["!python inference_gfpgan.py -i /content/drive/MyDrive/BDC/train -o /content/drive/MyDrive/BDC/GFPGAN/hasil1 -v 1.3 --bg_upsampler realesrgan -s 10 -w 0.6"],"metadata":{"id":"ccEf7wOLmrps"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72827,"status":"ok","timestamp":1688454479035,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"InFQqZCc2iYp","outputId":"59038215-ba47-426e-96e5-9f4fec6289bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n","  warnings.warn(\n","/content/GFPGAN/inference_gfpgan.py:63: UserWarning: The unoptimized RealESRGAN is slow on CPU. We do not use it. If you really want to use it, please modify the corresponding codes.\n","  warnings.warn('The unoptimized RealESRGAN is slow on CPU. We do not use it. '\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth\" to /content/GFPGAN/gfpgan/weights/detection_Resnet50_Final.pth\n","\n","100% 104M/104M [00:00<00:00, 198MB/s] \n","Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth\" to /content/GFPGAN/gfpgan/weights/parsing_parsenet.pth\n","\n","100% 81.4M/81.4M [00:00<00:00, 165MB/s]\n","Processing DataTest1.png ...\n","Processing DataTest10.png ...\n","Processing DataTest100.png ...\n","Processing DataTest11.png ...\n","Processing DataTest12.png ...\n","Processing DataTest13.png ...\n","Processing DataTest14.png ...\n","Processing DataTest15.png ...\n","Processing DataTest16.png ...\n","Processing DataTest17.png ...\n","Processing DataTest18.png ...\n","Processing DataTest19.png ...\n","Processing DataTest2.png ...\n","Processing DataTest20.png ...\n","Processing DataTest21.png ...\n","Processing DataTest22.png ...\n","Processing DataTest23.png ...\n","Processing DataTest24.png ...\n","Processing DataTest25.png ...\n","Processing DataTest26.png ...\n","Processing DataTest27.png ...\n","Processing DataTest28.png ...\n","Processing DataTest29.png ...\n","Processing DataTest3.png ...\n","Processing DataTest30.png ...\n","Processing DataTest31.png ...\n","Processing DataTest32.png ...\n","Processing DataTest33.png ...\n","Processing DataTest34.png ...\n","Processing DataTest35.png ...\n","Processing DataTest36.png ...\n","Processing DataTest37.png ...\n","Processing DataTest38.png ...\n","Processing DataTest39.png ...\n","Processing DataTest4.png ...\n","Processing DataTest40.png ...\n","Processing DataTest41.png ...\n","Processing DataTest42.png ...\n","Processing DataTest43.png ...\n","Processing DataTest44.png ...\n","Processing DataTest45.png ...\n","Processing DataTest46.png ...\n","Processing DataTest47.png ...\n","Processing DataTest48.png ...\n","Processing DataTest49.png ...\n","Processing DataTest5.png ...\n","Processing DataTest50.png ...\n","Processing DataTest51.png ...\n","Processing DataTest52.png ...\n","Processing DataTest53.png ...\n","Processing DataTest54.png ...\n","Processing DataTest55.png ...\n","Processing DataTest56.png ...\n","Processing DataTest57.png ...\n","Processing DataTest58.png ...\n","Processing DataTest59.png ...\n","Processing DataTest6.png ...\n","Processing DataTest60.png ...\n","Processing DataTest61.png ...\n","Processing DataTest62.png ...\n","Processing DataTest63.png ...\n","Processing DataTest64.png ...\n","Processing DataTest65.png ...\n","Processing DataTest66.png ...\n","Processing DataTest67.png ...\n","Processing DataTest68.png ...\n","Processing DataTest69.png ...\n","Processing DataTest7.png ...\n","Processing DataTest70.png ...\n","Processing DataTest71.png ...\n","Processing DataTest72.png ...\n","Processing DataTest73.png ...\n","Processing DataTest74.png ...\n","Processing DataTest75.png ...\n","Processing DataTest76.png ...\n","Processing DataTest77.png ...\n","Processing DataTest78.png ...\n","Processing DataTest79.png ...\n","Processing DataTest8.png ...\n","Processing DataTest80.png ...\n","Processing DataTest81.png ...\n","Processing DataTest82.png ...\n","Processing DataTest83.png ...\n","Processing DataTest84.png ...\n","Processing DataTest85.png ...\n","Processing DataTest86.png ...\n","Processing DataTest87.png ...\n","Processing DataTest88.png ...\n","Processing DataTest89.png ...\n","Processing DataTest9.png ...\n","Processing DataTest90.png ...\n","Processing DataTest91.png ...\n","Processing DataTest92.png ...\n","Processing DataTest93.png ...\n","Processing DataTest94.png ...\n","Processing DataTest95.png ...\n","Processing DataTest96.png ...\n","Processing DataTest97.png ...\n","Processing DataTest98.png ...\n","Processing DataTest99.png ...\n","Results are in the [/content/drive/MyDrive/BDC/GFPGAN/hasil1] folder.\n"]}],"source":["!python inference_gfpgan.py -i /content/drive/MyDrive/BDC/DataTest -o /content/drive/MyDrive/BDC/GFPGAN/hasil1 -v 1.3 --bg_upsampler realesrgan -s 10 -w 0.6"]},{"cell_type":"markdown","metadata":{"id":"2V4iVPE5jjxo"},"source":["##MODELING"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4829064,"status":"ok","timestamp":1688303289535,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"1KsRf4ep6LNv","outputId":"f10566eb-3211-4328-e8f7-98cab9d4af7f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.124 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=300, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train4\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100%|██████████| 755k/755k [00:00<00:00, 14.5MB/s]\n","Overriding model.yaml nc=80 with nc=55\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3807541  ultralytics.nn.modules.head.Detect           [55, [192, 384, 576]]         \n","Model summary: 295 layers, 25888165 parameters, 25888149 gradients\n","\n","Transferred 469/475 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/BDC/train/labels.cache... 700 images, 0 backgrounds, 0 corrupt: 100%|██████████| 700/700 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/BDC/val/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/train4/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train4\u001b[0m\n","Starting training for 300 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      1/300      3.64G      1.469      2.652       1.33         81        640: 100%|██████████| 88/88 [00:37<00:00,  2.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\n","                   all        100        762    0.00833     0.0598    0.00503    0.00139\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      2/300      3.79G      1.388       1.75      1.326         75        640: 100%|██████████| 88/88 [00:28<00:00,  3.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.89it/s]\n","                   all        100        762      0.581      0.367      0.383      0.207\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      3/300      3.83G      1.317       1.44        1.3         59        640: 100%|██████████| 88/88 [00:27<00:00,  3.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.59it/s]\n","                   all        100        762      0.652      0.506       0.55      0.345\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      4/300      3.82G      1.283      1.355      1.307         58        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.68it/s]\n","                   all        100        762      0.737      0.608      0.677      0.384\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      5/300      3.79G      1.266      1.212      1.311         88        640: 100%|██████████| 88/88 [00:28<00:00,  3.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.90it/s]\n","                   all        100        762      0.694      0.629       0.73      0.452\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      6/300       3.8G       1.25      1.146      1.313         61        640: 100%|██████████| 88/88 [00:28<00:00,  3.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.58it/s]\n","                   all        100        762      0.783      0.694      0.818      0.481\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      7/300      3.82G       1.22      1.067      1.297         75        640: 100%|██████████| 88/88 [00:26<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.47it/s]\n","                   all        100        762        0.8      0.756      0.865      0.528\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      8/300      3.79G      1.177      1.012      1.305         54        640: 100%|██████████| 88/88 [00:26<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.08it/s]\n","                   all        100        762      0.821      0.761      0.873      0.554\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      9/300      3.84G      1.193     0.9682      1.321         64        640: 100%|██████████| 88/88 [00:27<00:00,  3.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.85it/s]\n","                   all        100        762      0.724      0.792      0.852      0.531\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     10/300      3.81G      1.178     0.9316      1.313         66        640: 100%|██████████| 88/88 [00:26<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.87it/s]\n","                   all        100        762      0.861      0.806      0.883      0.549\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     11/300      3.83G      1.165     0.9108      1.306         66        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.80it/s]\n","                   all        100        762      0.808      0.774      0.868      0.553\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     12/300       3.8G      1.162     0.8747      1.316         52        640: 100%|██████████| 88/88 [00:26<00:00,  3.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.90it/s]\n","                   all        100        762      0.863       0.76      0.886      0.562\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     13/300      3.78G      1.157     0.8572      1.296         89        640: 100%|██████████| 88/88 [00:26<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.68it/s]\n","                   all        100        762      0.871      0.805      0.891       0.58\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     14/300      3.82G      1.148     0.8377      1.289         59        640: 100%|██████████| 88/88 [00:27<00:00,  3.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.64it/s]\n","                   all        100        762      0.886       0.77      0.888      0.583\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     15/300      3.82G      1.129     0.8225      1.311         47        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.04it/s]\n","                   all        100        762      0.868      0.838      0.911      0.599\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     16/300      3.81G      1.145     0.8425      1.307         87        640: 100%|██████████| 88/88 [00:27<00:00,  3.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.20it/s]\n","                   all        100        762      0.843      0.801      0.902      0.549\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     17/300       3.8G      1.129     0.8271      1.318         78        640: 100%|██████████| 88/88 [00:26<00:00,  3.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.32it/s]\n","                   all        100        762      0.854      0.796      0.904      0.564\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     18/300      3.81G      1.135     0.8022      1.305         90        640: 100%|██████████| 88/88 [00:27<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.81it/s]\n","                   all        100        762      0.866       0.76      0.891      0.544\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     19/300      3.79G      1.128      0.774      1.302         86        640: 100%|██████████| 88/88 [00:27<00:00,  3.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.62it/s]\n","                   all        100        762       0.88      0.806      0.895      0.572\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     20/300      3.83G      1.137     0.7829      1.309         61        640: 100%|██████████| 88/88 [00:27<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.60it/s]\n","                   all        100        762      0.915      0.825      0.925      0.574\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     21/300      3.79G      1.148     0.7919      1.317         58        640: 100%|██████████| 88/88 [00:26<00:00,  3.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.43it/s]\n","                   all        100        762      0.901      0.805      0.912      0.552\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     22/300      3.82G      1.129      0.767      1.299         56        640: 100%|██████████| 88/88 [00:26<00:00,  3.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.93it/s]\n","                   all        100        762      0.872      0.864       0.92      0.575\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     23/300      3.84G      1.117     0.7329      1.294         64        640: 100%|██████████| 88/88 [00:26<00:00,  3.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.02it/s]\n","                   all        100        762      0.889      0.853       0.93      0.582\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     24/300      3.81G      1.131     0.7382      1.307         96        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.73it/s]\n","                   all        100        762       0.88      0.842      0.924      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     25/300      3.81G        1.1     0.7167      1.267         55        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.23it/s]\n","                   all        100        762      0.934       0.85      0.941      0.607\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     26/300       3.8G      1.107      0.703       1.28         30        640: 100%|██████████| 88/88 [00:26<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.64it/s]\n","                   all        100        762      0.903      0.853      0.932      0.589\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     27/300       3.8G       1.11     0.7178       1.31         57        640: 100%|██████████| 88/88 [00:25<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.94it/s]\n","                   all        100        762      0.886      0.875      0.928      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     28/300      3.84G      1.105     0.7066      1.279         75        640: 100%|██████████| 88/88 [00:25<00:00,  3.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.69it/s]\n","                   all        100        762        0.9      0.855      0.939      0.605\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     29/300      3.83G      1.097     0.6919       1.28         50        640: 100%|██████████| 88/88 [00:26<00:00,  3.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.72it/s]\n","                   all        100        762      0.904      0.857      0.936       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     30/300      3.83G      1.097     0.7168      1.301         74        640: 100%|██████████| 88/88 [00:26<00:00,  3.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.61it/s]\n","                   all        100        762      0.889      0.849      0.938      0.628\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     31/300      3.81G      1.097     0.6822      1.291         89        640: 100%|██████████| 88/88 [00:27<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.98it/s]\n","                   all        100        762      0.909      0.846      0.941      0.612\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     32/300      3.84G      1.105     0.6821      1.286         52        640: 100%|██████████| 88/88 [00:26<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.85it/s]\n","                   all        100        762      0.886      0.821      0.918        0.6\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     33/300      3.83G      1.097     0.6946      1.298         61        640: 100%|██████████| 88/88 [00:29<00:00,  2.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.55it/s]\n","                   all        100        762      0.907      0.876      0.939        0.6\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     34/300      3.84G      1.078     0.6715      1.284         61        640: 100%|██████████| 88/88 [00:27<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.35it/s]\n","                   all        100        762      0.894      0.893      0.944      0.606\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     35/300      3.81G      1.085     0.6899       1.29         56        640: 100%|██████████| 88/88 [00:26<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.14it/s]\n","                   all        100        762      0.916      0.857      0.946       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     36/300       3.8G       1.08     0.6675      1.271         43        640: 100%|██████████| 88/88 [00:27<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.88it/s]\n","                   all        100        762      0.854      0.849      0.919      0.586\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     37/300      3.82G      1.099     0.6776      1.294         74        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.90it/s]\n","                   all        100        762      0.917      0.854      0.938      0.597\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     38/300       3.8G      1.083     0.6564      1.263         64        640: 100%|██████████| 88/88 [00:26<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.91it/s]\n","                   all        100        762      0.919      0.852      0.943      0.605\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     39/300      3.78G      1.082     0.6515      1.271         70        640: 100%|██████████| 88/88 [00:25<00:00,  3.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.02it/s]\n","                   all        100        762      0.923      0.867      0.946      0.606\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     40/300      3.84G      1.081     0.6614      1.277         71        640: 100%|██████████| 88/88 [00:25<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.73it/s]\n","                   all        100        762      0.914      0.869      0.949      0.612\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     41/300      3.82G       1.08     0.6534      1.272         72        640: 100%|██████████| 88/88 [00:25<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.27it/s]\n","                   all        100        762       0.93      0.847      0.942      0.579\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     42/300      3.83G      1.068     0.6496      1.264         57        640: 100%|██████████| 88/88 [00:26<00:00,  3.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.27it/s]\n","                   all        100        762      0.888      0.882      0.926      0.576\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     43/300      3.83G      1.068     0.6478      1.276         62        640: 100%|██████████| 88/88 [00:27<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]\n","                   all        100        762      0.908       0.85      0.944      0.597\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     44/300      3.81G      1.071     0.6519      1.275         72        640: 100%|██████████| 88/88 [00:26<00:00,  3.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.16it/s]\n","                   all        100        762      0.929      0.865      0.946      0.614\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     45/300      3.84G      1.061      0.628      1.257         88        640: 100%|██████████| 88/88 [00:27<00:00,  3.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.58it/s]\n","                   all        100        762      0.921      0.874      0.953      0.611\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     46/300      3.84G      1.073     0.6272      1.267         73        640: 100%|██████████| 88/88 [00:27<00:00,  3.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.79it/s]\n","                   all        100        762      0.919      0.899      0.955      0.598\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     47/300      3.83G      1.059     0.6387      1.271         84        640: 100%|██████████| 88/88 [00:27<00:00,  3.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]\n","                   all        100        762      0.885      0.896      0.941      0.609\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     48/300      3.85G       1.07     0.6378      1.263         79        640: 100%|██████████| 88/88 [00:27<00:00,  3.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.19it/s]\n","                   all        100        762      0.893      0.845       0.93       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     49/300      3.83G      1.059     0.6189      1.266         54        640: 100%|██████████| 88/88 [00:26<00:00,  3.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.20it/s]\n","                   all        100        762      0.905       0.86      0.934      0.606\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     50/300      3.81G      1.084     0.6337      1.286         63        640: 100%|██████████| 88/88 [00:26<00:00,  3.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.79it/s]\n","                   all        100        762      0.925      0.868      0.948       0.61\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     51/300      3.82G      1.068      0.618       1.26         84        640: 100%|██████████| 88/88 [00:26<00:00,  3.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.92it/s]\n","                   all        100        762      0.925      0.868      0.944      0.614\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     52/300      3.85G      1.074     0.6313      1.265         59        640: 100%|██████████| 88/88 [00:25<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.96it/s]\n","                   all        100        762       0.93      0.883      0.949      0.586\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     53/300      3.81G      1.058     0.6319      1.271         83        640: 100%|██████████| 88/88 [00:25<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.48it/s]\n","                   all        100        762      0.886      0.875      0.938      0.586\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     54/300      3.83G      1.058     0.6141      1.254         67        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.33it/s]\n","                   all        100        762      0.904      0.874      0.953      0.625\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     55/300      3.81G       1.05     0.6113      1.249         54        640: 100%|██████████| 88/88 [00:25<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.24it/s]\n","                   all        100        762      0.918      0.882       0.95      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     56/300      3.83G      1.043     0.6058      1.261         34        640: 100%|██████████| 88/88 [00:26<00:00,  3.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.64it/s]\n","                   all        100        762      0.941      0.862      0.958      0.641\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     57/300       3.8G      1.058     0.6179      1.269         37        640: 100%|██████████| 88/88 [00:26<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.96it/s]\n","                   all        100        762      0.841      0.895      0.942      0.615\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     58/300      3.83G       1.07     0.6102      1.272         46        640: 100%|██████████| 88/88 [00:25<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.78it/s]\n","                   all        100        762      0.923      0.876      0.956       0.63\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     59/300      3.84G      1.055     0.6005      1.267         42        640: 100%|██████████| 88/88 [00:25<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.10it/s]\n","                   all        100        762      0.912      0.876      0.947      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     60/300      3.82G      1.043     0.5954      1.255         55        640: 100%|██████████| 88/88 [00:26<00:00,  3.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.97it/s]\n","                   all        100        762       0.93      0.895      0.958      0.625\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     61/300      3.84G      1.056     0.5911      1.265         48        640: 100%|██████████| 88/88 [00:27<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.39it/s]\n","                   all        100        762      0.906      0.885      0.951      0.624\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     62/300       3.8G      1.024     0.5812      1.244         57        640: 100%|██████████| 88/88 [00:27<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.46it/s]\n","                   all        100        762      0.942      0.884      0.956      0.636\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     63/300      3.83G       1.05     0.5918       1.26         57        640: 100%|██████████| 88/88 [00:26<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.05it/s]\n","                   all        100        762      0.927      0.903      0.956      0.625\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     64/300      3.84G      1.044     0.5833      1.248         77        640: 100%|██████████| 88/88 [00:26<00:00,  3.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.92it/s]\n","                   all        100        762      0.926      0.887      0.954      0.626\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     65/300      3.83G      1.037     0.5811      1.251         47        640: 100%|██████████| 88/88 [00:26<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.95it/s]\n","                   all        100        762      0.908      0.879      0.953       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     66/300      3.82G      1.027     0.5723      1.239         68        640: 100%|██████████| 88/88 [00:26<00:00,  3.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.91it/s]\n","                   all        100        762      0.912      0.897      0.959      0.633\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     67/300      3.85G       1.04     0.5776      1.261         63        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.03it/s]\n","                   all        100        762      0.933       0.88      0.957      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     68/300      3.84G      1.046     0.5888      1.256         61        640: 100%|██████████| 88/88 [00:25<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.12it/s]\n","                   all        100        762      0.914      0.894      0.949      0.621\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     69/300      3.84G      1.037     0.5944      1.245         71        640: 100%|██████████| 88/88 [00:25<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.59it/s]\n","                   all        100        762      0.921      0.889      0.952       0.63\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     70/300      3.84G      1.033     0.5961      1.238         78        640: 100%|██████████| 88/88 [00:25<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.22it/s]\n","                   all        100        762      0.946      0.884      0.956      0.617\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     71/300      3.81G       1.02     0.5721      1.232         47        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.95it/s]\n","                   all        100        762       0.93      0.894       0.96      0.622\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     72/300      3.84G      1.031     0.5889      1.244         64        640: 100%|██████████| 88/88 [00:26<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.24it/s]\n","                   all        100        762      0.931      0.899       0.96      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     73/300      3.84G      1.041     0.5857      1.256         70        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.30it/s]\n","                   all        100        762      0.943      0.881      0.959      0.623\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     74/300      3.84G      1.044     0.5879      1.244         47        640: 100%|██████████| 88/88 [00:25<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.58it/s]\n","                   all        100        762      0.921      0.885      0.948      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     75/300      3.83G      1.026     0.5693      1.224         67        640: 100%|██████████| 88/88 [00:25<00:00,  3.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.83it/s]\n","                   all        100        762       0.91       0.89      0.947      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     76/300      3.83G      1.026     0.5634      1.227         76        640: 100%|██████████| 88/88 [00:25<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.34it/s]\n","                   all        100        762       0.93      0.882      0.954      0.619\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     77/300      3.81G       1.01     0.5528      1.242         52        640: 100%|██████████| 88/88 [00:26<00:00,  3.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.16it/s]\n","                   all        100        762      0.901        0.9      0.954      0.614\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     78/300      3.83G      1.013     0.5556      1.227         82        640: 100%|██████████| 88/88 [00:26<00:00,  3.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.88it/s]\n","                   all        100        762       0.91      0.887      0.954       0.63\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     79/300      3.82G      1.022     0.5624      1.239         42        640: 100%|██████████| 88/88 [00:26<00:00,  3.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.25it/s]\n","                   all        100        762      0.932      0.888      0.964      0.637\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     80/300      3.81G      1.023     0.5592      1.234         53        640: 100%|██████████| 88/88 [00:27<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.07it/s]\n","                   all        100        762       0.92      0.885      0.953      0.618\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     81/300      3.84G      1.018     0.5599      1.239         78        640: 100%|██████████| 88/88 [00:26<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.03it/s]\n","                   all        100        762      0.932       0.89      0.955      0.625\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     82/300      3.83G       1.02      0.573      1.236         46        640: 100%|██████████| 88/88 [00:25<00:00,  3.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.89it/s]\n","                   all        100        762      0.934      0.899      0.962      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     83/300      3.81G      1.034       0.56      1.227         85        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.93it/s]\n","                   all        100        762      0.953      0.896      0.964      0.622\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     84/300      3.83G      1.004     0.5466      1.235         90        640: 100%|██████████| 88/88 [00:25<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.26it/s]\n","                   all        100        762      0.925      0.917      0.965      0.628\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     85/300      3.81G      1.028     0.5683      1.242         53        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.27it/s]\n","                   all        100        762      0.952      0.865      0.954      0.633\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     86/300      3.82G      1.009     0.5476      1.231         57        640: 100%|██████████| 88/88 [00:25<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.97it/s]\n","                   all        100        762      0.933      0.892      0.967      0.615\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     87/300      3.81G      1.024     0.5597      1.244         48        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.35it/s]\n","                   all        100        762      0.933      0.917      0.966      0.599\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     88/300       3.8G     0.9993     0.5372      1.213         86        640: 100%|██████████| 88/88 [00:27<00:00,  3.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.11it/s]\n","                   all        100        762       0.92        0.9      0.957      0.633\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     89/300      3.81G      1.009     0.5428      1.234         75        640: 100%|██████████| 88/88 [00:27<00:00,  3.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.13it/s]\n","                   all        100        762      0.905      0.918      0.955      0.596\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     90/300      3.81G       1.02     0.5583      1.239         72        640: 100%|██████████| 88/88 [00:26<00:00,  3.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.02it/s]\n","                   all        100        762      0.938      0.888      0.967      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     91/300      3.79G      1.003     0.5441      1.237         37        640: 100%|██████████| 88/88 [00:26<00:00,  3.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.71it/s]\n","                   all        100        762       0.94      0.879      0.961      0.626\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     92/300      3.82G     0.9958     0.5295      1.211         54        640: 100%|██████████| 88/88 [00:27<00:00,  3.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.68it/s]\n","                   all        100        762      0.927      0.891       0.95      0.628\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     93/300       3.8G     0.9949     0.5267      1.217         60        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.70it/s]\n","                   all        100        762      0.928      0.885      0.953      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     94/300      3.82G     0.9908     0.5154      1.215         58        640: 100%|██████████| 88/88 [00:27<00:00,  3.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.03it/s]\n","                   all        100        762      0.934      0.891       0.96      0.637\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     95/300      3.82G      1.016     0.5584      1.237         70        640: 100%|██████████| 88/88 [00:26<00:00,  3.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.09it/s]\n","                   all        100        762      0.942      0.865      0.959      0.634\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     96/300      3.84G     0.9976      0.545       1.22         75        640: 100%|██████████| 88/88 [00:26<00:00,  3.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.72it/s]\n","                   all        100        762      0.909      0.894      0.948      0.617\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     97/300       3.8G     0.9957     0.5358      1.224         53        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.81it/s]\n","                   all        100        762      0.927      0.902      0.953      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     98/300      3.83G      1.011      0.543      1.234         42        640: 100%|██████████| 88/88 [00:26<00:00,  3.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.84it/s]\n","                   all        100        762      0.928      0.879      0.953      0.631\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     99/300      3.84G      1.006     0.5449      1.237         49        640: 100%|██████████| 88/88 [00:25<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.69it/s]\n","                   all        100        762      0.912      0.891      0.964      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    100/300      3.83G      1.015     0.5538      1.233         67        640: 100%|██████████| 88/88 [00:26<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.25it/s]\n","                   all        100        762      0.931       0.89      0.963      0.631\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    101/300      3.84G          1     0.5252      1.221         82        640: 100%|██████████| 88/88 [00:26<00:00,  3.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.08it/s]\n","                   all        100        762      0.934      0.898      0.956      0.617\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    102/300      3.83G     0.9905     0.5211      1.228         49        640: 100%|██████████| 88/88 [00:27<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.00it/s]\n","                   all        100        762      0.931      0.904      0.964      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    103/300       3.8G     0.9927     0.5275       1.22         67        640: 100%|██████████| 88/88 [00:27<00:00,  3.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.68it/s]\n","                   all        100        762      0.935      0.917      0.966      0.637\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    104/300      3.84G     0.9825     0.5199      1.211         57        640: 100%|██████████| 88/88 [00:27<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.67it/s]\n","                   all        100        762      0.933      0.891      0.961      0.639\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    105/300      3.83G     0.9995     0.5293      1.226         72        640: 100%|██████████| 88/88 [00:27<00:00,  3.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.51it/s]\n","                   all        100        762      0.955      0.903      0.965      0.646\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    106/300      3.83G      0.993     0.5332       1.22         76        640: 100%|██████████| 88/88 [00:28<00:00,  3.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.00it/s]\n","                   all        100        762      0.926      0.905      0.962      0.624\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    107/300      3.82G     0.9859      0.523      1.208         76        640: 100%|██████████| 88/88 [00:27<00:00,  3.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.90it/s]\n","                   all        100        762      0.911      0.899       0.96      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    108/300      3.83G     0.9832     0.5147      1.207         57        640: 100%|██████████| 88/88 [00:27<00:00,  3.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.78it/s]\n","                   all        100        762      0.924      0.885      0.965      0.639\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    109/300      3.79G     0.9808     0.5098      1.209         62        640: 100%|██████████| 88/88 [00:27<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.77it/s]\n","                   all        100        762      0.942      0.892      0.957      0.617\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    110/300      3.83G     0.9745     0.5065      1.207         94        640: 100%|██████████| 88/88 [00:26<00:00,  3.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.89it/s]\n","                   all        100        762      0.937       0.88      0.962       0.64\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    111/300      3.82G     0.9777     0.5104      1.196         54        640: 100%|██████████| 88/88 [00:26<00:00,  3.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.69it/s]\n","                   all        100        762      0.917      0.916      0.957      0.618\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    112/300      3.79G          1     0.5158      1.221         68        640: 100%|██████████| 88/88 [00:26<00:00,  3.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.98it/s]\n","                   all        100        762      0.936      0.907       0.96      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    113/300      3.83G     0.9908       0.51      1.221         56        640: 100%|██████████| 88/88 [00:25<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.03it/s]\n","                   all        100        762      0.927      0.893      0.957      0.626\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    114/300      3.81G     0.9729      0.512      1.205         51        640: 100%|██████████| 88/88 [00:25<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.52it/s]\n","                   all        100        762      0.932      0.903      0.962      0.622\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    115/300       3.8G     0.9791     0.5079      1.215         70        640: 100%|██████████| 88/88 [00:26<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.72it/s]\n","                   all        100        762      0.931      0.918       0.97      0.636\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    116/300      3.79G     0.9654     0.5011      1.185         56        640: 100%|██████████| 88/88 [00:26<00:00,  3.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.97it/s]\n","                   all        100        762      0.942      0.906      0.961      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    117/300      3.82G      0.972     0.5045      1.207         63        640: 100%|██████████| 88/88 [00:27<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.04it/s]\n","                   all        100        762      0.923      0.895      0.958      0.623\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    118/300      3.78G     0.9739     0.5195        1.2         80        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.22it/s]\n","                   all        100        762      0.954      0.883      0.956      0.622\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    119/300      3.83G     0.9697     0.4999      1.189         69        640: 100%|██████████| 88/88 [00:27<00:00,  3.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.96it/s]\n","                   all        100        762      0.933      0.906      0.965      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    120/300       3.8G     0.9622     0.4933      1.192         64        640: 100%|██████████| 88/88 [00:27<00:00,  3.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.99it/s]\n","                   all        100        762      0.957      0.859      0.963      0.626\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    121/300      3.83G     0.9815     0.5213      1.214         59        640: 100%|██████████| 88/88 [00:27<00:00,  3.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.64it/s]\n","                   all        100        762      0.946      0.893      0.957      0.618\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    122/300      3.83G     0.9745      0.515      1.212         62        640: 100%|██████████| 88/88 [00:26<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.38it/s]\n","                   all        100        762      0.933      0.907      0.958      0.618\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    123/300      3.78G     0.9546     0.5041      1.189         53        640: 100%|██████████| 88/88 [00:26<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.88it/s]\n","                   all        100        762       0.92      0.897      0.959      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    124/300      3.78G     0.9683     0.5123      1.201         52        640: 100%|██████████| 88/88 [00:26<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.00it/s]\n","                   all        100        762      0.934      0.896      0.954      0.625\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    125/300      3.79G     0.9639     0.5088      1.189         71        640: 100%|██████████| 88/88 [00:26<00:00,  3.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.05it/s]\n","                   all        100        762       0.92        0.9       0.96      0.631\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    126/300      3.82G     0.9653     0.4984      1.194         65        640: 100%|██████████| 88/88 [00:26<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.96it/s]\n","                   all        100        762      0.933      0.891       0.96      0.623\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    127/300      3.83G     0.9559     0.5025      1.192         61        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.35it/s]\n","                   all        100        762      0.928      0.896       0.96      0.626\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    128/300      3.83G     0.9563     0.4919      1.183         52        640: 100%|██████████| 88/88 [00:26<00:00,  3.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.60it/s]\n","                   all        100        762      0.945      0.896      0.963      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    129/300      3.81G     0.9595     0.4887      1.194         58        640: 100%|██████████| 88/88 [00:26<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.69it/s]\n","                   all        100        762       0.92      0.901      0.949      0.623\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    130/300       3.8G     0.9501     0.4856      1.203         67        640: 100%|██████████| 88/88 [00:26<00:00,  3.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.04it/s]\n","                   all        100        762      0.934      0.896      0.959      0.634\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    131/300      3.82G     0.9547     0.4992      1.204         75        640: 100%|██████████| 88/88 [00:27<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.18it/s]\n","                   all        100        762      0.927      0.889      0.957       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    132/300      3.79G     0.9567      0.501      1.187         77        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.09it/s]\n","                   all        100        762       0.93      0.893      0.965      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    133/300      3.81G     0.9469     0.4828      1.179         68        640: 100%|██████████| 88/88 [00:27<00:00,  3.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.82it/s]\n","                   all        100        762      0.937      0.894      0.961      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    134/300      3.82G     0.9473     0.4894      1.187         53        640: 100%|██████████| 88/88 [00:27<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.92it/s]\n","                   all        100        762      0.935      0.903      0.961      0.637\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    135/300      3.82G     0.9419     0.4963      1.195         47        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.96it/s]\n","                   all        100        762      0.912      0.897      0.956      0.621\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    136/300       3.8G     0.9498     0.5107      1.193         48        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.94it/s]\n","                   all        100        762      0.917      0.892      0.947      0.639\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    137/300      3.79G      0.944     0.4865      1.173         97        640: 100%|██████████| 88/88 [00:27<00:00,  3.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.06it/s]\n","                   all        100        762      0.932      0.881      0.964       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    138/300      3.83G     0.9458     0.4924      1.181         57        640: 100%|██████████| 88/88 [00:26<00:00,  3.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.81it/s]\n","                   all        100        762      0.937      0.901      0.973      0.639\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    139/300       3.8G      0.941     0.4834       1.18         54        640: 100%|██████████| 88/88 [00:26<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.01it/s]\n","                   all        100        762      0.959      0.874      0.959      0.636\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    140/300      3.83G     0.9439     0.4846      1.185         92        640: 100%|██████████| 88/88 [00:25<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.31it/s]\n","                   all        100        762      0.877      0.905      0.956      0.617\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    141/300      3.79G     0.9378     0.4879      1.189         51        640: 100%|██████████| 88/88 [00:26<00:00,  3.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.94it/s]\n","                   all        100        762      0.935       0.89      0.968      0.639\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    142/300      3.82G       0.94     0.4829      1.175         71        640: 100%|██████████| 88/88 [00:26<00:00,  3.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.07it/s]\n","                   all        100        762      0.918      0.913      0.962      0.623\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    143/300      3.81G     0.9475     0.4794      1.189         85        640: 100%|██████████| 88/88 [00:26<00:00,  3.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.02it/s]\n","                   all        100        762      0.934      0.911      0.956      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    144/300      3.79G     0.9252     0.4764      1.184         66        640: 100%|██████████| 88/88 [00:27<00:00,  3.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.24it/s]\n","                   all        100        762      0.942       0.89      0.965       0.63\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    145/300      3.82G     0.9365     0.4866      1.188         54        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.05it/s]\n","                   all        100        762      0.939      0.886      0.963      0.639\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    146/300      3.79G     0.9406     0.4901      1.188         51        640: 100%|██████████| 88/88 [00:27<00:00,  3.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.92it/s]\n","                   all        100        762      0.946      0.908      0.969      0.637\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    147/300      3.79G     0.9262     0.4726      1.162         50        640: 100%|██████████| 88/88 [00:27<00:00,  3.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.49it/s]\n","                   all        100        762      0.944      0.904       0.97      0.641\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    148/300       3.8G     0.9346     0.4851      1.196         58        640: 100%|██████████| 88/88 [00:27<00:00,  3.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.11it/s]\n","                   all        100        762       0.94      0.897      0.951      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    149/300      3.81G     0.9326     0.4841      1.184         69        640: 100%|██████████| 88/88 [00:28<00:00,  3.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.88it/s]\n","                   all        100        762      0.933      0.896      0.959      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    150/300      3.81G     0.9374     0.4911       1.19         71        640: 100%|██████████| 88/88 [00:27<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  4.02it/s]\n","                   all        100        762      0.928      0.898      0.963      0.633\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    151/300      3.81G     0.9297     0.4905      1.185         64        640: 100%|██████████| 88/88 [00:27<00:00,  3.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.12it/s]\n","                   all        100        762      0.927      0.916      0.962       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    152/300      3.84G     0.9312     0.4794      1.172         82        640: 100%|██████████| 88/88 [00:26<00:00,  3.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.92it/s]\n","                   all        100        762      0.943      0.913      0.965      0.636\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    153/300      3.83G     0.9315     0.4838      1.182         71        640: 100%|██████████| 88/88 [00:26<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.87it/s]\n","                   all        100        762      0.933      0.911      0.967       0.63\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    154/300      3.81G     0.9238     0.4705      1.162         67        640: 100%|██████████| 88/88 [00:27<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.98it/s]\n","                   all        100        762      0.911      0.915      0.968      0.628\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    155/300      3.81G     0.9237     0.4756      1.179         72        640: 100%|██████████| 88/88 [00:26<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:08<00:00,  1.15s/it]\n","                   all        100        762       0.95      0.898      0.966      0.634\n","Stopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 105, best model saved as best.pt.\n","To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","\n","155 epochs completed in 1.325 hours.\n","Optimizer stripped from runs/detect/train4/weights/last.pt, 52.1MB\n","Optimizer stripped from runs/detect/train4/weights/best.pt, 52.1MB\n","\n","Validating runs/detect/train4/weights/best.pt...\n","Ultralytics YOLOv8.0.124 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 218 layers, 25871605 parameters, 0 gradients\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.03it/s]\n","                   all        100        762      0.955      0.905      0.966      0.647\n","                     A        100         46      0.995      0.913      0.973      0.618\n","                     B        100         92      0.974      0.946      0.982      0.561\n","                     C        100          3       0.83          1      0.995      0.731\n","                     D        100         14          1      0.698      0.894       0.58\n","                     E        100         21          1      0.941      0.981      0.602\n","                     F        100         15          1      0.921      0.995      0.664\n","                     G        100          1      0.949          1      0.995      0.697\n","                     H        100          4      0.972          1      0.995      0.768\n","                     I        100          8      0.953       0.75      0.927      0.486\n","                     J        100         12      0.898      0.833      0.886      0.575\n","                     K        100          5          1      0.883      0.995       0.67\n","                     L        100          8      0.956          1      0.995      0.654\n","                     M        100          6          1      0.772      0.995       0.65\n","                     N        100         13      0.941          1      0.995       0.74\n","                     O        100         10      0.768        0.8      0.931      0.629\n","                     P        100         10          1      0.845      0.995      0.662\n","                     Q        100         12      0.842      0.833       0.91      0.604\n","                     R        100         10      0.993          1      0.995      0.821\n","                     S        100         17      0.984          1      0.995      0.675\n","                     T        100         20          1      0.942       0.99      0.687\n","                     U        100         11       0.98      0.818        0.9      0.611\n","                     V        100         10      0.972        0.7      0.811      0.469\n","                     W        100          7      0.994      0.857      0.874      0.619\n","                     X        100          2      0.874          1      0.995      0.448\n","                     Y        100          3          1      0.982      0.995      0.659\n","                     Z        100         10          1       0.86      0.972      0.642\n","                     0        100         31          1      0.932      0.989      0.638\n","                     1        100        111      0.972      0.927      0.987      0.538\n","                     2        100         30      0.983      0.933      0.993      0.696\n","                     3        100         17      0.845          1      0.989      0.691\n","                     4        100         36          1      0.887      0.994      0.688\n","                     5        100         30      0.983      0.967      0.988      0.724\n","                     6        100         39      0.923      0.925      0.966      0.663\n","                     7        100         34      0.976      0.912      0.953      0.722\n","                     8        100         27      0.851      0.926      0.974      0.706\n","                     9        100         37      0.976      0.865      0.965      0.689\n","Speed: 0.9ms preprocess, 6.6ms inference, 0.0ms loss, 4.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train4\u001b[0m\n"]}],"source":["model = YOLO('yolov8m.pt')\n","result= model.train(\n","    data='data.yaml',\n","    task= 'detect',\n","    mode='train',\n","    epochs=100,\n","    imgsz=640,\n","    batch=8,\n","    optimizer='Adam'\n","    )"]},{"cell_type":"markdown","metadata":{"id":"kkkXRpjXKV-m"},"source":["##Predict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDP1qIH6aiSK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688542304146,"user_tz":-420,"elapsed":73198,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"}},"outputId":"201a53a3-067b-48df-8e43-e1ef7b87f223"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","image 1/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest1.png: 224x640 1 A, 1 D, 1 E, 1 O, 1 0, 1 3, 1 4, 1 7, 467.0ms\n","image 2/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest10.png: 256x640 2 Bs, 1 H, 1 Y, 1 1, 1 3, 1 6, 1 7, 582.0ms\n","image 3/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest100.png: 192x640 1 B, 1 R, 1 X, 1 0, 1 1, 1 4, 1 8, 458.5ms\n","image 4/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest11.png: 224x640 1 B, 2 1s, 1 2, 1 6, 2 7s, 2 8s, 778.6ms\n","image 5/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest12.png: 224x640 1 B, 1 M, 1 N, 1 W, 1 Z, 1 1, 1 6, 1 7, 1 8, 766.9ms\n","image 6/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest13.png: 224x640 1 A, 1 D, 2 Ss, 1 1, 2 3s, 1 9, 778.3ms\n","image 7/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest14.png: 224x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 772.1ms\n","image 8/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest15.png: 352x640 1 B, 1 S, 1 T, 1 Z, 1 0, 2 1s, 1 8, 1140.2ms\n","image 9/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest16.png: 288x640 1 B, 1 J, 1 S, 1 T, 1 1, 2 4s, 1 7, 599.3ms\n","image 10/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest17.png: 224x640 1 B, 1 P, 1 U, 1 1, 1 3, 2 9s, 452.8ms\n","image 11/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest18.png: 224x640 1 B, 2 Ts, 1 Z, 1 0, 1 1, 1 2, 1 6, 470.2ms\n","image 12/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest19.png: 224x640 1 B, 1 J, 1 O, 1 T, 1 1, 1 3, 1 6, 1 7, 447.2ms\n","image 13/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest2.png: 224x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 473.3ms\n","image 14/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest20.png: 192x640 1 B, 1 O, 1 Q, 1 1, 1 7, 390.0ms\n","image 15/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest21.png: 352x640 1 A, 2 2s, 2 4s, 2 8s, 1 9, 725.5ms\n","image 16/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest22.png: 224x640 1 B, 1 M, 1 N, 1 Z, 1 1, 1 2, 1 3, 1 6, 463.9ms\n","image 17/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest23.png: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 388.2ms\n","image 18/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest24.png: 256x640 1 B, 1 J, 1 K, 1 T, 1 1, 532.8ms\n","image 19/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest25.png: 160x640 2 As, 1 D, 1 O, 1 0, 1 4, 1 7, 1 8, 342.6ms\n","image 20/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest26.png: 352x640 1 B, 1 E, 1 G, 1 K, 3 1s, 1 3, 770.4ms\n","image 21/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest27.png: 192x640 1 B, 1 N, 1 0, 1 1, 1 3, 1 7, 393.9ms\n","image 22/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest28.png: 192x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 396.2ms\n","image 23/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest29.png: 192x640 1 A, 1 B, 2 Cs, 1 D, 1 O, 1 0, 1 2, 1 8, 396.5ms\n","image 24/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest3.png: 256x640 2 Bs, 1 T, 1 1, 1 6, 517.3ms\n","image 25/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest30.png: 320x640 2 As, 1 N, 1 1, 1 2, 2 9s, 794.4ms\n","image 26/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest31.png: 224x640 1 B, 1 I, 1 K, 1 X, 2 0s, 1 1, 1 2, 1 9, 792.3ms\n","image 27/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest32.png: 224x640 1 B, 1 O, 1 R, 1 T, 1 1, 1 3, 1 4, 1 6, 757.4ms\n","image 28/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest33.png: 192x640 1 B, 1 J, 1 T, 1 U, 1 0, 1 1, 1 3, 1 9, 693.5ms\n","image 29/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest34.png: 352x640 1 A, 1 B, 1 D, 1 1, 1 2, 1 6, 1 8, 1204.0ms\n","image 30/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest35.png: 256x640 1 B, 1 D, 1 E, 1 F, 1 T, 1 0, 2 1s, 1 6, 1 8, 685.5ms\n","image 31/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest36.png: 416x640 1 A, 1 F, 1 S, 1 4, 1 7, 1 8, 1 9, 845.5ms\n","image 32/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest37.png: 224x640 1 B, 1 F, 1 N, 1 O, 1 1, 1 5, 2 6s, 458.9ms\n","image 33/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest38.png: 288x640 1 B, 1 J, 1 Q, 1 S, 1 0, 1 1, 1 3, 1 6, 590.0ms\n","image 34/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest39.png: 192x640 1 B, 1 F, 1 T, 1 X, 1 1, 1 2, 1 4, 1 5, 394.1ms\n","image 35/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest4.png: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 396.3ms\n","image 36/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest40.png: 224x640 1 B, 1 C, 1 J, 1 Y, 1 1, 1 3, 1 6, 1 8, 447.8ms\n","image 37/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest41.png: 352x640 1 A, 1 B, 1 H, 1 U, 1 2, 1 3, 1 4, 1 9, 715.2ms\n","image 38/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest42.png: 160x640 1 B, 1 N, 1 U, 1 0, 2 1s, 1 5, 1 9, 334.1ms\n","image 39/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest43.png: 160x640 1 B, 1 J, 1 L, 1 P, 1 T, 1 1, 1 3, 1 7, 1 9, 340.1ms\n","image 40/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest44.png: 256x640 1 B, 1 L, 1 U, 1 0, 2 2s, 517.8ms\n","image 41/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest45.png: 224x640 1 B, 1 M, 1 T, 1 Z, 1 0, 1 1, 1 2, 1 6, 459.4ms\n","image 42/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest46.png: 288x640 1 B, 1 P, 1 W, 1 Y, 1 1, 1 2, 1 4, 1 7, 587.4ms\n","image 43/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest47.png: 192x640 1 B, 1 I, 1 S, 1 V, 1 0, 2 1s, 1 2, 742.5ms\n","image 44/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest48.png: 224x640 1 A, 1 D, 1 E, 1 O, 1 Q, 1 0, 1 3, 1 4, 1 7, 450.6ms\n","image 45/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest49.png: 352x640 1 A, 1 B, 1 C, 1 X, 1 2, 1 3, 1 4, 1 5, 710.3ms\n","image 46/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest5.png: 384x640 1 A, 1 B, 1 2, 1 3, 1 6, 4 7s, 1173.6ms\n","image 47/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest50.png: 224x640 2 Bs, 1 E, 1 J, 1 1, 1 5, 1 8, 1 9, 778.7ms\n","image 48/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest51.png: 256x640 1 B, 1 J, 1 T, 1 U, 1 1, 1 6, 1 7, 1 8, 877.9ms\n","image 49/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest52.png: 256x640 1 B, 1 F, 1 R, 1 S, 1 1, 1 4, 1 5, 1 9, 856.9ms\n","image 50/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest53.png: 256x640 1 B, 1 E, 1 F, 1 O, 1 1, 1 6, 1 8, 1 9, 535.0ms\n","image 51/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest54.png: 192x640 1 B, 1 V, 1 X, 2 1s, 1 3, 1 7, 387.4ms\n","image 52/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest55.png: 352x640 1 B, 1 P, 1 S, 1 U, 1 W, 1 0, 1 1, 1 3, 1 6, 722.7ms\n","image 53/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest56.png: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 391.8ms\n","image 54/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest57.png: 192x640 2 As, 1 V, 1 0, 1 1, 1 4, 1 8, 417.2ms\n","image 55/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest58.png: 192x640 1 B, 1 U, 1 Y, 1 1, 1 3, 1 7, 1 8, 392.0ms\n","image 56/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest59.png: 160x640 1 B, 1 I, 1 U, 1 0, 1 1, 1 2, 1 8, 330.6ms\n","image 57/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest6.png: 192x640 1 B, 1 V, 2 1s, 1 2, 1 3, 388.5ms\n","image 58/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest60.png: 224x640 2 Bs, 2 Ks, 1 M, 1 1, 2 2s, 1 4, 460.8ms\n","image 59/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest61.png: 320x640 2 As, 1 B, 1 X, 1 2, 1 5, 1 7, 1 8, 640.5ms\n","image 60/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest62.png: 288x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 590.3ms\n","image 61/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest63.png: 288x640 1 B, 1 Y, 2 1s, 1 5, 1 7, 593.5ms\n","image 62/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest64.png: 224x640 1 B, 1 D, 1 F, 1 R, 1 1, 1 2, 2 3s, 450.3ms\n","image 63/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest65.png: 192x640 1 B, 1 I, 1 N, 1 0, 2 1s, 1 3, 396.3ms\n","image 64/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest66.png: 256x640 1 A, 1 D, 1 J, 1 Q, 1 R, 2 9s, 519.0ms\n","image 65/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest67.png: 288x640 1 B, 1 E, 1 S, 1 Y, 1 1, 1 3, 1 6, 1 8, 587.7ms\n","image 66/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest68.png: 256x640 2 As, 1 Q, 2 0s, 1 4, 1 7, 518.2ms\n","image 67/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest69.png: 160x640 1 B, 2 Ss, 1 W, 2 1s, 1 2, 1 4, 368.1ms\n","image 68/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest7.png: 288x640 1 B, 1 F, 1 R, 1 T, 1 0, 1 1, 1 4, 1 6, 995.0ms\n","image 69/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest70.png: 256x640 1 B, 2 Js, 1 T, 1 1, 1 2, 1 3, 1 6, 874.2ms\n","image 70/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest71.png: 256x640 1 B, 1 E, 1 L, 1 R, 1 0, 1 1, 1 7, 1 9, 887.6ms\n","image 71/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest72.png: 192x640 1 B, 1 D, 1 J, 1 Q, 1 T, 2 1s, 1 5, 1 8, 666.1ms\n","image 72/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest73.png: 288x640 1 B, 1 F, 1 J, 1 N, 1 U, 1 1, 1 3, 1 4, 1 7, 937.0ms\n","image 73/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest74.png: 192x640 1 B, 1 E, 1 F, 1 Y, 1 1, 1 3, 1 4, 1 7, 388.8ms\n","image 74/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest75.png: 160x640 1 B, 1 O, 1 Q, 1 0, 1 1, 1 5, 1 7, 340.9ms\n","image 75/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest76.png: 352x640 1 A, 1 2, 2 3s, 1 9, 706.1ms\n","image 76/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest77.png: 192x640 1 B, 1 J, 2 Ts, 1 1, 1 2, 1 3, 1 5, 398.6ms\n","image 77/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest78.png: 256x640 1 B, 1 J, 1 L, 2 Ss, 2 1s, 1 5, 1 7, 532.2ms\n","image 78/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest79.png: 192x640 1 B, 1 V, 1 X, 2 1s, 1 3, 1 7, 748.5ms\n","image 79/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest8.png: 160x640 1 B, 1 J, 1 T, 1 W, 1 1, 1 3, 1 5, 1 9, 328.7ms\n","image 80/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest80.png: 224x640 1 B, 1 J, 1 S, 1 T, 2 1s, 1 3, 1 6, 451.5ms\n","image 81/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest81.png: 192x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 393.8ms\n","image 82/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest82.png: 384x640 1 B, 1 K, 1 N, 1 Y, 1 1, 1 2, 1 3, 1 5, 762.1ms\n","image 83/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest83.png: 192x640 1 B, 1 Y, 3 0s, 1 1, 2 8s, 396.6ms\n","image 84/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest84.png: 192x640 1 B, 1 E, 1 T, 1 V, 3 1s, 1 4, 389.7ms\n","image 85/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest85.png: 352x640 1 B, 1 E, 2 Ks, 1 3, 2 7s, 1 8, 717.3ms\n","image 86/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest86.png: 256x640 1 B, 1 F, 1 O, 1 Q, 1 R, 1 1, 2 3s, 1 8, 518.9ms\n","image 87/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest87.png: 192x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 3, 1 9, 397.9ms\n","image 88/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest88.png: 320x640 1 A, 1 B, 1 0, 1 2, 1 5, 3 8s, 1 9, 653.5ms\n","image 89/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest89.png: 256x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 518.1ms\n","image 90/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest9.png: 256x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 2, 1 7, 765.1ms\n","image 91/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest90.png: 224x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 5, 2 8s, 785.1ms\n","image 92/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest91.png: 256x640 1 B, 1 N, 2 Ss, 1 1, 1 3, 1 4, 1 6, 872.3ms\n","image 93/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest92.png: 288x640 1 A, 2 Bs, 1 N, 2 1s, 1 3, 1 5, 1 9, 984.1ms\n","image 94/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest93.png: 288x640 1 A, 1 B, 2 Us, 1 1, 1 2, 1 6, 1 7, 951.3ms\n","image 95/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest94.png: 224x640 1 B, 1 J, 1 T, 1 V, 1 0, 1 1, 1 2, 1 8, 466.9ms\n","image 96/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest95.png: 160x640 2 Bs, 1 R, 2 1s, 1 6, 1 8, 1 9, 333.4ms\n","image 97/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest96.png: 256x640 1 B, 1 D, 1 L, 2 Qs, 1 2, 1 3, 1 5, 2 8s, 520.1ms\n","image 98/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest97.png: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 391.2ms\n","image 99/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest98.png: 192x640 1 A, 1 C, 1 E, 2 Gs, 1 1, 1 7, 1 8, 1 9, 397.8ms\n","image 100/100 /content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs/DataTest99.png: 160x640 1 B, 1 N, 1 U, 1 0, 2 1s, 1 5, 1 9, 325.3ms\n","Speed: 2.1ms preprocess, 585.9ms inference, 1.1ms postprocess per image at shape (1, 3, 160, 640)\n"]}],"source":["model = YOLO('/content/drive/MyDrive/BDC/runs/detect/train3/weights/best.pt')\n","tab = model.predict('/content/drive/MyDrive/BDC/GFPGAN/hasil1/restored_imgs')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C2hy6I83K3bI"},"outputs":[],"source":["NomorKendaraan=[]\n","NamaFile= []\n","for i in tab :\n","  kelas = pd.DataFrame(i.boxes.cls.cpu().numpy()).astype(int)\n","  kelas = kelas.rename(columns={0:'kelas'})\n","  titik = pd.DataFrame(i.boxes.xywhn.cpu().numpy())\n","  titik = titik.rename(columns={0:'x', 1:'y', 2:'w', 3:'h'})\n","  titik= titik.join(kelas).sort_values('x', ascending=True)\n","  plat = titik['kelas'].astype(str).tolist()\n","  name = i.path.split('/')\n","  name= name[8]\n","  NomorKendaraan.append(BikinPlat(plat))\n","  NamaFile.append(name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHotKJi7Pi6G"},"outputs":[],"source":["submission = {\n","    'File': NamaFile,\n","    'Plate':NomorKendaraan\n","}\n","submission = pd.DataFrame(submission)\n","submission = submission.iloc[submission['File'].map(natural_sort_key).argsort()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyqjAY-ApGuv"},"outputs":[],"source":["pd.set_option('display.max_rows', 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":490,"status":"ok","timestamp":1688542328538,"user":{"displayName":"ANDIKA RISKY SURURI","userId":"00248796806017607753"},"user_tz":-420},"id":"dex-2ak9aD0X","outputId":"7ee94721-5027-4fe3-c3a9-02afbc316892"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               File     Plate\n","0     DataTest1.png  AD7034OE\n","12    DataTest2.png   A9388EX\n","23    DataTest3.png     B16TB\n","34    DataTest4.png  B1661TKZ\n","45    DataTest5.png  7763772A\n","56    DataTest6.png    B3211V\n","67    DataTest7.png  B1064TFR\n","78    DataTest8.png  B1395TJW\n","89    DataTest9.png  B1270RFD\n","1    DataTest10.png  B1736BYH\n","3    DataTest11.png  B1627817\n","4    DataTest12.png  B1678WZM\n","5    DataTest13.png  AD9313SS\n","6    DataTest14.png   B1036UL\n","7    DataTest15.png  B1801TZS\n","8    DataTest16.png  B1474TJS\n","9    DataTest17.png   B1939PU\n","10   DataTest18.png  B1260TZT\n","11   DataTest19.png  B1376TJO\n","13   DataTest20.png     B17QO\n","14   DataTest21.png  A8842294\n","15   DataTest22.png  B1236ZNM\n","16   DataTest23.png  AB8644PK\n","17   DataTest24.png     B1JKT\n","18   DataTest25.png  AA7084OD\n","19   DataTest26.png  B1131EKG\n","20   DataTest27.png    B1037N\n","21   DataTest28.png   B1036UL\n","22   DataTest29.png  BACD820C\n","24   DataTest30.png   A9192AN\n","25   DataTest31.png  B90120KX\n","26   DataTest32.png  B1643TRO\n","27   DataTest33.png  B1390TJU\n","28   DataTest34.png   AB2681D\n","29   DataTest35.png  DB11860E\n","30   DataTest36.png   A8749FS\n","31   DataTest37.png  B1566FON\n","32   DataTest38.png  B1063SJQ\n","33   DataTest39.png  B1254TFX\n","35   DataTest40.png  B1638JCY\n","36   DataTest41.png  AB4923UH\n","37   DataTest42.png  B15091UN\n","38   DataTest43.png  B1937TJL\n","39   DataTest44.png    B202UL\n","40   DataTest45.png  B1026TMZ\n","41   DataTest46.png  B1724PYW\n","42   DataTest47.png  B1102SIV\n","43   DataTest48.png  AQD7034O\n","44   DataTest49.png  AB4352CX\n","46   DataTest50.png  B1895EJB\n","47   DataTest51.png  B1786UJT\n","48   DataTest52.png  B1549RFS\n","49   DataTest53.png  B1869EOF\n","50   DataTest54.png   B1713VX\n","51   DataTest55.png  B1063SPU\n","52   DataTest56.png  B1661TKZ\n","53   DataTest57.png   A8014VA\n","54   DataTest58.png   B1873YU\n","55   DataTest59.png   B1820UI\n","57   DataTest60.png  B1422BKK\n","58   DataTest61.png  AB5278XA\n","59   DataTest62.png    AD418U\n","60   DataTest63.png    B1157Y\n","61   DataTest64.png  B1233RFD\n","62   DataTest65.png   B1031NI\n","63   DataTest66.png   AQD99JR\n","64   DataTest67.png  B1683SEY\n","65   DataTest68.png   AA7004Q\n","66   DataTest69.png  B1241SSW\n","68   DataTest70.png  B1632TJJ\n","69   DataTest71.png  B1907ELR\n","70   DataTest72.png  B1815TJD\n","71   DataTest73.png  FB1734UJ\n","72   DataTest74.png  B1743EYF\n","73   DataTest75.png   B1075QO\n","74   DataTest76.png     A2933\n","75   DataTest77.png  B1523TJT\n","76   DataTest78.png  B1157SSL\n","77   DataTest79.png   B1713VX\n","79   DataTest80.png  B1361TJS\n","80   DataTest81.png   A9388EX\n","81   DataTest82.png  B1532NKY\n","82   DataTest83.png  B18008Y0\n","83   DataTest84.png  B1411TVE\n","84   DataTest85.png  KB3787KE\n","85   DataTest86.png  B1338RFO\n","86   DataTest87.png  B1903RFD\n","87   DataTest88.png  A8B29580\n","88   DataTest89.png    AD418U\n","90   DataTest90.png  B1885TLP\n","91   DataTest91.png  B1634SSN\n","92   DataTest92.png  AB35119B\n","93   DataTest93.png  B1726UUA\n","94   DataTest94.png  B1820TJV\n","95   DataTest95.png  B1619BR8\n","96   DataTest96.png  B82385DQ\n","97   DataTest97.png  AB8644PK\n","98   DataTest98.png  ACG9718E\n","99   DataTest99.png  B15091UN\n","2   DataTest100.png   B1408RX"],"text/html":["\n","  <div id=\"df-1349e6ee-cb33-4a32-bb82-eb3979450a43\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File</th>\n","      <th>Plate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DataTest1.png</td>\n","      <td>AD7034OE</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>DataTest2.png</td>\n","      <td>A9388EX</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>DataTest3.png</td>\n","      <td>B16TB</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>DataTest4.png</td>\n","      <td>B1661TKZ</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>DataTest5.png</td>\n","      <td>7763772A</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>DataTest6.png</td>\n","      <td>B3211V</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>DataTest7.png</td>\n","      <td>B1064TFR</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>DataTest8.png</td>\n","      <td>B1395TJW</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>DataTest9.png</td>\n","      <td>B1270RFD</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DataTest10.png</td>\n","      <td>B1736BYH</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DataTest11.png</td>\n","      <td>B1627817</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DataTest12.png</td>\n","      <td>B1678WZM</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>DataTest13.png</td>\n","      <td>AD9313SS</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>DataTest14.png</td>\n","      <td>B1036UL</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>DataTest15.png</td>\n","      <td>B1801TZS</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>DataTest16.png</td>\n","      <td>B1474TJS</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>DataTest17.png</td>\n","      <td>B1939PU</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>DataTest18.png</td>\n","      <td>B1260TZT</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>DataTest19.png</td>\n","      <td>B1376TJO</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>DataTest20.png</td>\n","      <td>B17QO</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>DataTest21.png</td>\n","      <td>A8842294</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>DataTest22.png</td>\n","      <td>B1236ZNM</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>DataTest23.png</td>\n","      <td>AB8644PK</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>DataTest24.png</td>\n","      <td>B1JKT</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>DataTest25.png</td>\n","      <td>AA7084OD</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>DataTest26.png</td>\n","      <td>B1131EKG</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>DataTest27.png</td>\n","      <td>B1037N</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>DataTest28.png</td>\n","      <td>B1036UL</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>DataTest29.png</td>\n","      <td>BACD820C</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>DataTest30.png</td>\n","      <td>A9192AN</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>DataTest31.png</td>\n","      <td>B90120KX</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>DataTest32.png</td>\n","      <td>B1643TRO</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>DataTest33.png</td>\n","      <td>B1390TJU</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>DataTest34.png</td>\n","      <td>AB2681D</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>DataTest35.png</td>\n","      <td>DB11860E</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>DataTest36.png</td>\n","      <td>A8749FS</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>DataTest37.png</td>\n","      <td>B1566FON</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>DataTest38.png</td>\n","      <td>B1063SJQ</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>DataTest39.png</td>\n","      <td>B1254TFX</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>DataTest40.png</td>\n","      <td>B1638JCY</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>DataTest41.png</td>\n","      <td>AB4923UH</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>DataTest42.png</td>\n","      <td>B15091UN</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>DataTest43.png</td>\n","      <td>B1937TJL</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>DataTest44.png</td>\n","      <td>B202UL</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>DataTest45.png</td>\n","      <td>B1026TMZ</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>DataTest46.png</td>\n","      <td>B1724PYW</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>DataTest47.png</td>\n","      <td>B1102SIV</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>DataTest48.png</td>\n","      <td>AQD7034O</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>DataTest49.png</td>\n","      <td>AB4352CX</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>DataTest50.png</td>\n","      <td>B1895EJB</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>DataTest51.png</td>\n","      <td>B1786UJT</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>DataTest52.png</td>\n","      <td>B1549RFS</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>DataTest53.png</td>\n","      <td>B1869EOF</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>DataTest54.png</td>\n","      <td>B1713VX</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>DataTest55.png</td>\n","      <td>B1063SPU</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>DataTest56.png</td>\n","      <td>B1661TKZ</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>DataTest57.png</td>\n","      <td>A8014VA</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>DataTest58.png</td>\n","      <td>B1873YU</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>DataTest59.png</td>\n","      <td>B1820UI</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>DataTest60.png</td>\n","      <td>B1422BKK</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>DataTest61.png</td>\n","      <td>AB5278XA</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>DataTest62.png</td>\n","      <td>AD418U</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>DataTest63.png</td>\n","      <td>B1157Y</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>DataTest64.png</td>\n","      <td>B1233RFD</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>DataTest65.png</td>\n","      <td>B1031NI</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>DataTest66.png</td>\n","      <td>AQD99JR</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>DataTest67.png</td>\n","      <td>B1683SEY</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>DataTest68.png</td>\n","      <td>AA7004Q</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>DataTest69.png</td>\n","      <td>B1241SSW</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>DataTest70.png</td>\n","      <td>B1632TJJ</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>DataTest71.png</td>\n","      <td>B1907ELR</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>DataTest72.png</td>\n","      <td>B1815TJD</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>DataTest73.png</td>\n","      <td>FB1734UJ</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>DataTest74.png</td>\n","      <td>B1743EYF</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>DataTest75.png</td>\n","      <td>B1075QO</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>DataTest76.png</td>\n","      <td>A2933</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>DataTest77.png</td>\n","      <td>B1523TJT</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>DataTest78.png</td>\n","      <td>B1157SSL</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>DataTest79.png</td>\n","      <td>B1713VX</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>DataTest80.png</td>\n","      <td>B1361TJS</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>DataTest81.png</td>\n","      <td>A9388EX</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>DataTest82.png</td>\n","      <td>B1532NKY</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>DataTest83.png</td>\n","      <td>B18008Y0</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>DataTest84.png</td>\n","      <td>B1411TVE</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>DataTest85.png</td>\n","      <td>KB3787KE</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>DataTest86.png</td>\n","      <td>B1338RFO</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>DataTest87.png</td>\n","      <td>B1903RFD</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>DataTest88.png</td>\n","      <td>A8B29580</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>DataTest89.png</td>\n","      <td>AD418U</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>DataTest90.png</td>\n","      <td>B1885TLP</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>DataTest91.png</td>\n","      <td>B1634SSN</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>DataTest92.png</td>\n","      <td>AB35119B</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>DataTest93.png</td>\n","      <td>B1726UUA</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>DataTest94.png</td>\n","      <td>B1820TJV</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>DataTest95.png</td>\n","      <td>B1619BR8</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>DataTest96.png</td>\n","      <td>B82385DQ</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>DataTest97.png</td>\n","      <td>AB8644PK</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>DataTest98.png</td>\n","      <td>ACG9718E</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>DataTest99.png</td>\n","      <td>B15091UN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DataTest100.png</td>\n","      <td>B1408RX</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1349e6ee-cb33-4a32-bb82-eb3979450a43')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1349e6ee-cb33-4a32-bb82-eb3979450a43 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1349e6ee-cb33-4a32-bb82-eb3979450a43');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":39}],"source":["submission"]},{"cell_type":"markdown","metadata":{"id":"FKXOqsFgyd_q"},"source":["Hasil Score : 0.865\n","\n","Epoch : 100"]},{"cell_type":"code","source":["y_true = validation['Plate']\n","y_pred4 = submission['Plate']\n","scores=[]\n","for y_pred, y_true in zip(y_pred4, y_true):\n","  score = metric(y_pred,y_true)\n","  scores.append(score)"],"metadata":{"id":"PETH8IMIynCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(scores), len(scores)"],"metadata":{"id":"gCTorSNyyzyp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Implement code"],"metadata":{"id":"P1TsoZlq7RPQ"}},{"cell_type":"code","source":["from tkinter import *\n","from tkinter import ttk\n","from tkinter import filedialog\n","from PIL import ImageTk, Image\n","import pandas as pd, os, imutils, random, cv2, re, numpy as np\n","from ultralytics import YOLO\n","\n","\n","\n","model_path = \"D:/Download/best_v5l.pt\"\n","model = YOLO(model_path)\n","\n","filename = dirname = None\n","root = Tk()  # create root window\n","def metric(y_pred, y_true):\n","  n = min(len(y_true), len(y_pred))\n","  banyak_spasi= 9-len(y_true)\n","  score= 0\n","  for i in range(n):\n","    if y_pred[i]==y_true[i]:\n","      score+=1\n","  score+= banyak_spasi\n","  score/= 9\n","  return score\n","def destroyAll():\n","    for widget in root.winfo_children():\n","        widget.destroy()\n","\n","def predict_gambar(path):\n","    global model\n","    names = model.names\n","    results = model.predict(path)\n","    result = results[0].cpu().numpy()\n","    class_names = []\n","    result_boxes = []\n","\n","    for box in result.boxes:\n","        class_names.append(names[int(box.cls)])\n","        result_boxes.append(box.xyxy[0])\n","\n","    pd_box = pd.DataFrame(result_boxes)\n","    pd_box.columns = ['xmin', 'ymin', 'xmax', 'ymax']\n","    pd_box['class'] = class_names\n","    pd_box['conf'] = result.boxes.conf\n","    pd_box = pd_box.sort_values('xmin')\n","    return \"\".join(pd_box[\"class\"])\n","\n","def predict_banyak_gambar(dirpath):\n","    global validation\n","    tabel_prediksi = {\"NamaFile\" : [], \"Prediksi\" : [], \"Score\": []}\n","    filenames = os.listdir(dirpath)\n","    filenames = list(filter(lambda x : \".png\" in x or \".jpg\" in x, filenames))\n","    for filename in filenames:\n","        hasil = predict_gambar(dirpath+\"/\"+filename)\n","        tabel_prediksi[\"NamaFile\"].append(filename)\n","        tabel_prediksi['Prediksi'].append(hasil)\n","        tabel_prediksi[\"Score\"].append(metric(hasil, validation.loc[validation['File']==filename, \"Plate\"].values[0]))\n","    return pd.DataFrame(tabel_prediksi)\n","\n","def rotate_prep(dirname, tabel_prediksi):\n","    for i, row in tabel_prediksi.iterrows():\n","        skorAwal = row[\"Score\"]\n","        if skorAwal >= 1:\n","           continue\n","        prediksi = row[\"Prediksi\"]\n","\n","        img = cv2.imread(dirname + \"/\" + row[\"NamaFile\"])\n","        for sudut in [7, -7, 15, -15]:\n","            img_miring = imutils.rotate(img, angle=sudut)\n","            img_miring = img_scale_up = cv2.resize(img_miring, (0, 0), fx=1.5, fy=1.5)\n","            # Create the sharpening kernel\n","            kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n","            # Apply the sharpening kernel to the image using filter2D\n","            img_miring = cv2.filter2D(img_miring, -1, kernel)\n","            try:\n","                hasil = predict_gambar(img_miring)\n","                skorBaru = metric(hasil,validation.loc[validation['File']==row[\"NamaFile\"], \"Plate\"].values[0])\n","                if skorBaru > skorAwal:\n","                    prediksi = hasil\n","                    skorAwal = skorBaru\n","                    tabel_prediksi.loc[tabel_prediksi[\"NamaFile\"] == row[\"NamaFile\"], \"Score\"] = skorAwal\n","                    tabel_prediksi.loc[tabel_prediksi[\"NamaFile\"] == row[\"NamaFile\"], \"Prediksi\"] = prediksi\n","            except:\n","               continue\n","            #     possible_prediksi.append(hasil)\n","        # possible_prediksi = list(filter(lambda x: 4 <= len(x) <= 9, possible_prediksi))\n","        # possible_prediksi = list(filter(lambda x: not x[0].isdigit(), possible_prediksi))\n","        # random_pred = random.choice(possible_prediksi)\n","        # tabel_prediksi.loc[tabel_prediksi[\"NamaFile\"] == row[\"NamaFile\"], \"Prediksi\"] = prediksi\n","    return tabel_prediksi\n","\n","def natural_sort_key(s):\n","    parts = re.split(r'(\\d+)', s)\n","    parts[1::2] = map(int, parts[1::2])\n","    return parts\n","#Fungsi berikut berdasarkan aturan plat tiap daerah\n","\n","def AturanPlat(i):\n","  pattern = \"[A-Z]{1,2}\\d+(\\w+)\"\n","  digitAkhir = re.findall(pattern, i)\n","  pattern = \"[A-Z]{1,2}(\\d+)\\w+\"\n","  digitTengah = re.findall(pattern, i)\n","  pattern = \"([A-Z]{1,2})\\d+\\w+\"\n","  digitAwal = re.findall(pattern, i)\n","  tmp = list(i)\n","  if digitTengah:\n","    if digitTengah[0][0] == \"0\": #Tidak mungkin karakter pertsma tengah diawali 0\n","      digitTengah[0] = \"8\" + digitTengah[0][1:]\n","      tmp = digitAwal + digitTengah + digitAkhir ## Jika karakter awal numerik pada plat nomor dideteksi 0, maka diubah menjadi menjadi 8\n","  if tmp[0]+tmp[1] == 'AB':\n","    if tmp[-2] == 'O':\n","      tmp[-1] = tmp[-1].replace(tmp[-1], 'H') ## Jika karakter awal AB, dan karakter ke 2 dari akhir adalah O, maka karakter akhir diubah menjadi H\n","    elif tmp[-1] == 'O':\n","      tmp.append('H')\n","    elif i[-1]=='1':\n","      i= i[:-1] + \"I\" #Jika digit akhir merupakan angka 1, maka diganti dengan huruf I, karena paling menyerupai\n","      if len(digitAkhir[0]) == 1:\n","        tmp = list(i) + [\"Z\"] # Jika panjang digit akhir hanya 1 karakter, ditambahkan dengan huruf Z\n","\n","  elif tmp[0]+tmp[1] == 'AD':\n","    if tmp[-2]+ tmp[-1] == 'AB':\n","      tmp.append('E') ## Jika digit akhirnya AB (dua huruf), ditambahkan huruf E\n","    elif tmp[-2] == 'C':\n","      tmp[-1] = tmp[-1].replace(tmp[-1], 'B') ##Jika digit keduanya C, digit akhirnya direplcae B\n","  elif tmp[0] == 'B' and tmp[1].isdigit():\n","    if digitAkhir[0][0] == 'U' and len(digitAkhir[0]) == 1:\n","      tmp.append('L') # Jika karakter digit akhirnya hanya 1, dan karakternya U, ditambahkan karakter L\n","    elif digitAkhir[0][0] not in [\"B\",\"S\",\"U\",\"P\",\"T\", \"W\", \"E\", \"N\", \"W\", \"C\", \"V\", \"Q\", \"D\", \"G\", \"J\", \"K\", \"F\", \"Y\",\"R\"] and digitAkhir[0] not in [\"RFD\",\"RFS\",\"RFL\",\"RFU\",\"RFP\"]:\n","      tmp[-2] = tmp[-2].replace(tmp[-2], 'B') #Jika digit akhirnya tidak mengandung plat dari wilayah jabodetabek dan plat khusus, digit keduanya direplace 2 ~\n","    # elif i[0]== 'B' and i[1] =='1' and i[-3:]!= \"JKT\":\n","    #   k=0\n","    #   for x in i:\n","    #     if x.isdigit():\n","    #       k=k+1\n","    #   if k ==1:\n","    #     i = \"\".join(digitAwal+digitTengah) + \"JKT\"\n","    #     tmp = list(i) ## Jika karakter awal B, diikuti numeriknya 1, digit akhirnya diubah menjadi JKT\n","  if digitAwal:\n","\n","    if digitAwal[0] == \"AT\":\n","      tmp = [\"AB\"] + digitTengah + digitAkhir ## Karena AT tidak ada, maka diganti AB\n","      if tmp[-1]==\"I\" and (len(digitAkhir[0]) == 1):\n","        tmp += [\"N\"] ##Jika panjang digit akhirnya 1,dan digit akhirnya I, ditambah huruf N di digit akhir\n","    elif digitAwal[0] == \"AQ\":\n","\n","       digitAwal = [\"AD\"]\n","       tmp = digitAwal + digitTengah + digitAkhir\n","  if digitAkhir:\n","    digitAkhirCorrected = \"\"\n","    for i in range(len(digitAkhir[0])):\n","        if digitAkhir[0][i] == \"0\":\n","           digitAkhirCorrected += \"D\"\n","        else:\n","           digitAkhirCorrected += digitAkhir[0][i]\n","    digitAkhirCorrected = list(digitAkhirCorrected)\n","    tmp = digitAwal + digitTengah + digitAkhirCorrected\n","  tmp = ''.join(tmp)\n","  return tmp\n","\n","## Untuk menghapus digit numerik yang lebih dari 4 buahbuah\n","## Untuk mengibah hasil deteksi O menjadi 0 (nol) jika jumlah digit numerik sudah 4 buah\n","def RemoveDigit(i):\n","  teks = list(i)\n","  c= -1\n","  for i in range(len(teks)):\n","    if teks[i].isdigit():\n","      c=c+1\n","      if c >3 and  teks[i]== '0':\n","        teks[i] = 'O'\n","      elif c> 3 and teks[i]!= '0':\n","        teks[i] = \"\"\n","  teks = ''.join(teks)\n","  return teks\n","\n","def CheckKarakter(i):\n","  tmp = i\n","  pattern = \"[A-Z]{1,2}\\d+(\\w+)\"\n","  digitAkhir = re.findall(pattern, i)\n","  pattern = \"[A-Z]{1,2}(\\d+)\\w+\"\n","  digitTengah = re.findall(pattern, i)\n","  pattern = \"([A-Z]{1,3})\\d+\\w+\"\n","  digitAwal = re.findall(pattern, tmp)\n","  if digitAwal:\n","    if len(digitAwal[0]) >= 3:\n","      tmp = digitAwal[0][:2]+digitTengah[0]+digitAkhir[0]\n","  if digitAkhir:\n","    if len(digitAkhir[0]) > 3:\n","        tmp = digitAwal[0][:2]+digitTengah[0]+digitAkhir[0][:3]\n","  return tmp\n","\n","def post_process1(tabel_prediksi):\n","   for i, row in tabel_prediksi.iterrows():\n","      hasil = RemoveDigit(row[\"Prediksi\"])\n","      tabel_prediksi.loc[tabel_prediksi[\"NamaFile\"] == row[\"NamaFile\"], \"Prediksi\"] = hasil\n","   return tabel_prediksi\n","\n","def post_process2(tabel_prediksi):\n","   for i, row in tabel_prediksi.iterrows():\n","      hasil = AturanPlat(CheckKarakter(row[\"Prediksi\"]))\n","      tabel_prediksi.loc[tabel_prediksi[\"NamaFile\"] == row[\"NamaFile\"], \"Prediksi\"] = hasil\n","   return tabel_prediksi\n","\n","def post_process3(tabel_prediksi):\n","   for i, row in tabel_prediksi.iterrows():\n","      hasil = AturanPlat(CheckKarakter(row[\"Prediksi\"]))\n","      tabel_prediksi.loc[tabel_prediksi[\"NamaFile\"] == row[\"NamaFile\"], \"Prediksi\"] = hasil\n","   return tabel_prediksi\n","\n","def update_score(tabel_prediksi):\n","    for i, row in tabel_prediksi.iterrows():\n","      tabel_prediksi.loc[tabel_prediksi[\"NamaFile\"] == row[\"NamaFile\"], \"Score\"] = metric(row[\"Prediksi\"], validation.loc[validation['File']==row[\"NamaFile\"], \"Plate\"].values[0])\n","    return tabel_prediksi\n","\n","def satuGambar():\n","    global image\n","    destroyAll()\n","    filename = filedialog.askopenfilename()\n","    root.title(\"Aplikasi prediksi plat nomor\")  # title of the GUI window\n","    root.maxsize(900, 600)  # specify the max size the window can expand to\n","    root.config(bg=\"skyblue\")  # specify background color\n","\n","    # Create left and right frames\n","    left_frame = Frame(root, width=200, height=400, bg='grey')\n","    left_frame.grid(row=0, column=0, padx=10, pady=5,sticky=W)\n","\n","    right_frame = Frame(root, width=650, height=400, bg='grey')\n","    right_frame.grid(row=0, column=1, padx=10, pady=5)\n","\n","\n","    # Create frames and labels in left_frame\n","    Label(left_frame, text=\"Menu\", bg=\"grey\").grid(row=0, column=0, padx=5, pady=5)\n","\n","    # load image to be \"edited\"\n","\n","\n","    # original_image = image.subsample(3,3)  # resize image using subsample\n","    # Label(left_frame, image=original_image).grid(row=1, column=0, padx=5, pady=5)\n","\n","    # # Display image in right_frame\n","    if filename:\n","        prediksi = predict_gambar(filename)\n","        image = Image.open(filename)\n","        image = image.resize((300, 300)) # crop_image(image,300,300)\n","        image = ImageTk.PhotoImage(image)\n","        Label(right_frame, image=image,width=image.width(),height=image.height()).grid(row=0,column=0, padx=5, pady=5)\n","        Label(left_frame, text=prediksi, bg=\"grey\").grid(row=1, column=0, padx=5, pady=5)\n","\n","    # Create tool bar frame\n","    tool_bar = Frame(left_frame, width=180, height=185)\n","    tool_bar.grid(row=2, column=0, padx=5, pady=5)\n","    Button(root, text=\"Kembali\", command=main).grid(row=0,column=0)\n","\n","def crop_image(image, nw, nh):\n","    w, h = image.size\n","    left = (w - nw) // 2\n","    right = (w + nw) // 2\n","    top = (h - nh) // 2\n","    bottom = (h + nh) // 2\n","    new_im = image.crop((left, top, right, bottom))\n","    return new_im\n","\n","def banyakGambar():\n","    destroyAll()\n","    dirname = filedialog.askdirectory()\n","    root.title(\"Aplikasi prediksi plat nomor\")  # title of the GUI window\n","    root.maxsize(900, 600)  # specify the max size the window can expand to\n","    root.config(bg=\"skyblue\")  # specify background color\n","\n","    # Create left and right frames\n","    left_frame = Frame(root, width=200, height=400, bg='grey')\n","    left_frame.grid(row=0, column=0, padx=10, pady=5)\n","\n","    right_frame = Frame(root, width=650, height=400, bg='grey')\n","    right_frame.grid(row=0, column=1, padx=10, pady=5)\n","\n","    data = predict_banyak_gambar(dirname)\n","    data = rotate_prep(dirname=dirname,tabel_prediksi=data)\n","    data = post_process1(data)\n","    for i in range(2):\n","       data = post_process2(data)\n","    data = post_process3(data)\n","    data = update_score(data)\n","\n","    data = data.iloc[data[\"NamaFile\"].map(natural_sort_key).argsort()]\n","    tree = ttk.Treeview(right_frame, columns = (1,2,3), height = 5, show = \"headings\")\n","    tree.pack(side = 'left')\n","\n","    tree.heading(1, text=\"Nama File\")\n","    tree.heading(2, text=\"Prediksi Plat\")\n","    tree.heading(3, text=\"Score\")\n","\n","    tree.column(1, width = 100)\n","    tree.column(2, width = 100)\n","    tree.column(3, width = 100)\n","\n","    scroll = ttk.Scrollbar(right_frame, orient=\"vertical\", command=tree.yview)\n","    scroll.pack(side = 'right', fill = 'y')\n","\n","    tree.configure(yscrollcommand=scroll.set)\n","\n","    for i, row in data.iterrows():\n","        tree.insert('', 'end', values = (row[\"NamaFile\"], row[\"Prediksi\"], row[\"Score\"]) )\n","\n","    # Create frames and labels in left_frame\n","    Label(left_frame, text=\"Menu\", bg=\"grey\").grid(row=0, column=0, padx=5, pady=5)\n","\n","    # load image to be \"edited\"\n","    # image = PhotoImage(file=\"/home/zafin/Pictures/hh.jpg\")\n","    # original_image = image.subsample(3,3)  # resize image using subsample\n","    # Label(left_frame, image=original_image).grid(row=1, column=0, padx=5, pady=5)\n","\n","    # # Display image in right_frame\n","    # Label(right_frame, image=image).grid(row=0,column=0, padx=5, pady=5)\n","\n","    # Create tool bar frame\n","    tool_bar = Frame(left_frame, width=180, height=185)\n","    tool_bar.grid(row=2, column=0, padx=5, pady=5)\n","    Button(tool_bar, text=\"Kembali\", command=main).grid(row=0,column=0)\n","    Button(tool_bar, text=\"Eksport\", command=lambda : eksport(data)).grid(row=1,column=0)\n","\n","## Untuk mengukur akurasi hasil prediksi\n","\n","\n","def eksport(data):\n","   data.to_csv(\"Data_prediksi.csv\")\n","   print(\"Eksported\")\n","   main()\n","\n","validation = pd.read_csv('D:/College Stuff/IPB University/Data Mining/Satria Data/2023/Final/DataTest.csv', sep=';')\n","validation = validation.iloc[validation['File'].map(natural_sort_key).argsort()]\n","\n","def main():\n","    global image\n","    destroyAll()\n","    root.title(\"Aplikasi prediksi plat nomor\")  # title of the GUI window\n","    root.maxsize(900, 600)  # specify the max size the window can expand to\n","    root.config(bg=\"skyblue\")  # specify background color\n","    root.resizable(False, False)\n","    # Create left and right frames\n","    left_frame = Frame(root, width=200, height=400, bg='black')\n","    left_frame.grid(row=0, column=0, padx=10, pady=5)\n","\n","    right_frame = Frame(root, width=650, height=400, bg='black')\n","    right_frame.grid(row=0, column=1, padx=10, pady=5)\n","\n","    # Create frames and labels in left_frame\n","    Label(left_frame, text=\"Menu Utama\", bg=\"black\",fg=\"white\").grid(row=0, column=0, padx=5, pady=5)\n","\n","    # load image to be \"edited\"\n","    image = Image.open(\"D:/College Stuff/IPB University/Data Mining/Satria Data/2023/Final/home.jpg\")\n","    image = image.resize((300,300))\n","    image = ImageTk.PhotoImage(image)\n","    Label(right_frame, image=image,width=image.width(),height=image.height()).grid(row=0,column=0, padx=5, pady=5)\n","\n","    # image = PhotoImage(file=\"/home/zafin/Pictures/hh.jpg\")\n","    # original_image = image.subsample(3,3)  # resize image using subsample\n","    # Label(left_frame, image=original_image).grid(row=1, column=0, padx=5, pady=5)\n","\n","    # # Display image in right_frame\n","    # Label(right_frame, image=image).grid(row=0,column=0, padx=5, pady=5)\n","\n","    # Create tool bar frame\n","    tool_bar = Frame(left_frame, width=180, height=185)\n","    tool_bar.grid(row=2, column=0, padx=5, pady=5)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    # Example labels that serve as placeholders for other widgets\n","    Button(tool_bar, text=\"1 Gambar\", relief=RAISED,command=satuGambar).grid(row=0, column=0, padx=5, pady=3, ipadx=10)  # ipadx is padding inside the Label widget\n","    Button(tool_bar, text=\"1 Folder\", relief=RAISED, command=banyakGambar).grid(row=0, column=1, padx=5, pady=3, ipadx=10)\n","\n","    Button(tool_bar, text=\"Keluar\",relief=RAISED,command=root.quit).grid(row=1, column=0, padx=5, pady=5,columnspan=2,ipadx=10)\n","\n","\n","# Example labels that could be displayed under the \"Tool\" menu\n","# Label(tool_bar, text=\"Select\").grid(row=1, column=0, padx=5, pady=5)\n","# Label(tool_bar, text=\"Crop\").grid(row=2, column=0, padx=5, pady=5)\n","# Label(tool_bar, text=\"Rotate & Flip\").grid(row=3, column=0, padx=5, pady=5)\n","# Label(tool_bar, text=\"Resize\").grid(row=4, column=0, padx=5, pady=5)\n","# Label(tool_bar, text=\"Exposure\").grid(row=5, column=0, padx=5, pady=5)\n","\n","if __name__ == \"__main__\":\n","    main()\n","    root.mainloop()"],"metadata":{"id":"LJ35DMEV7WhR"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"171qJsRXAs1sIdR5JSfCb5OVI8MfgR6qF","timestamp":1688804406696},{"file_id":"10qWBmR2fJat27oZAAurKjv601vOxFrbK","timestamp":1688738894940}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}